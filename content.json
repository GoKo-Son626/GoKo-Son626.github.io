{"posts":[{"title":"Compilation libraries and tools","text":"常见的编译库与编译工具的介绍及之间的关系 编译器、工具链与C库基本概念1. 编译器 (Compiler) 它是什么？ 代码的“翻译官”。 它的作用？ 将你写的 C/C++ 代码翻译成机器能懂的汇编代码或目标文件 (.o)。 典型代表：GCC, Clang。 使用场景：写任何代码并想让它运行时，第一步就是用编译器进行翻译。 2. 工具链 (Toolchain) 它是什么？ 一个完整的“工具箱”。 它的关联？ 编译器是工具链的核心组件之一。工具链还包含了链接器 (ld)、汇编器 (as) 等，它们协同工作，将代码和库文件打包成最终的可执行文件。 使用场景： 本地工具链：编译在本机运行的程序 (e.g., gcc)。 交叉工具链：在一种架构（如x86电脑）上，编译给另一种架构（如RISC-V开发板）运行的程序 (e.g., riscv64-linux-gnu-gcc)。 3. libc (C标准库) 它是什么？ 一个API标准或规范，不是一个具体的软件。它定义了像 printf, malloc 等基础函数。 它的关联？ 它是所有C程序的基础依赖。你需要一个具体的实现来使用它。 使用场景：这是一个抽象概念，你写的每一行C代码，只要调用了标准函数，都在与这个“标准”打交道。 4. glibc (GNU C Library) 它是什么？ libc 的一种强大、功能全面的实现。 它的关联？ 它是为 Linux 操作系统设计的 libc。它不仅包含标准C函数，还包含大量与Linux内核交互的接口（如进程、网络功能）。 使用场景：当你需要开发一个运行在标准Linux系统（如Ubuntu/Debian/CentOS）上的应用程序时，你的程序会链接 glibc。对应的工具链通常叫 ...-linux-gnu-gcc。 5. newlib 它是什么？ libc 的一种轻量级、精简的实现。 它的关联？ 它是为没有操作系统的环境设计的。因此，它没有 fork 等需要OS支持的复杂功能。 使用场景：开发裸机 (Bare-metal) 程序、固件 (Firmware)、Bootloader，或者在简单的实时操作系统 (RTOS) 上开发。对应的工具链通常叫 ...-elf-gcc。 6. GNU 它是什么？ 一个庞大的自由软件生态系统。 它的关联？ 我们上面讨论的大部分经典工具都来自GNU项目，包括 GCC (编译器), glibc (C库), GDB (调试器), Make (构建工具)。”GNU Toolchain” 指的就是这一整套工具。 使用场景：Linux 和嵌入式开发的事实标准。 7. Clang / LLVM 它是什么？ 一套现代化的、可替代 GNU 的编译器工具集。 它的关联？ Clang 是编译器，是 GCC 的直接竞争对手。Clang 自身不提供 libc，它需要配合 glibc 或 newlib 等一起使用。 使用场景：因其友好的报错信息和模块化设计，在很多领域（如苹果生态、Android NDK）越来越流行。 8. ELF (Executable and Linkable Format) 它是什么？ 一种文件格式，像 .doc 或 .pdf 一样。 它的关联？ 它是工具链最终生成的产品。无论是裸机程序还是Linux程序，最终都可以打包成 ELF 格式。 使用场景： 裸机ELF：内部不依赖 glibc，直接在硬件上跑。 Linux ELF：内部依赖 glibc 和Linux内核，必须在Linux系统上跑。 关键：决定它在哪跑的，是它内部链接了什么库，而不是 ELF 这个格式本身。","link":"/post/Compilation-libraries-and-tools.html"},{"title":"ebpf and use on spacemit-k1","text":"了解ebpf并在riscv平台上使用ebpf ebpf eBPF（extened Berkeley Packet Filter）是一种内核技术，它允许开发人员在不修改内核代码的情况下运行特定的功能。eBPF 的概念源自于 Berkeley Packet Filter（BPF），后者是由贝尔实验室开发的一种网络过滤器，可以捕获和过滤网络数据包。 用途和优势 网络监控：eBPF 可以用于捕获网络数据包，并执行特定的逻辑来分析网络流量。例如，可以使用 eBPF 程序来监控网络流量，并在发现异常流量时进行警报。 安全过滤：eBPF 可以用于对网络数据包进行安全过滤。例如，可以使用 eBPF 程序来阻止恶意流量的传播，或者在发现恶意流量时对其进行拦截。[1] 性能分析：eBPF 可以用于对内核的性能进行分析。例如，可以使用 eBPF 程序来收集内核的性能指标，并通过特定的接口将其可视化。这样，可以更好地了解内核的性能瓶颈，并进行优化。 虚拟化：eBPF 可以用于虚拟化技术。例如，可以使用 eBPF 程序来收集虚拟机的性能指标，并进行负载均衡。这样，可以更好地利用虚拟化环境的资源，提高系统的性能和稳定性。 安全：验证器确保了任何 eBPF 程序都不会搞垮内核。 可移植：同一份 eBPF 字节码，理论上可以在任何架构（x86, ARM, RISC-V）的 Linux 内核上运行，因为 JIT 会为它们翻译出对应的原生机器码。 高性能：因为 JIT 的存在，最终运行的是原生机器码，速度接近于原生内核代码。 原理 eBPF 的工作原理主要分为三个步骤：加载、编译和执行。 eBPF 需要在内核中运行。这通常是由用户态的应用程序完成的，它会通过系统调用来加载 eBPF 程序。在加载过程中，内核会将 eBPF 程序的代码复制到内核空间。 eBPF 程序需要经过编译和执行。这通常是由Clang/LLVM的编译器完成，然后形成字节码后，将用户态的字节码装载进内核，Verifier会对要注入内核的程序进行一些内核安全机制的检查,这是为了确保 eBPF 程序不会破坏内核的稳定性和安全性。在检查过程中，内核会对 eBPF 程序的代码进行分析，以确保它不会进行恶意操作，如系统调用、内存访问等。如果 eBPF 程序通过了内核安全机制的检查，它就可以在内核中正常运行了，其会通过通过一个JIT编译步骤将程序的通用字节码转换为机器特定指令集，以优化程序的执行速度。 关系图1234567891011121314151617181920212223242526272829303132333435363738394041424344454647+-----------------------------------------------------------------------------+| 用户空间 (User Space) ||-----------------------------------------------------------------------------|| [高层抽象/工具] [底层开发库] || || +-----------------+ +----------------+ || | bpftrace | | BCC | || | (诊断与排障语言) | | (快速原型框架) | || +-------+---------+ +--------+-------+ || | | || | | +---------------------------+ || +--------------------------+-------&gt;| libbpf | || | (C开发库, CO-RE) | || +-------------+-------------+ || | || BPF Maps (e.g., RingBuf, Hash) | System Call || &lt;------------------------------------------------------&gt; (bpf()) || (内核与用户空间的数据通道) | (控制与加载) || | |+------------------------------------------------------------+----------------+| 内核空间 (Kernel Space) ||-----------------------------------------------------------------------------|| | || BPF Maps (内核中的键值对存储) &lt;-----------------+ | || | | || +---------------------------------------------+ | | || | eBPF 子系统 | | | || | | | | || | +-----------+ +----------+ +-----+ | | || | | Verifier | --&gt; | JIT | --&gt; | CPU | | | || | | (安全检查) | | (编译优化) | | (原生执行)| | | || | +-----------+ +----------+ +-----+ | v || | | | || | eBPF 程序 (你的.bpf.c代码) | | || | | | || +-----------------------+---------------------+ v || ^ | || | (事件触发) | (读取/写入) || | | || +-----------------------+--------------------------+------------+ || | 内核钩子 (Kernel Hooks) | || | | || | ftrace (kprobes, tracepoints), LSM, TC, XDP, Sockets ... | || | (BTF - 提供内核元数据, 增强钩子能力) | || +-------------------------------------------------------------+ || |+---------------------------------------------------------------------+ 用户空间 / 内核空间 (User/Kernel Space) 明确划分了程序的运行区域。libbpf, BCC, bpftrace 主要运行在用户空间，而 eBPF 程序和钩子则在内核空间。 系统调用 (System Call - bpf()) 这是用户空间的 libbpf 与内核 eBPF 子系统沟通的唯一官方大门。所有加载、卸载、创建 Map 等管理操作，都通过这个系统调用完成。 BPF Maps (数据通道) 它横跨用户空间和内核空间，是两者之间交换数据的桥梁。eBPF 程序在内核里把监控到的数据放进 Map，用户态程序再从 Map 里把数据取出来。 eBPF 子系统内部流程 (Verifier -&gt; JIT -&gt; CPU) 细化了 eBPF 程序在内核中的生命周期：先被验证器(Verifier) 严格检查安全性，然后被即时编译器(JIT) 优化成原生机器码，最后在 CPU 上高效执行。 内核钩子 (Kernel Hooks) 将 ftrace 归入一个更广泛的概念——内核钩子。eBPF 不仅仅能用于追踪 (ftrace)，还能挂载到网络（TC, XDP）、安全（LSM）等各种地方。 BTF (BPF Type Format) 明确了它的角色：它不是一个钩子，而是内核提供的一份“元数据”或“蓝图”。libbpf 利用这份蓝图来实现 CO-RE，eBPF 程序也利用它来更准确地理解和访问内核数据，从而增强了所有钩子的能力。 配置并使用","link":"/post/ebpf-and-use-it.html"},{"title":"Platform bus","text":"平台总线是linux系统虚拟出来的一种总线,是一个内核子系统，负责管理 platform_device（硬件描述）和 platform_driver（驱动代码）,使它们先分离.后搭档 平台总线(Platform Bus)(总线控制器信息和控制器驱动之间) 平台总线（Platform Bus）是内核的一条“虚拟”总线。它不像 PCI、USB 那样是物理上存在的总线，而是为了解决一类特殊设备的驱动问题而设计的 软件机制。这类设备通常是 SoC (System on Chip) 芯片内部集成的、不可被自动识别的外设，比如 I2C 控制器、SPI 控制器、GPIO 控制器、LCD 控制器等。 原理：设备与驱动的分离与匹配 (Separation and Matching) 问题： 对于 PCI 或 USB 设备，设备自身带有 ID 信息（Vendor ID, Product ID）。驱动可以根据这些 ID “认领” 设备。但 SoC 上的那些外设，它们的寄存器地址、中断号都是固定的，写死在芯片里了，没法自动发现。 解决： 把 设备信息 和 驱动代码 分开！” 平台设备 (platform_device)： 这是一块纯粹的“数据”，用来描述硬件资源。它告诉内核：“在物理地址 0x12345678 有个设备，它使用中断号 5，它的名字叫 my-i2c-controller”。这些信息通常写在 设备树 (Device Tree, .dts 文件) 中，或者早期的板级配置文件 (board-xxx.c)里。 平台驱动 (platform_driver)： 真正的驱动代码。注册时告诉内核：是一个驱动，我能处理名字叫 my-i2c-controller 的设备。 匹配 (Match)： 当一个 platform_device 和一个 platform_driver 被注册到内核时，平台总线核心会进行匹配。最常见的匹配方式就是看 名字 是否一样。 探测 (Probe)： 一旦匹配成功，总线核心就会调用平台驱动的 .probe 函数。在这个函数里，驱动程序会通过相关的API函数从 platform_device 结构体中获取到设备的硬件资源（如内存地址、中断号），然后用这些信息去初始化硬件，完成驱动的加载。 流程： 系统启动，内核解析设备树。 内核在设备树里读到一段描述 I2C 控制器硬件的节点（包含了寄存器地址、中断号，以及最重要的 compatible = “vendor,i2c-controller-v1”;）。 内核根据这个节点，创建并注册一个 platform_device 到平台总线。 I2C 控制器驱动（platform_driver）在加载时，会告诉平台总线：“我能处理 compatible 是 “vendor,i2c-controller-v1” 的设备”。 平台总线看到两者匹配，于是调用 I2C 控制器驱动的 .probe 函数。 在 I2C 控制器驱动的 .probe 函数中，驱动程序会执行一系列初始化操作，其中最重要的一步是调用 i2c_add_adapter() 或 i2c_add_numbered_adapter()。这个函数调用，才是在内核中“建立”或“注册”了一条 I2C 总线（即一个 i2c_adapter）。这条逻辑上的总线就代表了那条物理的 I2C 总线。内核里的 i2c_adapter 就是物理 I2C 总线在软件层面的抽象。 设备间交互： “其他设备驱动”（比如 I2C 温度传感器驱动）不直接调用 I2C 控制器驱动里的 ops。这是一个分层概念。 正确的交互方式： I2C 控制器驱动把它实现底层 I/O 操作的 ops（struct i2c_algorithm）注册给了 I2C 总线核心。 I2C 温度传感器驱动想通信时，它调用的是 I2C 总线核心提供的标准、统一的 API，如 i2c_master_send() 和 i2c_master_recv()。 I2C 总线核心在收到这些 API 调用后，会找到对应的 i2c_adapter，然后去调用这个 adapter 在注册时提供的 ops 里的具体函数，最终由 I2C 控制器驱动的代码来操作硬件。 platform bus 设备和驱动1. platform_device结构体1234567891011121314151617181920212223struct platform_device { const char *name; // 显示在/sys/bus/platform/devices/name.id(.auto) int id; // 用来区分不同设备：name.id, id = -1: 没有后缀 bool id_auto; // 自动设置id：name.id.auto struct device dev; // 设备的通用属性部分 u64 platform_dma_mask; struct device_dma_parameters dma_parms; u32 num_resources; // 存储的资源的个数 struct resource *resource; // 存储资源 const struct platform_device_id *id_entry; /* * Driver name to force a match. Do not set directly, because core * frees it. Use driver_set_override() to set or clear it. */ const char *driver_override; /* MFD cell pointer */ struct mfd_cell *mfd_cell; /* arch specific additions */ struct pdev_archdata archdata;}; 成员结构体: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123struct device { struct kobject kobj; struct device *parent; struct device_private *p; const char *init_name; /* initial name of the device */ const struct device_type *type; const struct bus_type *bus; /* type of bus device is on */ struct device_driver *driver; /* which driver has allocated this device */ void *platform_data; /* Platform specific data, device core doesn't touch it */ void *driver_data; /* Driver data, set and get with dev_set_drvdata/dev_get_drvdata */ struct mutex mutex; /* mutex to synchronize calls to * its driver. */ struct dev_links_info links; struct dev_pm_info power; struct dev_pm_domain *pm_domain;#ifdef CONFIG_ENERGY_MODEL struct em_perf_domain *em_pd;#endif#ifdef CONFIG_PINCTRL#endif struct dev_pin_info *pins; struct dev_msi_info msi;#ifdef CONFIG_ARCH_HAS_DMA_OPS const struct dma_map_ops *dma_ops;#endif u64 *dma_mask; /* dma mask (if dma'able device) */ u64 coherent_dma_mask;/* Like dma_mask, but for alloc_coherent mappings as not all hardware supports 64 bit addresses for consistent allocations such descriptors. */ u64 bus_dma_limit; /* upstream dma constraint */ const struct bus_dma_region *dma_range_map; struct device_dma_parameters *dma_parms; struct list_head dma_pools; /* dma pools (if dma'ble) */#ifdef CONFIG_DMA_DECLARE_COHERENT struct dma_coherent_mem *dma_mem; /* internal for coherent mem override */#endif#ifdef CONFIG_DMA_CMA struct cma *cma_area; /* contiguous memory area for dma allocations */#endif#ifdef CONFIG_SWIOTLB struct io_tlb_mem *dma_io_tlb_mem;#endif#ifdef CONFIG_SWIOTLB_DYNAMIC struct list_head dma_io_tlb_pools; spinlock_t dma_io_tlb_lock; bool dma_uses_io_tlb;#endif /* arch specific additions */ struct dev_archdata archdata; struct device_node *of_node; /* associated device tree node */ struct fwnode_handle *fwnode; /* firmware device node */#ifdef CONFIG_NUMA int numa_node; /* NUMA node this device is close to */#endif dev_t devt; /* dev_t, creates the sysfs &quot;dev&quot; */ u32 id; /* device instance */ spinlock_t devres_lock; struct list_head devres_head; const struct class *class; const struct attribute_group **groups; /* optional groups */ void (*release)(struct device *dev); // 必须编写，不然驱动编译不过去 struct iommu_group *iommu_group; struct dev_iommu *iommu; struct device_physical_location *physical_location; enum device_removable removable; bool offline_disabled:1; bool offline:1; bool of_node_reused:1; bool state_synced:1; bool can_match:1;#if defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_DEVICE) || \\ defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU) || \\ defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL) bool dma_coherent:1;#endif#ifdef CONFIG_DMA_OPS_BYPASS bool dma_ops_bypass : 1;#endif#ifdef CONFIG_DMA_NEED_SYNC bool dma_skip_sync:1;#endif#ifdef CONFIG_IOMMU_DMA bool dma_iommu:1;#endif};/* * Resources are tree-like, allowing * nesting etc.. */struct resource { resource_size_t start; // 资源的起始信息和终止信息 resource_size_t end; // etc：中断的起始地址和终止地址 const char *name; // 存储信息名称：etc：中断-irq unsigned long flags; // 存储资源类型：etc: IORESOURCE_IO/MEM/REG/IRQ/DMA/BUS... unsigned long desc; // 描述信息 struct resource *parent, *sibling, *child; // 节点相关}; 2. 简单的platform_device insmod注册成功：ls /sys/bus/platform/devices/mydevice 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;linux/module.h&gt;#include &lt;linux/init.h&gt;#include &lt;linux/platform_device.h&gt;static struct resource mydevice_resource[] = { [0] = { .start = 0xFDD60000, .end = 0xFDD50004, .flags = IORESOURCE_IO, }, [1] = { .start = 13, .end = 13, .flags = IORESOURCE_IRQ, },}void mydevice_release(struct device *dev){ printk(&quot;This is mydevice_release\\n&quot;);}static platform_device platform_device_test = { .name = &quot;mydevice&quot;, .id = -1, .resource = mydevice_resource, .num_resources = ARRAY_SIZE(mydevice_resource), .dev = { .release = mydevice_release, },};static int platform_device_init(void){ platform_device_register(&amp;platform_device_test); printk(&quot;platform_device init\\n&quot;); return 0;}static int platform_device_exit(void){ platform_device_unregister(&amp;platform_device_test); printk(&quot;platform_device exit\\n&quot;); return 0;}module init(platform_device_init);module exit(platform_device_exit);MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;goko&quot;);MODULE_VERSION(&quot;V1.0&quot;); 3. platform_driver结构体123456789101112131415161718struct platform_driver { int (*probe)(struct platform_device *); // 匹配成功之后执行 void (*remove)(struct platform_device *); // 设备移除时执行 void (*shutdown)(struct platform_device *); // 设备关闭时执行dy int (*suspend)(struct platform_device *, pm_message_t state); // 设备挂起时执行dy int (*resume)(struct platform_device *); // 设备恢复时执行dy struct device_driver driver; // 设备公用的一些属性 const struct platform_device_id *id_table; // 设备id表 bool prevent_deferred_probe; /* * For most device drivers, no need to care about this flag as long as * all DMAs are handled through the kernel DMA API. For some special * ones, for example VFIO drivers, they know how to manage the DMA * themselves and set this flag so that the IOMMU layer will allow them * to setup and manage their own I/O address space. */ bool driver_managed_dma;}; 4. 简单的platform_driver insmod注册成功：ls /sys/bus/platform/drivers/mydevice 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287#include &lt;linux/module.h&gt; // 所有模块都需要#include &lt;linux/init.h&gt; // __init 和 __exit 宏#include &lt;linux/fs.h&gt; // file_operations 结构体和文件系统相关函数#include &lt;linux/cdev.h&gt; // cdev 结构体和相关函数#include &lt;linux/uaccess.h&gt; // copy_to_user, copy_from_user#include &lt;linux/device.h&gt; // class_create, device_create#include &lt;linux/io.h&gt; // ioremap, iounmap#include &lt;linux/platform_device.h&gt; // platform_driver 和 platform_device#include &lt;linux/of.h&gt; // of_match_ptr, 设备树相关（如果使用设备树匹配）#include &lt;linux/slab.h&gt; // kzalloc, kfree#define DRIVER_NAME &quot;my_platform_device&quot; // 定义驱动名称#define DEVICE_COUNT 1 // 定义设备数量// 驱动的私有数据结构体，用于存储设备相关的所有信息// 这个结构体整合了你截图中`struct device_test`的所有成员struct mydevice_dev { dev_t dev_num; // 设备号 (主设备号 + 次设备号) struct cdev cdev_test; // 字符设备结构体 struct class *class; // 设备类，用于在/sys/class/下创建条目 struct device *device; // 设备实例，用于在/dev/下创建设备文件 char kbuf[32]; // 内核缓冲区，用于与用户空间交换数据 void __iomem *vir_gpio_dr; // 经过ioremap映射后的虚拟地址};// 全局指针，指向我们的私有数据结构体// 在probe中分配，在remove中释放// 注意：更好的做法是通过 platform_set_drvdata/platform_get_drvdata 来管理，这里为了清晰展示，先用一个全局指针// 稍后会展示更标准的做法struct mydevice_dev *global_mydev; // --- 文件操作函数集 (file_operations) ---static int mydevice_open(struct inode *inode, struct file *file){ struct mydevice_dev *dev; printk(KERN_INFO &quot;mydevice: device opened\\n&quot;); // 通过 inode 中的 cdev 指针，找到包含它的父结构体 mydevice_dev // 这是内核中非常常见和重要的技巧 dev = container_of(inode-&gt;i_cdev, struct mydevice_dev, cdev_test); // 将设备私有结构体的指针存放在 file-&gt;private_data 中 // 这样，在后续的 read/write/release 操作中，就可以直接从 file 中获取，无需再次查找 file-&gt;private_data = dev; return 0;}static int mydevice_release(struct inode *inode, struct file *file){ printk(KERN_INFO &quot;mydevice: device closed\\n&quot;); // 这里不需要释放 file-&gt;private_data，因为它指向的是在 probe 中分配的内存 // 该内存的生命周期与驱动绑定，而不是与文件的打开/关闭绑定 return 0;}static ssize_t mydevice_read(struct file *file, char __user *buf, size_t size, loff_t *off){ // 从 file-&gt;private_data 中获取设备私有结构体指针 struct mydevice_dev *dev = file-&gt;private_data; size_t len = strlen(dev-&gt;kbuf); int ret; printk(KERN_INFO &quot;mydevice: reading data: %s\\n&quot;, dev-&gt;kbuf); if (size &gt; len) { size = len; } // 将内核空间的数据 (dev-&gt;kbuf) 拷贝到用户空间 (buf) ret = copy_to_user(buf, dev-&gt;kbuf, size); if (ret != 0) { printk(KERN_ERR &quot;mydevice: copy_to_user failed\\n&quot;); return -EFAULT; // 返回一个标准的错误码 } // 在这里，一个简单的实现是每次读取后返回已读取的字节数 // 一个更完整的实现需要处理 *off，以支持多次读取文件的不同部分 return size;}static ssize_t mydevice_write(struct file *file, const char __user *buf, size_t size, loff_t *off){ // 从 file-&gt;private_data 中获取设备私有结构体指针 struct mydevice_dev *dev = file-&gt;private_data; int ret; if (size &gt;= sizeof(dev-&gt;kbuf)) { printk(KERN_WARNING &quot;mydevice: write size is too large\\n&quot;); // 截断写入的数据，防止缓冲区溢出 size = sizeof(dev-&gt;kbuf) - 1; } // 将用户空间的数据 (buf) 拷贝到内核空间 (dev-&gt;kbuf) ret = copy_from_user(dev-&gt;kbuf, buf, size); if (ret != 0) { printk(KERN_ERR &quot;mydevice: copy_from_user failed\\n&quot;); return -EFAULT; } // 给内核缓冲区加上字符串结束符 dev-&gt;kbuf[size] = '\\0'; printk(KERN_INFO &quot;mydevice: written data: %s\\n&quot;, dev-&gt;kbuf); // 在一个真实的GPIO驱动中，这里会解析 kbuf 中的命令（如&quot;on&quot;或&quot;off&quot;） // 然后通过 dev-&gt;vir_gpio_dr 指针向硬件寄存器写入值 // 例如：iowrite32(1, dev-&gt;vir_gpio_dr); return size; // 返回成功写入的字节数}// 定义 file_operations 结构体，并将我们的函数与之关联static const struct file_operations mydevice_fops = { .owner = THIS_MODULE, .open = mydevice_open, .release = mydevice_release, .read = mydevice_read, .write = mydevice_write,};// --- Platform 驱动核心函数 ---// 当内核匹配到同名的 platform_device 时，会调用此 probe 函数static int mydriver_probe(struct platform_device *pdev){ int ret; struct resource *mem_res; struct mydevice_dev *dev; printk(KERN_INFO &quot;mydriver_probe: device probed!\\n&quot;); // 1. 分配私有数据结构体内存 // 使用 devm_kzalloc, &quot;devm_&quot; 开头的函数是受设备管理的，当设备卸载时会自动释放资源，非常方便 dev = devm_kzalloc(&amp;pdev-&gt;dev, sizeof(struct mydevice_dev), GFP_KERNEL); if (!dev) { return -ENOMEM; } global_mydev = dev; // 赋值给全局指针（仅为示例） // 2. 从 platform_device 获取资源 (这里以内存资源为例) // 参数: platform_device指针, 资源类型, 索引(第0个内存资源) mem_res = platform_get_resource(pdev, IORESOURCE_MEM, 0); if (!mem_res) { printk(KERN_ERR &quot;mydriver: failed to get memory resource\\n&quot;); return -EINVAL; } printk(KERN_INFO &quot;mydriver: mem resource start: 0x%pa, size: %lld\\n&quot;, &amp;mem_res-&gt;start, resource_size(mem_res)); // 3. 将物理地址映射到内核虚拟地址空间 // devm_ioremap_resource 会自动处理 ioremap 和 iounmap，非常推荐使用 dev-&gt;vir_gpio_dr = devm_ioremap_resource(&amp;pdev-&gt;dev, mem_res); if (IS_ERR(dev-&gt;vir_gpio_dr)) { printk(KERN_ERR &quot;mydriver: failed to ioremap memory resource\\n&quot;); return PTR_ERR(dev-&gt;vir_gpio_dr); } // ======== 以下是字符设备创建的标准流程 (来自你的截图逻辑) ======== // 4. 动态申请设备号 ret = alloc_chrdev_region(&amp;dev-&gt;dev_num, 0, DEVICE_COUNT, DRIVER_NAME); if (ret &lt; 0) { printk(KERN_ERR &quot;mydriver: failed to allocate chrdev region\\n&quot;); return ret; } printk(KERN_INFO &quot;mydriver: allocated major=%d, minor=%d\\n&quot;, MAJOR(dev-&gt;dev_num), MINOR(dev-&gt;dev_num)); // 5. 初始化 cdev 结构体，并绑定 file_operations cdev_init(&amp;dev-&gt;cdev_test, &amp;mydevice_fops); dev-&gt;cdev_test.owner = THIS_MODULE; // 6. 将 cdev 添加到内核中 ret = cdev_add(&amp;dev-&gt;cdev_test, dev-&gt;dev_num, DEVICE_COUNT); if (ret &lt; 0) { printk(KERN_ERR &quot;mydriver: failed to add cdev\\n&quot;); goto err_unregister_chrdev; } // 7. 创建设备类 /sys/class/my_platform_device dev-&gt;class = class_create(THIS_MODULE, DRIVER_NAME); if (IS_ERR(dev-&gt;class)) { ret = PTR_ERR(dev-&gt;class); printk(KERN_ERR &quot;mydriver: failed to create class\\n&quot;); goto err_cdev_del; } // 8. 创建设备文件 /dev/my_platform_device dev-&gt;device = device_create(dev-&gt;class, NULL, dev-&gt;dev_num, NULL, DRIVER_NAME); if (IS_ERR(dev-&gt;device)) { ret = PTR_ERR(dev-&gt;device); printk(KERN_ERR &quot;mydriver: failed to create device\\n&quot;); goto err_class_destroy; } // 9. 将私有数据结构体指针与 platform_device 关联 // 这样在 remove 函数中就可以通过 platform_get_drvdata 获取它 platform_set_drvdata(pdev, dev); // 初始化内核缓冲区 strcpy(dev-&gt;kbuf, &quot;Hello from kernel!&quot;); printk(KERN_INFO &quot;mydriver: probe successful, device created at /dev/%s\\n&quot;, DRIVER_NAME); return 0;// 错误处理：按相反的顺序释放已申请的资源err_class_destroy: class_destroy(dev-&gt;class);err_cdev_del: cdev_del(&amp;dev-&gt;cdev_test);err_unregister_chrdev: unregister_chrdev_region(dev-&gt;dev_num, DEVICE_COUNT); // devm_kzalloc 和 devm_ioremap_resource 分配的资源会自动释放，无需手动处理 return ret;}// 当驱动被卸载或设备被移除时，调用此 remove 函数static int mydriver_remove(struct platform_device *pdev){ // 通过 platform_get_drvdata 获取在 probe 中设置的私有数据 struct mydevice_dev *dev = platform_get_drvdata(pdev); printk(KERN_INFO &quot;mydriver_remove: removing device\\n&quot;); // 按照与 probe 相反的顺序销毁和释放资源 // 注意：devm_ 家族函数管理的资源（内存、ioremap）不需要在这里手动释放！ // 驱动核心会在这个函数返回后自动清理它们。 // 销毁设备文件 /dev/my_platform_device device_destroy(dev-&gt;class, dev-&gt;dev_num); // 销毁设备类 /sys/class/my_platform_device class_destroy(dev-&gt;class); // 从内核中删除 cdev cdev_del(&amp;dev-&gt;cdev_test); // 注销设备号 unregister_chrdev_region(dev-&gt;dev_num, DEVICE_COUNT); printk(KERN_INFO &quot;mydriver_remove: remove successful\\n&quot;); return 0;}// ID 表，用于匹配 platform_device// 当一个 platform_device 的 .name 字段与这里的 .name 匹配时，probe 就会被调用static const struct platform_device_id mydriver_id_table[] = { { .name = &quot;my-platform-device-example&quot; }, // 这个名字需要与 platform_device 注册时使用的名字完全一致 { /* sentinel */ }, // 结尾的空条目，表示列表结束};MODULE_DEVICE_TABLE(platform, mydriver_id_table); // 将id_table导出，让内核和用户空间知道// 定义 platform_driver 结构体static struct platform_driver my_platform_driver = { .probe = mydriver_probe, .remove = mydriver_remove, .driver = { .name = &quot;my-platform-device-example&quot;, // 驱动的名字 .owner = THIS_MODULE, }, .id_table = mydriver_id_table, // 关联ID匹配表};// 模块加载函数static int __init my_driver_init(void){ printk(KERN_INFO &quot;my_driver_init: Registering platform driver\\n&quot;); // 注册 platform_driver 到内核 return platform_driver_register(&amp;my_platform_driver);}// 模块卸载函数static void __exit my_driver_exit(void){ printk(KERN_INFO &quot;my_driver_exit: Unregistering platform driver\\n&quot;); // 从内核中注销 platform_driver platform_driver_unregister(&amp;my_platform_driver);}// 注册模块加载和卸载函数module_init(my_driver_init);module_exit(my_driver_exit);// 模块许可和信息MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;Your Name&quot;);MODULE_DESCRIPTION(&quot;A complete platform device driver example&quot;);MODULE_VERSION(&quot;1.0&quot;); 平台总线和设备驱动 启动与准备 (第 0 步): 内核启动，解析设备树。 它看到一个描述 I2C 控制器的节点，于是创建了一个 platform_device。 它看到 I2C 控制器节点下还有一个描述温度传感器的子节点，于是为它创建了一个 i2c_client 的描述信息（但此时还未注册，因为 I2C 总线还不存在）。 第一层匹配 (平台总线): 你加载了 I2C 控制器驱动 (platform_driver)。 平台总线发现这个驱动和之前创建的 platform_device 匹配。 平台总线调用 I2C 控制器驱动 的 .probe() 函数。 桥梁搭建 (控制器驱动的工作): 在 I2C 控制器驱动 的 .probe() 函数中，驱动初始化了硬件，然后调用 i2c_add_adapter()。 这个调用是关键！ 它在内核里创建并注册了一条功能完备的 I2C 总线。 第二层匹配 (I2C 总线): 新的 I2C 总线被注册后，内核的 I2C 核心会把之前为温度传感器准备的 i2c_client 描述信息，正式注册到这条新的 I2C 总线上。 现在，你加载了温度传感器驱动 (i2c_driver)。 I2C 总线发现这个驱动和刚刚注册的 i2c_client 匹配。 I2C 总线调用温度传感器驱动的 .probe() 函数。 最终通信 (设备驱动的工作): 在温度传感器驱动的 .probe() 或其他函数里，它想读取温度。 它调用一个标准的、与硬件无关的函数 i2c_master_recv()。 I2C 核心收到调用，查找该设备挂在哪条 I2C 总线上。 它找到了由I2C 控制器驱动注册的那条总线，然后调用了该控制器驱动提供的底层传输函数。 I2C 控制器驱动的代码开始执行，通过操作寄存器来命令物理 I2C 控制器去和物理温度传感器通信，并取回数据。 总结：关系一览 角色 所在的“层” 它的“驱动”是？ 它的“设备描述”是？ 它和下一层的关系 I2C 控制器 平台总线层 platform_driver platform_device 它的驱动创建了 I2C 总线层 I2C 终端设备 I2C 总线层 i2c_driver i2c_client 它的驱动使用 I2C 总线层提供的服务","link":"/post/Platform-bus.html"},{"title":"hexo-blog","text":"使用hexo和GitHub Pagtes部署一个自己的博客 1. 安装并初始化Hexo 安装 Hexo CLI 1npm install -g hexo-cli 初始化博客项目目录 123mkdir my-blog &amp;&amp; cd my-bloghexo initnpm install 本地预览 1hexo server 启动本地服务：在浏览器访问 http://localhost:4000 查看效果 2. 配置 GitHub Pages 部署 创建GitHub仓库 创建一个仓库，名字叫 你的GitHub用户名.github.io 比如你是 goko，就叫 goko.github.io 安装部署插件 1npm install hexo-deployer-git --save 修改 _config.yml（根目录下）添加部署配置： 12345deploy: type: git # repo建议使用SSH, SSH免密 repo: https://github.com/你的GitHub用户名/你的GitHub用户名.github.io.git branch: main # 或者 master，看你的默认分支 生成并部署博客 123hexo cleanhexo generatehexo deploy 3. 域名(.com)绑定 添加域名(在my-blog下) 123echo &quot;&lt;xxxx&gt;.com&quot; &gt; source/CNAME# 或者可以：echo &quot;www.&lt;xxxx&gt;.com&quot; &gt; source/CNAME# 只能添加一个，而且两个需要添加不同的域名解析（如下） 重新部署 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 设置 DNS 解析指向 GitHub Pages A. 使用裸域名（apex 域名）goku72.com 记录类型 主机记录 记录值 说明 A @ 185.199.108.153 GitHub Pages IP A @ 185.199.109.153 GitHub Pages IP A @ 185.199.110.153 GitHub Pages IP A @ 185.199.111.153 GitHub Pages IP example aliyun: 选择业务需求: 将网站域名解析到服务器IPv4地址 选择网站域名(主机记录): .com（对应设置“@”主机记录） 填写 IP（记录值）： 在输入框里粘贴以下四行（每一行一个 IP）： &gt; 185.199.109.153 &gt; 185.199.108.153 &gt; 185.199.110.153 &gt; 185.199.111.153 B. 使用 www.goku72.com 作为主域名 记录类型 主机记录 记录值 说明 CNAME www &lt;github用户名&gt;.github.io. 指向你的 GitHub 用户页仓库 example aliyun: 选择业务需求: 将网站域名解析到另外的目标域名 选择网站域名(主机记录): www..com（对应设置“www”主机记录） 填写 IP（记录值）：&lt;github用户名&gt;.github.io. (最有有一个符号”.”) 4. 设置主题 cd my-blog/themes git clone -b master https://github.com/jerryc127/hexo-theme-butterfly.git butterfly 修改_config.yml: theme: butterfly hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 更多主题：https://hexo.io/themes/ 注： 如果AB两个方式都添加了，只需要在 Hexo 项目的 source/CNAME 文件中写 www..com，GitHub Pages 就会自动把 goku72.com 重定向过去，无需额外设置！ 后续换域名只需要：阿里云重新解析 + 修改 source/CNAME + 重新部署 Hexo，就能完成域名迁移。 有些主题可能需要下载插件","link":"/post/hexo-blog.html"},{"title":"Basic of linux drivers","text":"linux驱动相关基础知识 正文","link":"/post/linux-kernel-drivers.html"},{"title":"qspinlock","text":"qspinlock 是一种为现代多核系统设计的先进混合自旋锁。它巧妙地融合了两种经典锁的优点：既继承了票据锁（ticket lock）的公平性，又借鉴了 MCS 锁优异的可扩展性。 1. 传统spinlock： 多个等待的 CPU 核心中，谁先获得锁并无保证，存在公平性问题，同时缓存一致性开销大（如MESI），CPU核心越大，cache需求越厉害，缺乏可扩展性 2. Ticket spinlock1234567891011121314151617#define TICKET_NEXT 16typedef struct { union { u32 lock; struct __raw_tickets { /* little endian */ u16 owner; u16 next; } tickets; };} arch_spinlock_t;my_ticket = atomic_fetch_inc(&amp;lock-&gt;tickets.next);while (lock-&gt;tickets.owner != my_ticket) cpu_relax(); 解决了公平问题，防止某些 CPU 永远得不到锁，但所有核都轮询同一个owner变量，read cache line成热点，限制扩展性 3. MCS lock 本质上是一种基于链表结构的自旋锁，每个CPU有一个对应的节点(锁的副本)，基于各自不同的副本变量进行等待，锁本身是共享的，但队列节点是线程自己维护的，每个CPU只需要查询自己对应的本地cache line，仅在这个变量发生变化的时候，才需要读取内存和刷新这条cache line, 不像 classic/ticket对共享变量进行spin 123456789101112131415161718192021222324struct mcs_spinlock { struct mcs_spinlock *next; int locked; /* 1 if lock acquired */ int count; /* nesting count, see qspinlock.c */};static inlinevoid mcs_spin_lock(struct mcs_spinlock **lock, struct mcs_spinlock *node){ struct mcs_spinlock *prev; /* Init node */ node-&gt;locked = 0; node-&gt;next = NULL; prev = xchg(lock, node); if (likely(prev == NULL)) { return; } WRITE_ONCE(prev-&gt;next, node); /* Wait until the lock holder passes the lock down. */ arch_mcs_spin_lock_contended(&amp;node-&gt;locked);} 每个 CPU 线程创建的node 是独立的，每个线程都有自己的 node 实例。但是结构体中多了一个指针使结构体变大了，导致了“内存开销问题”：MCS 锁把竞争带来的 cache-line 抖动降低了，但牺牲了一些内存和部分结构管理的成本。 4. qspinlockinclude/asm-generic/qspinlock_types.h: 锁数据结构 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758typedef struct qspinlock { union { atomic_t val; /* * By using the whole 2nd least significant byte for the * pending bit, we can allow better optimization of the lock * acquisition for the pending bit holder. */#ifdef __LITTLE_ENDIAN struct { u8 locked; u8 pending; }; struct { u16 locked_pending; u16 tail; };#else struct { u16 tail; u16 locked_pending; }; struct { u8 reserved[2]; u8 pending; u8 locked; };#endif };} arch_spinlock_t;/* * Initializier */#define __ARCH_SPIN_LOCK_UNLOCKED { { .val = ATOMIC_INIT(0) } }/* * Bitfields in the atomic value: * * When NR_CPUS &lt; 16K * 0- 7: locked byte * 8: pending * 9-15: not used * 16-17: tail index * 18-31: tail cpu (+1) * * When NR_CPUS &gt; = 16K * 0- 7: locked byte * 8: pending * 9-10: tail index * 11-31: tail cpu (+1) */#define _Q_SET_MASK(type) (((1U &lt;&lt; _Q_ ## type ## _BITS) - 1)\\&lt;&lt; _Q_ ## type ## _OFFSET)#define _Q_LOCKED_OFFSET 0#define _Q_LOCKED_BITS 8#define _Q_LOCKED_MASK _Q_SET_MASK(LOCKED) When NR_CPUS &lt; 16K： locked：用来表示这个锁是否被人持有（0：无，1：有） pending：可以理解为最优先持锁位，即当unlock之后只有这个位的CPU最先持锁，也有1和0 tail：有idx+CPU构成，用来标识等待队列的最后一个节点。 tail_idx：就是index，它作为mcs_nodes数组的下标使用 tail_CPU：用来表示CPU的编号+1，+1因为规定tail为0的时候表示等待队列中没有成员 kernel/locking/mcs_spinlock.h 12345struct mcs_spinlock { struct mcs_spinlock *next; int locked; /* 1 if lock acquired */ int count; /* nesting count, see qspinlock.c */}; locked = 1:只是说锁传到了当前加节点，但是当前节点还需要主动申请锁(qspinlock -&gt; locked = 1)count：针对四种上下文用于追踪当前用了第几个 node（即 idx），最大为4,不够用时就fallback不排队直接自旋 kernel/locking/qspinlock.c: 123456789101112131415161718#define MAX_NODES 4struct qnode { struct mcs_spinlock mcs;#ifdef CONFIG_PARAVIRT_SPINLOCKS long reserved[2];#endif};/* * Per-CPU queue node structures; we can never have more than 4 nested * contexts: task, softirq, hardirq, nmi. * * Exactly fits one 64-byte cacheline on a 64-bit architecture. * * PV doubles the storage and uses the second cacheline for PV state. */static DEFINE_PER_CPU_ALIGNED(struct qnode, qnodes[MAX_NODES]); 一个 CPU 上可能嵌套多个锁, qnodes针对四种上下文情况下，例：进程上下文中发生中断后再次获取锁 PER_CPU的优点是快，可防止抢锁时再mallock或临时分配导致延迟，成本等问题 申请锁： 快速申请include/asm-generic/qspinlock.h 12345678910111213/** * queued_spin_lock - acquire a queued spinlock * @lock: Pointer to queued spinlock structure */static __always_inline void queued_spin_lock(struct qspinlock *lock){ int val = 0; if (likely(atomic_try_cmpxchg_acquire(&amp;lock-&gt;val, &amp;val, _Q_LOCKED_VAL))) return; queued_spin_lock_slowpath(lock, val);} 中速申请 快速申请失败，queue中为空时，设置锁的pending位 再次检测（检查中间是否有其它cpu进入） 一直循环检测locked位 当locked位为0时，清除pending位获得锁 慢速申请 申请 操作 快速申请 这个锁当前没有人持有，直接通过cmpxchg()设置locked域即可获取了锁 中速申请 锁已经被人持有，但是MCS链表没有其他人，有且仅有一个人在等待这个锁。设置pending域，表示是第一顺位继承者，自旋等待lock-&gt; locked清0，即锁持有者释放锁 慢速申请 进入到queue中自旋等待，若为队列头（队列中没有等待的cpu），说明它已排到最前，可以开始尝试获取锁；否则，它会自旋等待前一个节点释放锁，并通知它可以尝试获取锁了 end: 如果只有1个或2个CPU试图获取锁，那么只需要一个4字节的qspinlock就可以了，其所占内存的大小和ticket spinlock一样。当有3个以上的CPU试图获取锁，则需要(N-2)个MCS node qspinlock中加入”pending”位域的意义，如果是两个CPU试图获取锁，那么第二个CPU只需要简单地设置”pending”为1，而不用创建一个MCS node 试图加锁的CPU数目超过3个，使用ticket spinlock机制就会造成多个CPU的cache line刷新的问题，而qspinlock可以利用MCS node队列来解决这个问题 在多核争用严重场景下，qspinlock 让等待者在本地内存区域自旋，减少了锁的缓存抖动和对总线的竞争消耗 RISCV_QUEUED_SPINLOCKS 只应在平台(RISC-V)具有 Zabha 或 Ziccrse 时启用，不支持的情况不要选用 优先级反转问题，queue会保证了FIFO提高了公平性，但它无法感知任务的优先级，可能因为排在队列前方的低优先级任务未释放锁而发生等待，从而导致 优先级反转","link":"/post/qspinlock.html"},{"title":"riscv toolchain","text":"在 RISC-V 开发中, 交叉编译工具链允许我们在一个平台（如 x86 主机）上，为另一个平台（如RISC-V 开发板）生成可执行代码。 1. 核心概念：工具链的“三元组” (Triplet)你经常会看到像 riscv64-unknown-linux-gnu- 这样的名称，这就是工具链的“三元组”，其标准格式为： 1&lt;arch&gt;-&lt;vendor&gt;-&lt;os&gt; &lt;arch&gt; (架构)：指定目标 CPU 架构，例如 riscv64 或 riscv32。 &lt;vendor&gt; (供应商)：通常是 unknown 或公司名。 &lt;os&gt; (操作系统/环境)：这是最关键的部分，它决定了工具链的目标环境和使用的 C 标准库 (libc)。最常见的两个是： elf: 面向裸机 (Bare-metal) 或嵌入式实时操作系统 (RTOS)。 linux-gnu: 面向完整的 GNU/Linux 操作系统。 2. 两大主流工具链详解1. riscv64-unknown-elf用于裸机和嵌入式开发的标准工具链。 目标系统: 没有任何操作系统的环境（裸机），或者使用了轻量级实时操作系统（如 FreeRTOS, RT-Thread）的环境。 C 标准库 (Libc): 使用 Newlib。 Newlib 是一个轻量级的 C 库，专为嵌入式系统设计。它只提供最基础的 C 语言函数（如 strcpy, printf），并且不依赖任何操作系统的系统调用（Syscall）。如果需要文件操作或内存管理，需要实现底层的“桩函数”(stubs)。 应用场景: 编写 Bootloader（如 U-Boot）。 开发 RISC-V 的“特权二进制接口”固件（如 OpenSBI）。 为微控制器 (MCU) 编写固件。 开发简单的操作系统内核。 2. riscv64-linux-gnu用于在 RISC-V 平台上开发 Linux 应用的工具链。 目标系统: 运行完整 Linux 内核的系统。 C 标准库 (Libc): 使用 glibc (GNU C Library)。 glibc 是功能完备的标准 C 库，提供了丰富的 POSIX API 支持（如 fork, pthread, 文件系统操作等）。它深度依赖 Linux 内核提供的系统调用来完成工作。 典型应用场景: 编译一个标准的 C/C++ 应用程序（如 Nginx, Redis），让它运行在 RISC-V 架构的 Linux 发行版上（如 Ubuntu, Debian for RISC-V）。 开发 Linux 用户态驱动或服务程序。 Tip: riscv64-unknown-linux-gnu- 和 riscv64-linux-gnu- 在功能上是等价的，可以互换使用。unknown 字段在这里没有实际影响。 3. 如何获取和安装工具链方式一：使用包管理器 (简单快捷)对于 linux-gnu 工具链，这是最简单的方法。以 Ubuntu/Debian 为例： 123# 安装 C 和 C++ 交叉编译器sudo apt updatesudo apt install gcc-riscv64-linux-gnu g++-riscv64-linux-gnu 优点: 安装简单 缺点: 版本可能不是最新的 方式二：从源码编译 (推荐，灵活且最新)获取最新版本工具链（包括 elf 和 linux-gnu）的最佳方式。 安装相关依赖 12sudo apt install libncurses-dev libncursesw5-dev pkg-config autoconf automake bison flex gawk gcc g++ libtool make patch python3-dev texinfo wgetsudo apt-get install autoconf automake autotools-dev curl libmpc-dev libmpfr-dev libgmp-dev gawk build-essential bison flex texinfo gperf libtool patchutils bc zlib1g-dev libexpat-dev make bison flex texinfo gawk libncurses5-dev libexpat1-dev libgmp-dev libmpfr-dev libmpc-dev libgmp-dev libmpfr-dev libmpc-dev 克隆官方仓库 123#`--recursive` 参数至关重要，它会同时下载 `gcc`, `binutils` 等所有子模块。git clone --recursive https://github.com/riscv-collab/riscv-gnu-toolchaincd riscv-gnu-toolchain 1234567* 检查当前子模块情况。git submodule status* 拉取子模块(init: 子模块未初始化时初始化，recursive: 嵌套子模块也一起拉取)* 主仓库换分支时同步子模块git submodule update --init --recursive 配置与编译需要指定安装路径 (--prefix) 和目标架构 (--with-arch, --with-abi)。 编译 linux-gnu 工具链 (用于Linux): 12345678# 创建安装目录mkdir -p /opt/riscv-linux# 配置: 目录，目标是为linux构建工具链./configure --prefix=/opt/riscv-linux --enable-linux# `make linux` 会自动处理多阶段编译的复杂流程（构建临时gcc-&gt;构建glibc-&gt;构建最终gcc）time make -j$(nproc) linux# 安装sudo make install 编译 elf 工具链 (用于裸机):riscv64-unknown-elf- 123456789# 创建一个安装目录mkdir -p /opt/riscv-elf# 配置: 其中 `rv64gc` 指支持 64 位基础整数指令集（I）、乘除法（M）、原子（A）、浮点（F、D）、压缩（C）等扩展；# `lp64d` 表示 long 和 pointer 为 64 位，使用 double 精度浮点。./configure --prefix=/opt/riscv-elf --with-arch=rv64gc --with-abi=lp64d# 编译 (-j`nproc` 使用所有CPU核心加速)time make -j$(nproc)# 安装sudo make install 添加到环境变量为了方便使用，将工具链的 bin 目录添加到 PATH。编辑 ~/.bashrc 或 ~/.zshrc 文件： 123456# 添加这行到文件末尾 (根据编译的类型选择)export PATH=&quot;/opt/riscv-elf/bin:$PATH&quot; # For elf toolchainexport PATH=&quot;/opt/riscv-linux/bin:$PATH&quot; # For linux toolchain# 使配置生效source ~/.bashrc 4. 简单使用1234567// hello.c#include &lt;stdio.h&gt;int main() { printf(&quot;Hello, RISC-V World!\\n&quot;); return 0;} 使用 elf 工具链编译1234567# 编译riscv64-unknown-elf-gcc -o hello.elf hello.c# 查看文件类型file hello.elf# 输出会类似:# hello.elf: ELF 64-bit LSB executable, UCB RISC-V, version 1 (SYSV), statically linked, not stripped 这个 hello.elf 是一个静态链接的裸机程序。它不能直接在 x86 Linux 主机上运行，也不能在 RISC-V Linux 系统上直接运行，因为它缺少操作系统加载器所需的信息。它需要被烧录到裸机环境或通过模拟器（如 QEMU-system）加载执行。 这个 hello.elf 文件虽然是标准的 ELF 格式，但它与 Linux 可执行文件有本质区别： 不含 INTERP 段：它不指定动态链接器，因为它不依赖任何动态库。 静态链接: 它静态链接了轻量级的 newlib C 库，而非 glibc。 无系统调用: 其中的 printf 函数最终依赖开发者实现的底层 I/O 桩函数（如通过 UART 发送字符），而不是 Linux 的 write 系统调用。 不同的程序入口: 它的启动代码 (_start) 负责初始化 C 运行环境后调用 main，但 main 返回后程序通常会进入死循环，因为它没有“退出”到操作系统的概念。 使用 linux-gnu 工具链编译1234567# 编译riscv64-linux-gnu-gcc -o hello.linux hello.c# 查看文件类型file hello.linux# 输出会类似:# hello.linux: ELF 64-bit LSB executable, UCB RISC-V, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux-riscv64-lp64d.so.1, for GNU/Linux 4.15.0, not stripped 这个 hello.linux 是一个动态链接的 Linux 程序。它需要一个 RISC-V Linux 环境来运行，因为它依赖于该环境中的动态链接器 (ld-linux-riscv64-lp64d.so.1) 和 glibc 库。 总结： 特性 riscv64-unknown-elf riscv64-linux-gnu 目标平台 裸机 (Bare-metal)、RTOS GNU/Linux 系统 C 库 newlib (轻量级，无 OS 依赖) glibc (功能完备，依赖 Linux 内核) 核心用途 固件、Bootloader、RTOS 应用、简单操作系统内核 编译可在 RISC-V Linux 上运行的应用程序 选择场景 “为一块开发板从零开始写程序。” “在启动的 Linux 上面运行软件。”","link":"/post/riscv-toolchains.html"},{"title":"the Three Basic Linux Driver Models","text":"按照读写存储数据方式，我们可以把设备分为以下几种：字符设备、块设备和网络设备。而Linux三大驱动就是指对这些设备的驱动，即字符设备、块设备驱动和网络设备驱动。 1. 字符设备 (Character Devices) 字符设备是一种按字节流（character stream）进行访问的设备，不可寻址，没有缓冲。你请求 5 个字节，它就给你 5 个字节（如果设备里有的话）。它不支持随机访问，数据只能顺序读写。 原理 核心： file_operations 结构体。里面定义了当用户空间程序对设备文件调用 open(), read(), write(), ioctl() 等系统调用时，内核应该执行的对应驱动函数。 VFS (虚拟文件系统)： 当 open(&quot;/dev/mydevice&quot;, ...) 时，VFS 会根据路径找到对应的 inode（索引节点），inode 中包含了设备号（主设备号和次设备号）。 驱动注册： 驱动在加载时，会通过 register_chrdev() 或 alloc_chrdev_region() + cdev_add() 来告诉内核能处理主设备号为 X 的设备，操作函数菜单是file_operations 结构体。 连接： VFS 通过主设备号找到驱动和 file_operations，然后调用实现的 my_open(), my_read() 等函数，从而将用户空间的操作连接到了驱动代码上。 典型例子： 串口 (/dev/ttyS*)、控制台 (/dev/console)、鼠标 (/dev/input/mouse0)、键盘 (/dev/input/event*)。 I2C/SPI 设备： 虽然挂在特定总线上，但最终给用户提供的接口往往是字符设备，如一个 I2C 接口的温湿度传感器，可能会表现为 /dev/i2c-1 或通过 sysfs 访问。 裸设备驱动： 各种自定义的、简单的控制类设备 代码示例 CLICK 2. 块设备 (Block Devices) 块设备是按“块”（Block）为单位进行数据访问的设备，块是固定大小的（如 512 字节、4KB）。与字符设备最大的不同是： 支持随机寻址它可以随机访问（直接读写第 N 个块），并且 有内核I/O缓冲区。 原理 核心： block_device_operations 结构体和 请求队列 (Request Queue)。 I/O 调度器： 当用户程序请求读写数据时，请求不会立即发送给硬件。而是被分解成一个个对“块”的操作请求（struct request），放入一个请求队列中。内核的 I/O 调度器 会对队列里的请求进行合并、排序，以提高磁盘寻道效率（比如把对相邻块的请求放在一起处理）。 缓冲/缓存 (Buffer Cache)： 内核会把频繁访问的块设备数据缓存在内存中（Page Cache/Buffer Cache）。当用户请求读取数据时，如果缓存里有，就直接从内存返回，速度极快，根本不需要访问物理设备。写操作也可能先写入缓存，稍后再“刷”到磁盘上。 驱动的角色： 块设备驱动的主要工作不是直接处理 read/write，而是从请求队列中取出已经由 I/O 调度器优化好的 request，然后根据 request 里的信息（起始块号、块数量、方向），操作硬件来完成真正的数据传输。 使用： 通常不直接用 read/write 对 /dev/sda 这样的裸设备进行操作（虽然也可以）。但更常见的用法是：在块设备上创建文件系统（mkfs.ext4 /dev/sda1），然后 mount 到一个目录上。之后，用户和程序就通过文件系统来访问，享受到了文件系统和块设备层共同带来的高效和便利。 典型例子： 硬盘 (HDD/SSD)(/dev/sda)、U盘 (/dev/sdb)、SD卡 (/dev/mmcblk0)、RAM disk（内存模拟的块设备）、Flash 存储 (通过 MTD): NAND/NOR Flash 在 MTD 层之上也可以表现为块设备。 代码示例 CLICK 3. 网络设备 (Network Devices) 网络设备是用于收发数据包（Packet）的设备。它和其他两类设备有本质区别，它不对应 /dev 目录下的文件节点。而是通过单独的网络接口来代表。 原理 核心： net_device_ops 结构体和 sk_buff (Socket Buffer)。 接口而非文件： 网络设备在内核中被抽象成一个接口（Interface），如 eth0, wlan0。用户空间程序通过 Socket API（socket(), bind(), sendto(), recvfrom()）等内核协议栈来与内核的 TCP/IP 协议栈交互，而不是操作设备文件。 数据流： 发送： 用户数据通过 Socket API 进入内核协议栈，被层层打包（加上 TCP/UDP 头、IP 头等），最终形成一个 sk_buff 结构体。这个 sk_buff 被交给网络设备驱动。驱动的 ndo_start_xmit 函数（定义在 net_device_ops 中）负责将 sk_buff 里的数据包通过物理网卡发送出去。 接收： 网卡收到一个数据包，产生硬件中断。驱动的中断处理程序把数据从硬件接收到内存，封装成一个新的 sk_buff，然后把它交给内核网络协议栈。协议栈逐层解包，最后通过 Socket 将数据送达正确的应用程序。 驱动的角色： 网络设备驱动是硬件和内核协议栈之间的“搬运工”，主要负责：初始化网卡、启动/停止数据收发、在 sk_buff 和硬件之间传递数据包。 典型例子： 有线网卡 (eth0, enp3s0)、无线网卡 (wlan0)虚拟网络接口、 CAN总线设备、 USB网络适配器。 代码示例 CLICK 对比 特性 字符设备 (Char) 块设备 (Block) 网络设备 (Net) 平台驱动 (Platform) 数据单位 字节流 (Stream) 数据块 (Block) 数据包 (Packet) 不直接处理数据流 访问方式 顺序访问 随机访问 Socket API N/A I/O 缓冲 无 (或很简单) 有内核缓冲/缓存和I/O调度 有 Socket 缓冲 N/A 用户接口 /dev 文件节点 /dev 文件节点, 文件系统 Socket 接口, ifconfig 通常是为其他驱动提供服务 核心结构体 file_operations block_device_operations net_device_ops platform_driver 核心机制 VFS 文件操作映射 请求队列和I/O调度 协议栈和sk_buff 设备与驱动的分离、匹配、探测 主要用途 简单、串行 I/O 设备 存储设备 网络通信 SoC 内部集成外设的管理框架 字符设备代码示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177#include &lt;linux/module.h&gt;#include &lt;linux/kernel.h&gt;#include &lt;linux/init.h&gt;#include &lt;linux/fs.h&gt; // 包含 file_operations 结构体#include &lt;linux/cdev.h&gt; // 包含 cdev 结构体和相关函数#include &lt;linux/device.h&gt; // 包含 class_create 和 device_create#include &lt;linux/uaccess.h&gt; // 包含 copy_to_user 和 copy_from_user#include &lt;linux/slab.h&gt; // 包含 kmalloc 和 kfree#define DEVICE_NAME &quot;mymem_char&quot;#define CLASS_NAME &quot;mymem_class&quot;#define MAX_BUFFER_SIZE 1024// --- 驱动核心数据结构 ---static int major_number; // 主设备号static char *kernel_buffer; // 内核数据缓冲区static struct class* my_class = NULL; // 设备类static struct cdev my_cdev; // 字符设备结构// --- file_operations 函数实现 ---// open 函数：当设备文件被打开时调用static int my_open(struct inode *inode, struct file *file){ printk(KERN_INFO &quot;MyCharDev: Device opened.\\n&quot;); // 通常可以在这里为每个打开实例分配私有数据 // file-&gt;private_data = ... return 0;}// release 函数：当设备文件被关闭时调用static int my_release(struct inode *inode, struct file *file){ printk(KERN_INFO &quot;MyCharDev: Device closed.\\n&quot;); // 清理 open 时分配的私有数据 // kfree(file-&gt;private_data); return 0;}// read 函数：从设备读取数据static ssize_t my_read(struct file *filp, char __user *user_buf, size_t len, loff_t *offset){ int bytes_to_read; // 检查读取长度是否有效 if (*offset &gt;= MAX_BUFFER_SIZE) return 0; // End of file if (*offset + len &gt; MAX_BUFFER_SIZE) len = MAX_BUFFER_SIZE - *offset; bytes_to_read = len; // 使用 copy_to_user 将内核数据拷贝到用户空间 if (copy_to_user(user_buf, kernel_buffer + *offset, bytes_to_read) != 0) { printk(KERN_ERR &quot;MyCharDev: Failed to copy data to user.\\n&quot;); return -EFAULT; } *offset += bytes_to_read; // 更新文件偏移 printk(KERN_INFO &quot;MyCharDev: Read %d bytes.\\n&quot;, bytes_to_read); return bytes_to_read;}// write 函数：向设备写入数据static ssize_t my_write(struct file *filp, const char __user *user_buf, size_t len, loff_t *offset){ int bytes_to_write; // 检查写入位置是否有效 if (*offset &gt;= MAX_BUFFER_SIZE) { printk(KERN_WARNING &quot;MyCharDev: No space left on device.\\n&quot;); return -ENOSPC; // No space left on device } if (*offset + len &gt; MAX_BUFFER_SIZE) len = MAX_BUFFER_SIZE - *offset; bytes_to_write = len; // 使用 copy_from_user 将用户数据拷贝到内核空间 if (copy_from_user(kernel_buffer + *offset, user_buf, bytes_to_write) != 0) { printk(KERN_ERR &quot;MyCharDev: Failed to copy data from user.\\n&quot;); return -EFAULT; } *offset += bytes_to_write; // 更新文件偏移 printk(KERN_INFO &quot;MyCharDev: Wrote %d bytes.\\n&quot;, bytes_to_write); return bytes_to_write;}// --- file_operations 结构体定义 ---// 将实现的函数与标准文件操作关联起来static struct file_operations fops = { .owner = THIS_MODULE, .open = my_open, .release = my_release, .read = my_read, .write = my_write,};// --- 模块初始化函数 ---static int __init memchar_init(void){ dev_t dev_num; // 1. 分配内核缓冲区 kernel_buffer = kmalloc(MAX_BUFFER_SIZE, GFP_KERNEL); if (!kernel_buffer) { printk(KERN_ERR &quot;MyCharDev: Failed to allocate kernel buffer.\\n&quot;); return -ENOMEM; } // 2. 动态分配主设备号 if (alloc_chrdev_region(&amp;dev_num, 0, 1, DEVICE_NAME) &lt; 0) { printk(KERN_ERR &quot;MyCharDev: Failed to allocate major number.\\n&quot;); kfree(kernel_buffer); return -1; } major_number = MAJOR(dev_num); printk(KERN_INFO &quot;MyCharDev: Major number allocated: %d\\n&quot;, major_number); // 3. 初始化 cdev 结构体，并与 file_operations 关联 cdev_init(&amp;my_cdev, &amp;fops); my_cdev.owner = THIS_MODULE; // 4. 将 cdev 添加到内核 if (cdev_add(&amp;my_cdev, dev_num, 1) &lt; 0) { printk(KERN_ERR &quot;MyCharDev: Failed to add cdev to the kernel.\\n&quot;); unregister_chrdev_region(dev_num, 1); kfree(kernel_buffer); return -1; } // 5. 创建设备类 my_class = class_create(THIS_MODULE, CLASS_NAME); if (IS_ERR(my_class)) { printk(KERN_ERR &quot;MyCharDev: Failed to create device class.\\n&quot;); cdev_del(&amp;my_cdev); unregister_chrdev_region(dev_num, 1); kfree(kernel_buffer); return PTR_ERR(my_class); } // 6. 创建设备文件 (/dev/mymem_char) if (device_create(my_class, NULL, dev_num, NULL, DEVICE_NAME) == NULL) { printk(KERN_ERR &quot;MyCharDev: Failed to create device file.\\n&quot;); class_destroy(my_class); cdev_del(&amp;my_cdev); unregister_chrdev_region(dev_num, 1); kfree(kernel_buffer); return -1; } printk(KERN_INFO &quot;MyCharDev: Driver loaded successfully.\\n&quot;); return 0;}// --- 模块卸载函数 ---static void __exit memchar_exit(void){ dev_t dev_num = MKDEV(major_number, 0); // 逆序清理资源 device_destroy(my_class, dev_num); // 销毁设备文件 class_destroy(my_class); // 销毁设备类 cdev_del(&amp;my_cdev); // 从内核移除 cdev unregister_chrdev_region(dev_num, 1); // 释放设备号 kfree(kernel_buffer); // 释放内核缓冲区 printk(KERN_INFO &quot;MyCharDev: Driver unloaded.\\n&quot;);}module_init(memchar_init);module_exit(memchar_exit);MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;Your Name&quot;);MODULE_DESCRIPTION(&quot;A simple character device driver for memory simulation.&quot;); 块设备代码示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128#include &lt;linux/module.h&gt;#include &lt;linux/kernel.h&gt;#include &lt;linux/init.h&gt;#include &lt;linux/genhd.h&gt; // 包含 gendisk#include &lt;linux/fs.h&gt; // 包含 block_device_operations#include &lt;linux/blkdev.h&gt; // 包含请求队列相关函数#include &lt;linux/vmalloc.h&gt; // 使用 vmalloc 分配大块内存#define DEVICE_NAME &quot;myram_block&quot;#define SECTOR_SIZE 512#define DEVICE_SECTORS 20480 // 10MB (20480 * 512 bytes)// --- 驱动核心数据结构 ---static int major_number; // 主设备号static u8 *device_data; // 模拟磁盘的内存区域static struct gendisk *my_disk; // gendisk 结构，代表一个独立的磁盘static struct request_queue *my_queue; // 请求队列static spinlock_t lock; // 用于保护请求队列的自旋锁// --- 请求处理函数 ---// 这是块设备驱动的核心，处理来自I/O调度器的请求static void my_request_fn(struct request_queue *q){ struct request *req; // 循环处理队列中的所有请求 while ((req = blk_fetch_request(q)) != NULL) { // 检查请求是否合法（这里简化处理，只检查读写请求） if (req == NULL || (rq_data_dir(req) != READ &amp;&amp; rq_data_dir(req) != WRITE)) { printk(KERN_NOTICE &quot;MyRamBlock: Skipping non-RW request\\n&quot;); __blk_end_request_all(req, -EIO); continue; } // 计算物理地址和大小 // blk_rq_pos(req) 返回起始扇区号 // blk_rq_cur_bytes(req) 返回请求的总字节数 unsigned long offset = blk_rq_pos(req) * SECTOR_SIZE; unsigned long num_bytes = blk_rq_cur_bytes(req); // 模拟数据传输 if (rq_data_dir(req) == WRITE) { // bio_for_each_segment 遍历请求中的所有段 (segment) // 将请求缓冲区中的数据拷贝到我们的模拟磁盘内存 memcpy(device_data + offset, bio_data(req-&gt;bio), num_bytes); } else { // 将模拟磁盘内存中的数据拷贝到请求缓冲区 memcpy(bio_data(req-&gt;bio), device_data + offset, num_bytes); } // 标记请求完成 __blk_end_request_all(req, 0); // 0 表示成功 }}// --- block_device_operations ---// 对于简单的驱动，这个结构体可以为空static struct block_device_operations my_bops = { .owner = THIS_MODULE,};// --- 模块初始化函数 ---static int __init ramblock_init(void){ // 1. 分配模拟磁盘的内存 device_data = vmalloc(DEVICE_SECTORS * SECTOR_SIZE); if (!device_data) { return -ENOMEM; } // 2. 注册块设备，获取主设备号 major_number = register_blkdev(0, DEVICE_NAME); if (major_number &lt; 0) { vfree(device_data); return major_number; } // 3. 初始化自旋锁和请求队列 spin_lock_init(&amp;lock); my_queue = blk_init_queue(my_request_fn, &amp;lock); if (!my_queue) { unregister_blkdev(major_number, DEVICE_NAME); vfree(device_data); return -ENOMEM; } // 4. 分配和初始化 gendisk 结构 my_disk = alloc_disk(1); // 1个次设备 (分区) if (!my_disk) { blk_cleanup_queue(my_queue); unregister_blkdev(major_number, DEVICE_NAME); vfree(device_data); return -ENOMEM; } // 5. 填充 gendisk 信息 my_disk-&gt;major = major_number; my_disk-&gt;first_minor = 0; my_disk-&gt;fops = &amp;my_bops; my_disk-&gt;queue = my_queue; snprintf(my_disk-&gt;disk_name, 32, DEVICE_NAME); set_capacity(my_disk, DEVICE_SECTORS); // 设置磁盘容量（以扇区为单位） // 6. 将 gendisk 添加到系统，使其可见 add_disk(my_disk); printk(KERN_INFO &quot;MyRamBlock: Driver loaded. Major: %d\\n&quot;, major_number); return 0;}// --- 模块卸载函数 ---static void __exit ramblock_exit(void){ del_gendisk(my_disk); // 从系统移除 gendisk put_disk(my_disk); // 释放 gendisk 引用 blk_cleanup_queue(my_queue); // 清理请求队列 unregister_blkdev(major_number, DEVICE_NAME); // 注销块设备 vfree(device_data); // 释放内存 printk(KERN_INFO &quot;MyRamBlock: Driver unloaded.\\n&quot;);}module_init(ramblock_init);module_exit(ramblock_exit);MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;Your Name&quot;);MODULE_DESCRIPTION(&quot;A simple RAM-based block device driver.&quot;); 网络设备代码示例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133#include &lt;linux/module.h&gt;#include &lt;linux/kernel.h&gt;#include &lt;linux/init.h&gt;#include &lt;linux/netdevice.h&gt; // 包含 net_device 和相关函数#include &lt;linux/etherdevice.h&gt; // 包含 alloc_etherdev#define DEVICE_NAME &quot;mynet&quot;// --- 驱动核心数据结构 ---// 我们将自定义的统计信息和设备指针放在一个结构体中struct mynet_priv { struct net_device_stats stats; struct net_device *dev;};static struct net_device *my_net_dev;// --- net_device_ops 函数实现 ---// open 函数：当接口被 &quot;ifconfig up&quot; 启动时调用static int mynet_open(struct net_device *dev){ // 启动传输队列 netif_start_queue(dev); printk(KERN_INFO &quot;%s: Device opened.\\n&quot;, dev-&gt;name); return 0;}// stop 函数：当接口被 &quot;ifconfig down&quot; 关闭时调用static int mynet_stop(struct net_device *dev){ // 停止传输队列 netif_stop_queue(dev); printk(KERN_INFO &quot;%s: Device stopped.\\n&quot;, dev-&gt;name); return 0;}// 发包函数：这是网络驱动的核心，负责发送数据包static netdev_tx_t mynet_start_xmit(struct sk_buff *skb, struct net_device *dev){ struct mynet_priv *priv = netdev_priv(dev); printk(KERN_INFO &quot;%s: Transmitting packet (len: %u)\\n&quot;, dev-&gt;name, skb-&gt;len); // 更新统计信息 priv-&gt;stats.tx_packets++; priv-&gt;stats.tx_bytes += skb-&gt;len; // --- 模拟环回 --- // 正常驱动会在这里把 skb 的数据通过 DMA 发送到硬件 // 我们直接将 skb 重新送回收包路径 skb-&gt;protocol = eth_type_trans(skb, dev); // 设置协议类型 skb-&gt;dev = dev; netif_rx(skb); // 将 skb 传递给内核协议栈的接收部分 // 告诉内核数据包已发送，可以释放 skb // dev_kfree_skb(skb); // 真实驱动中发送完会释放 skb // 但因为我们环回了，协议栈会负责释放它 return NETDEV_TX_OK; // 返回 OK 表示发送成功}// 获取统计信息函数static struct net_device_stats *mynet_get_stats(struct net_device *dev){ struct mynet_priv *priv = netdev_priv(dev); return &amp;priv-&gt;stats;}// --- net_device_ops 结构体定义 ---static const struct net_device_ops mynet_ops = { .ndo_open = mynet_open, .ndo_stop = mynet_stop, .ndo_start_xmit = mynet_start_xmit, .ndo_get_stats = mynet_get_stats,};// --- setup 函数，用于初始化设备 ---void mynet_setup(struct net_device *dev){ // 设置为以太网设备 ether_setup(dev); // 关联我们的操作函数 dev-&gt;netdev_ops = &amp;mynet_ops; // 分配一个随机的 MAC 地址 eth_hw_addr_random(dev); // 其他设备特性标志 dev-&gt;flags |= IFF_NOARP;}// --- 模块初始化函数 ---static int __init netloop_init(void){ struct mynet_priv *priv; // 1. 分配 net_device 结构体，并为私有数据分配空间 my_net_dev = alloc_netdev(sizeof(struct mynet_priv), DEVICE_NAME, NET_NAME_UNKNOWN, mynet_setup); if (!my_net_dev) { return -ENOMEM; } // 获取私有数据指针 priv = netdev_priv(my_net_dev); priv-&gt;dev = my_net_dev; // 2. 注册网络设备到内核 if (register_netdev(my_net_dev)) { printk(KERN_ERR &quot;Failed to register net device\\n&quot;); free_netdev(my_net_dev); return -1; } printk(KERN_INFO &quot;%s: Driver loaded.\\n&quot;, my_net_dev-&gt;name); return 0;}// --- 模块卸载函数 ---static void __exit netloop_exit(void){ printk(KERN_INFO &quot;%s: Unloading driver.\\n&quot;, my_net_dev-&gt;name); unregister_netdev(my_net_dev); // 从内核注销 free_netdev(my_net_dev); // 释放 net_device}module_init(netloop_init);module_exit(netloop_exit);MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;Your Name&quot;);MODULE_DESCRIPTION(&quot;A simple loopback network device driver.&quot;);","link":"/post/the-Three-Basic-Linux-Driver-Models.html"}],"tags":[{"name":"Toolchain","slug":"Toolchain","link":"/tags/Toolchain/"},{"name":"ebpf","slug":"ebpf","link":"/tags/ebpf/"},{"name":"kernel","slug":"kernel","link":"/tags/kernel/"},{"name":"driver","slug":"driver","link":"/tags/driver/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"lock","slug":"lock","link":"/tags/lock/"},{"name":"risc-v","slug":"risc-v","link":"/tags/risc-v/"}],"categories":[{"name":"note","slug":"note","link":"/categories/note/"},{"name":"kernel","slug":"kernel","link":"/categories/kernel/"},{"name":"dirver","slug":"dirver","link":"/categories/dirver/"},{"name":"blog","slug":"blog","link":"/categories/blog/"},{"name":"compiler","slug":"note/compiler","link":"/categories/note/compiler/"},{"name":"qspinlock","slug":"kernel/qspinlock","link":"/categories/kernel/qspinlock/"},{"name":"ebpf","slug":"kernel/ebpf","link":"/categories/kernel/ebpf/"},{"name":"risc-v","slug":"risc-v","link":"/categories/risc-v/"},{"name":"driver","slug":"kernel/driver","link":"/categories/kernel/driver/"},{"name":"hexo","slug":"blog/hexo","link":"/categories/blog/hexo/"},{"name":"Toolchain","slug":"risc-v/Toolchain","link":"/categories/risc-v/Toolchain/"}],"pages":[{"title":"","text":"Troy's Blog >>> 欢迎交换友链~ 请通过邮件联系我。","link":"/friend/index.html"}]}