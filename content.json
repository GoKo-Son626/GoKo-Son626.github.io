{"posts":[{"title":"hexo博客搭建","text":"使用hexo和GitHub Pagtes部署一个自己的博客 1. 安装并初始化Hexo 安装 Hexo CLI 1npm install -g hexo-cli 初始化博客项目目录 123mkdir my-blog &amp;&amp; cd my-bloghexo initnpm install 本地预览 1hexo server 启动本地服务：在浏览器访问 http://localhost:4000 查看效果 2. 配置 GitHub Pages 部署 创建GitHub仓库 创建一个仓库，名字叫 你的GitHub用户名.github.io 比如你是 goko，就叫 goko.github.io 安装部署插件 1npm install hexo-deployer-git --save 修改 _config.yml（根目录下）添加部署配置： 12345deploy: type: git # repo建议使用SSH, SSH免密 repo: https://github.com/你的GitHub用户名/你的GitHub用户名.github.io.git branch: main # 或者 master，看你的默认分支 生成并部署博客 123hexo cleanhexo generatehexo deploy 3. 域名(.com)绑定 添加域名(在my-blog下) 123echo &quot;&lt;xxxx&gt;.com&quot; &gt; source/CNAME# 或者可以：echo &quot;www.&lt;xxxx&gt;.com&quot; &gt; source/CNAME# 只能添加一个，而且两个需要添加不同的域名解析（如下） 重新部署 1hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 设置 DNS 解析指向 GitHub Pages A. 使用裸域名（apex 域名）goku72.com 记录类型 主机记录 记录值 说明 A @ 185.199.108.153 GitHub Pages IP A @ 185.199.109.153 GitHub Pages IP A @ 185.199.110.153 GitHub Pages IP A @ 185.199.111.153 GitHub Pages IP example aliyun: 选择业务需求: 将网站域名解析到服务器IPv4地址 选择网站域名(主机记录): .com（对应设置“@”主机记录） 填写 IP（记录值）： 在输入框里粘贴以下四行（每一行一个 IP）： &gt; 185.199.109.153 &gt; 185.199.108.153 &gt; 185.199.110.153 &gt; 185.199.111.153 B. 使用 www.goku72.com 作为主域名 记录类型 主机记录 记录值 说明 CNAME www &lt;github用户名&gt;.github.io. 指向你的 GitHub 用户页仓库 example aliyun: 选择业务需求: 将网站域名解析到另外的目标域名 选择网站域名(主机记录): www..com（对应设置“www”主机记录） 填写 IP（记录值）：&lt;github用户名&gt;.github.io. (最有有一个符号”.”) 4. 设置主题 cd my-blog/themes git clone -b master https://github.com/jerryc127/hexo-theme-butterfly.git butterfly 修改_config.yml: theme: butterfly hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 更多主题：https://hexo.io/themes/ 注： 如果AB两个方式都添加了，只需要在 Hexo 项目的 source/CNAME 文件中写 www..com，GitHub Pages 就会自动把 goku72.com 重定向过去，无需额外设置！ 后续换域名只需要：阿里云重新解析 + 修改 source/CNAME + 重新部署 Hexo，就能完成域名迁移。 有些主题可能需要下载插件","link":"/post/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA.html"},{"title":"qspinlock","text":"qspinlock is a hybrid spinlock combining the fairness of ticket locks with the scalability of MCS locks: it uses only 4 bytes under low contention, falls back to an MCS queue under heavy load, and optimizes the second contender with a pending bit. It improves fairness and scalability but should not be enabled on RISC-V platforms lacking Ziccrse or Zabha. 1. 传统spinlock： 多个等待的 CPU 核心中，谁先获得锁并无保证，存在公平性问题，同时缓存一致性开销大（如MESI），CPU核心越大，cache需求越厉害，缺乏可扩展性 2. Ticket spinlock1234567891011121314151617#define TICKET_NEXT 16typedef struct { union { u32 lock; struct __raw_tickets { /* little endian */ u16 owner; u16 next; } tickets; };} arch_spinlock_t;my_ticket = atomic_fetch_inc(&amp;lock-&gt;tickets.next); while (lock-&gt;tickets.owner != my_ticket) cpu_relax(); 解决了公平问题，防止某些 CPU 永远得不到锁，但所有核都轮询同一个owner变量，read cache line成热点，限制扩展性 3. MCS lock 本质上是一种基于链表结构的自旋锁，每个CPU有一个对应的节点(锁的副本)，基于各自不同的副本变量进行等待，锁本身是共享的，但队列节点是线程自己维护的，每个CPU只需要查询自己对应的本地cache line，仅在这个变量发生变化的时候，才需要读取内存和刷新这条cache line, 不像 classic/ticket对共享变量进行spin 123456789101112131415161718192021222324struct mcs_spinlock { struct mcs_spinlock *next; int locked; /* 1 if lock acquired */ int count; /* nesting count, see qspinlock.c */};static inlinevoid mcs_spin_lock(struct mcs_spinlock **lock, struct mcs_spinlock *node){ struct mcs_spinlock *prev; /* Init node */ node-&gt;locked = 0; node-&gt;next = NULL; prev = xchg(lock, node); if (likely(prev == NULL)) { return; } WRITE_ONCE(prev-&gt;next, node); /* Wait until the lock holder passes the lock down. */ arch_mcs_spin_lock_contended(&amp;node-&gt;locked);} 每个 CPU 线程创建的node 是独立的，每个线程都有自己的 node 实例。但是结构体中多了一个指针使结构体变大了，导致了“内存开销问题”：MCS 锁把竞争带来的 cache-line 抖动降低了，但牺牲了一些内存和部分结构管理的成本。 4. qspinlockinclude/asm-generic/qspinlock_types.h: 锁数据结构 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758typedef struct qspinlock { union { atomic_t val; /* * By using the whole 2nd least significant byte for the * pending bit, we can allow better optimization of the lock * acquisition for the pending bit holder. */#ifdef __LITTLE_ENDIAN struct { u8 locked; u8 pending; }; struct { u16 locked_pending; u16 tail; };#else struct { u16 tail; u16 locked_pending; }; struct { u8 reserved[2]; u8 pending; u8 locked; };#endif };} arch_spinlock_t;/* * Initializier */#define __ARCH_SPIN_LOCK_UNLOCKED { { .val = ATOMIC_INIT(0) } }/* * Bitfields in the atomic value: * * When NR_CPUS &lt; 16K * 0- 7: locked byte * 8: pending * 9-15: not used * 16-17: tail index * 18-31: tail cpu (+1) * * When NR_CPUS &gt; = 16K * 0- 7: locked byte * 8: pending * 9-10: tail index * 11-31: tail cpu (+1) */#define _Q_SET_MASK(type) (((1U &lt;&lt; _Q_ ## type ## _BITS) - 1)\\ &lt;&lt; _Q_ ## type ## _OFFSET)#define _Q_LOCKED_OFFSET 0#define _Q_LOCKED_BITS 8#define _Q_LOCKED_MASK _Q_SET_MASK(LOCKED) When NR_CPUS &lt; 16K： locked：用来表示这个锁是否被人持有（0：无，1：有） pending：可以理解为最优先持锁位，即当unlock之后只有这个位的CPU最先持锁，也有1和0 tail：有idx+CPU构成，用来标识等待队列的最后一个节点。 tail_idx：就是index，它作为mcs_nodes数组的下标使用 tail_CPU：用来表示CPU的编号+1，+1因为规定tail为0的时候表示等待队列中没有成员 kernel/locking/mcs_spinlock.h 12345struct mcs_spinlock { struct mcs_spinlock *next; int locked; /* 1 if lock acquired */ int count; /* nesting count, see qspinlock.c */}; locked = 1:只是说锁传到了当前加节点，但是当前节点还需要主动申请锁(qspinlock -&gt; locked = 1)count：针对四种上下文用于追踪当前用了第几个 node（即 idx），最大为4,不够用时就fallback不排队直接自旋 kernel/locking/qspinlock.c: 123456789101112131415161718#define MAX_NODES 4struct qnode { struct mcs_spinlock mcs;#ifdef CONFIG_PARAVIRT_SPINLOCKS long reserved[2];#endif};/* * Per-CPU queue node structures; we can never have more than 4 nested * contexts: task, softirq, hardirq, nmi. * * Exactly fits one 64-byte cacheline on a 64-bit architecture. * * PV doubles the storage and uses the second cacheline for PV state. */static DEFINE_PER_CPU_ALIGNED(struct qnode, qnodes[MAX_NODES]); 一个 CPU 上可能嵌套多个锁, qnodes针对四种上下文情况下，例：进程上下文中发生中断后再次获取锁 PER_CPU的优点是快，可防止抢锁时再mallock或临时分配导致延迟，成本等问题 申请锁： 快速申请include/asm-generic/qspinlock.h 12345678910111213/** * queued_spin_lock - acquire a queued spinlock * @lock: Pointer to queued spinlock structure */static __always_inline void queued_spin_lock(struct qspinlock *lock){ int val = 0; if (likely(atomic_try_cmpxchg_acquire(&amp;lock-&gt;val, &amp;val, _Q_LOCKED_VAL))) return; queued_spin_lock_slowpath(lock, val);} 中速申请 快速申请失败，queue中为空时，设置锁的pending位 再次检测（检查中间是否有其它cpu进入） 一直循环检测locked位 当locked位为0时，清除pending位获得锁 慢速申请 申请 操作 快速申请 这个锁当前没有人持有，直接通过cmpxchg()设置locked域即可获取了锁 中速申请 锁已经被人持有，但是MCS链表没有其他人，有且仅有一个人在等待这个锁。设置pending域，表示是第一顺位继承者，自旋等待lock-&gt; locked清0，即锁持有者释放锁 慢速申请 进入到queue中自旋等待，若为队列头（队列中没有等待的cpu），说明它已排到最前，可以开始尝试获取锁；否则，它会自旋等待前一个节点释放锁，并通知它可以尝试获取锁了 end: 如果只有1个或2个CPU试图获取锁，那么只需要一个4字节的qspinlock就可以了，其所占内存的大小和ticket spinlock一样。当有3个以上的CPU试图获取锁，则需要(N-2)个MCS node qspinlock中加入”pending”位域的意义，如果是两个CPU试图获取锁，那么第二个CPU只需要简单地设置”pending”为1，而不用创建一个MCS node 试图加锁的CPU数目超过3个，使用ticket spinlock机制就会造成多个CPU的cache line刷新的问题，而qspinlock可以利用MCS node队列来解决这个问题 在多核争用严重场景下，qspinlock 让等待者在本地内存区域自旋，减少了锁的缓存抖动和对总线的竞争消耗 RISCV_QUEUED_SPINLOCKS 只应在平台具有 Zabha 或 Ziccrse 时启用，不支持的情况不要选用 优先级反转问题，queue会保证了FIFO提高了公平性，但它无法感知任务的优先级，可能因为排在队列前方的低优先级任务未释放锁而发生等待，从而导致 优先级反转","link":"/post/qspinlock.html"},{"title":"start-kerneling","text":"前言介绍….","link":"/post/start-kerneling.html"},{"title":"riscv-toolchains","text":"riscv-toolchain介绍 GNU 工具链的三元组（triplet），格式是： 1&lt;目标架构&gt;-&lt;供应商&gt;-&lt;目标系统&gt; riscv64-unknown-elf-： 适用于 riscv64 架构、面向嵌入式/裸机平台（使用 newlib 标准库）的工具链。 可从 riscv-collab/riscv-gnu-toolchain 构建。 不推荐通过包管理工具安装此编译链。发行版软件源中的此工具链常常缺少关键的 newlib 标准库。riscv64-unknown-linux-gnu-： 适用于 riscv64 架构、面向 linux-gnu 平台（使用 glibc 标准库）的工具链，可以与riscv64-linux-gnu- 相互替换。可从 riscv-collab/riscv-gnu-toolchain 构建。riscv64-linux-gnu-： 适用于 riscv64 架构、面向 linux-gnu 平台（使用 glibc 标准库）的工具链。 可通过包管理工具（如 Ubuntu 的 apt）安装。受限于发行版软件源限制，其编译器版本可能较老。","link":"/post/riscv-toolchains.html"}],"tags":[{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"riscv","slug":"riscv","link":"/tags/riscv/"},{"name":"kernel-start","slug":"kernel-start","link":"/tags/kernel-start/"},{"name":"riscv-toolchain","slug":"riscv-toolchain","link":"/tags/riscv-toolchain/"}],"categories":[],"pages":[{"title":"","text":"Troy's Blog >>> 欢迎交换友链~ 请通过邮件联系我。","link":"/friend/index.html"}]}