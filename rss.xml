<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>GoKo&#39;s blog</title>
    <link>https://GoKo-Son626.github.io/</link>
    
    <atom:link href="https://goko-son626.github.io/rss.xml" rel="self" type="application/rss+xml"/>
    
    <description></description>
    <pubDate>Mon, 12 May 2025 13:41:10 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>qspinlock</title>
      <link>https://goko-son626.github.io/post/qspinlock.html</link>
      <guid>https://goko-son626.github.io/post/qspinlock.html</guid>
      <pubDate>Sat, 03 May 2025 01:25:24 GMT</pubDate>
      
      <description>&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;qspinlock is a hybrid spinlock combining the fairness of ticket locks with the scalability of MCS locks: it uses only 4 bytes under low contention, falls back to an MCS queue under heavy load, and optimizes the second contender with a pending bit. It improves fairness and scalability but should not be enabled on RISC-V platforms lacking Ziccrse or Zabha.&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      
      
      
      <content:encoded><![CDATA[<ul><li><em><strong>qspinlock is a hybrid spinlock combining the fairness of ticket locks with the scalability of MCS locks: it uses only 4 bytes under low contention, falls back to an MCS queue under heavy load, and optimizes the second contender with a pending bit. It improves fairness and scalability but should not be enabled on RISC-V platforms lacking Ziccrse or Zabha.</strong></em></li></ul><span id="more"></span><h4 id="1-传统spinlock："><a href="#1-传统spinlock：" class="headerlink" title="1. 传统spinlock："></a>1. 传统spinlock：</h4><ul><li>多个等待的 CPU 核心中，谁先获得锁并无保证，存在公平性问题，同时缓存一致性开销大（如MESI），CPU核心越大，cache需求越厉害，缺乏可扩展性</li></ul><p><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/spinlock/image-8.png" alt="alt text"></p><h4 id="2-Ticket-spinlock"><a href="#2-Ticket-spinlock" class="headerlink" title="2. Ticket spinlock"></a>2. Ticket spinlock</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TICKET_NEXT16</span><br><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br><span class="hljs-class"><span class="hljs-keyword">union</span> &#123;</span><br>u32 lock;<br><span class="hljs-class"><span class="hljs-keyword">struct</span> __<span class="hljs-title">raw_tickets</span> &#123;</span><br><span class="hljs-comment">/* little endian */</span><br>u16 owner;<br>u16 next;<br>&#125; tickets;<br>&#125;;<br>&#125; <span class="hljs-type">arch_spinlock_t</span>;<br><br>my_ticket = atomic_fetch_inc(&amp;lock-&gt;tickets.next);<br><br> <span class="hljs-keyword">while</span> (lock-&gt;tickets.owner != my_ticket)<br>    cpu_relax();<br></code></pre></td></tr></table></figure><ul><li>解决了公平问题，防止某些 CPU 永远得不到锁，但所有核都轮询同一个owner变量，read cache line成热点，限制扩展性</li></ul><h4 id="3-MCS-lock"><a href="#3-MCS-lock" class="headerlink" title="3. MCS lock"></a>3. MCS lock</h4><ul><li>本质上是一种基于链表结构的自旋锁，每个CPU有一个对应的节点(锁的副本)，基于各自不同的副本变量进行等待，锁本身是共享的，但队列节点是线程自己维护的，每个CPU只需要查询自己对应的本地cache line，仅在这个变量发生变化的时候，才需要读取内存和刷新这条cache line, 不像 classic&#x2F;ticket对共享变量进行spin</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mcs_spinlock</span> &#123;</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mcs_spinlock</span> *<span class="hljs-title">next</span>;</span><br><span class="hljs-type">int</span> locked; <span class="hljs-comment">/* 1 if lock acquired */</span><br><span class="hljs-type">int</span> count;  <span class="hljs-comment">/* nesting count, see qspinlock.c */</span><br>&#125;;<br><br><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">mcs_spin_lock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> mcs_spinlock **lock, <span class="hljs-keyword">struct</span> mcs_spinlock *node)</span><br>&#123;<br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mcs_spinlock</span> *<span class="hljs-title">prev</span>;</span><br><br><span class="hljs-comment">/* Init node */</span><br>node-&gt;locked = <span class="hljs-number">0</span>;<br>node-&gt;next   = <span class="hljs-literal">NULL</span>;<br><br>prev = xchg(lock, node);<br><span class="hljs-keyword">if</span> (likely(prev == <span class="hljs-literal">NULL</span>)) &#123;<br><span class="hljs-keyword">return</span>;<br>&#125;<br>WRITE_ONCE(prev-&gt;next, node);<br><br><span class="hljs-comment">/* Wait until the lock holder passes the lock down. */</span><br>arch_mcs_spin_lock_contended(&amp;node-&gt;locked);<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>每个 CPU 线程创建的node 是独立的，每个线程都有自己的 node 实例。但是结构体中多了一个指针使结构体变大了，导致了“内存开销问题”：MCS 锁把竞争带来的 cache-line 抖动降低了，但牺牲了一些内存和部分结构管理的成本。</li></ul><h4 id="4-qspinlock"><a href="#4-qspinlock" class="headerlink" title="4. qspinlock"></a>4. qspinlock</h4><p><strong>include&#x2F;asm-generic&#x2F;qspinlock_types.h:</strong> 锁数据结构</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">qspinlock</span> &#123;</span><br>        <span class="hljs-class"><span class="hljs-keyword">union</span> &#123;</span><br>                <span class="hljs-type">atomic_t</span> val;<br><br>                <span class="hljs-comment">/*</span><br><span class="hljs-comment">                 * By using the whole 2nd least significant byte for the</span><br><span class="hljs-comment">                 * pending bit, we can allow better optimization of the lock</span><br><span class="hljs-comment">                 * acquisition for the pending bit holder.</span><br><span class="hljs-comment">                 */</span><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> __LITTLE_ENDIAN</span><br>                <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br>                        u8      locked;<br>                        u8      pending;<br>                &#125;;<br>                <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br>                        u16     locked_pending;<br>                        u16     tail;<br>                &#125;;<br><span class="hljs-meta">#<span class="hljs-keyword">else</span></span><br>                <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br>                        u16     tail;<br>                        u16     locked_pending;<br>                &#125;;<br>                <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br>                        u8      reserved[<span class="hljs-number">2</span>];<br>                        u8      pending;<br>                        u8      locked;<br>                &#125;;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>        &#125;;<br>&#125; <span class="hljs-type">arch_spinlock_t</span>;<br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * Initializier</span><br><span class="hljs-comment"> */</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> __ARCH_SPIN_LOCK_UNLOCKED       &#123; &#123; .val = ATOMIC_INIT(0) &#125; &#125;</span><br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * Bitfields in the atomic value:</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * When NR_CPUS &lt; 16K</span><br><span class="hljs-comment"> *  0- 7: locked byte</span><br><span class="hljs-comment"> *     8: pending</span><br><span class="hljs-comment"> *  9-15: not used</span><br><span class="hljs-comment"> * 16-17: tail index</span><br><span class="hljs-comment"> * 18-31: tail cpu (+1)</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * When NR_CPUS &gt; = 16K</span><br><span class="hljs-comment"> *  0- 7: locked byte</span><br><span class="hljs-comment"> *     8: pending</span><br><span class="hljs-comment"> *  9-10: tail index</span><br><span class="hljs-comment"> * 11-31: tail cpu (+1)</span><br><span class="hljs-comment"> */</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _Q_SET_MASK(type)       (((1U &lt;&lt; _Q_ ## type ## _BITS) - 1)\</span><br><span class="hljs-meta">                                      &lt;&lt; _Q_ ## type ## _OFFSET)</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _Q_LOCKED_OFFSET        0</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _Q_LOCKED_BITS          8</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> _Q_LOCKED_MASK          _Q_SET_MASK(LOCKED)</span><br></code></pre></td></tr></table></figure><p><strong>When NR_CPUS &lt; 16K：</strong><br><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/spinlock/image-7.png" alt="alt text"></p><ul><li><code>locked</code>：用来表示这个锁是否被人持有（0：无，1：有）</li><li><code>pending</code>：可以理解为最优先持锁位，即当unlock之后只有这个位的CPU最先持锁，也有1和0</li><li><code>tail</code>：有idx+CPU构成，用来标识等待队列的最后一个节点。</li><li><code>tail_idx</code>：就是index，它作为mcs_nodes数组的下标使用</li><li><code>tail_CPU</code>：用来表示CPU的编号+1，+1因为规定tail为0的时候表示等待队列中没有成员</li></ul><p><strong>kernel&#x2F;locking&#x2F;mcs_spinlock.h</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mcs_spinlock</span> &#123;</span><br>        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mcs_spinlock</span> *<span class="hljs-title">next</span>;</span><br>        <span class="hljs-type">int</span> locked; <span class="hljs-comment">/* 1 if lock acquired */</span><br>        <span class="hljs-type">int</span> count;  <span class="hljs-comment">/* nesting count, see qspinlock.c */</span><br>&#125;;<br></code></pre></td></tr></table></figure><p><code>locked = 1</code>:只是说锁传到了当前加节点，但是当前节点还需要主动申请锁(qspinlock -&gt; locked &#x3D; 1)<br><code>count</code>：针对四种上下文用于追踪当前用了第几个 node（即 idx），最大为4,不够用时就fallback不排队直接自旋</p><p><strong>kernel&#x2F;locking&#x2F;qspinlock.c:</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> MAX_NODES       4</span><br><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">qnode</span> &#123;</span><br>        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mcs_spinlock</span> <span class="hljs-title">mcs</span>;</span><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> CONFIG_PARAVIRT_SPINLOCKS</span><br>        <span class="hljs-type">long</span> reserved[<span class="hljs-number">2</span>];<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>&#125;;<br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * Per-CPU queue node structures; we can never have more than 4 nested</span><br><span class="hljs-comment"> * contexts: task, softirq, hardirq, nmi.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Exactly fits one 64-byte cacheline on a 64-bit architecture.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * PV doubles the storage and uses the second cacheline for PV state.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> <span class="hljs-title function_">DEFINE_PER_CPU_ALIGNED</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> qnode, qnodes[MAX_NODES])</span>;<br></code></pre></td></tr></table></figure><ul><li>一个 CPU 上可能嵌套多个锁, <code>qnodes</code>针对四种上下文情况下，例：进程上下文中发生中断后再次获取锁</li><li>PER_CPU的优点是快，可防止抢锁时再mallock或临时分配导致延迟，成本等问题</li></ul><p><strong>申请锁：</strong></p><ol><li>快速申请<br><strong>include&#x2F;asm-generic&#x2F;qspinlock.h</strong></li></ol><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * queued_spin_lock - acquire a queued spinlock</span><br><span class="hljs-comment"> * @lock: Pointer to queued spinlock structure</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> __always_inline <span class="hljs-type">void</span> <span class="hljs-title function_">queued_spin_lock</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> qspinlock *lock)</span><br>&#123;<br><span class="hljs-type">int</span> val = <span class="hljs-number">0</span>;<br><br><span class="hljs-keyword">if</span> (likely(atomic_try_cmpxchg_acquire(&amp;lock-&gt;val, &amp;val, _Q_LOCKED_VAL)))<br><span class="hljs-keyword">return</span>;<br><br>queued_spin_lock_slowpath(lock, val);<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/spinlock/image-9.png" alt="alt text"></p><ol start="2"><li>中速申请</li></ol><ul><li>快速申请失败，queue中为空时，设置锁的pending位</li><li>再次检测（检查中间是否有其它cpu进入）</li><li>一直循环检测locked位</li><li>当locked位为0时，清除pending位获得锁</li></ul><p><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/spinlock/image-11.png" alt="alt text"></p><ol start="3"><li>慢速申请</li></ol><p><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/spinlock/image-12.png" alt="alt text"></p><table><thead><tr><th>申请</th><th>操作</th></tr></thead><tbody><tr><td>快速申请</td><td>这个锁当前没有人持有，直接通过cmpxchg()设置locked域即可获取了锁</td></tr><tr><td>中速申请</td><td>锁已经被人持有，但是MCS链表没有其他人，有且仅有一个人在等待这个锁。设置pending域，表示是第一顺位继承者，自旋等待lock-&gt; locked清0，即锁持有者释放锁</td></tr><tr><td>慢速申请</td><td>进入到queue中自旋等待，若为队列头（队列中没有等待的cpu），说明它已排到最前，可以开始尝试获取锁；否则，它会自旋等待前一个节点释放锁，并通知它可以尝试获取锁了</td></tr></tbody></table><p><strong>end:</strong></p><ul><li><p>如果只有1个或2个CPU试图获取锁，那么只需要一个4字节的qspinlock就可以了，其所占内存的大小和ticket spinlock一样。当有3个以上的CPU试图获取锁，则需要(N-2)个MCS node</p></li><li><p>qspinlock中加入”pending”位域的意义，如果是两个CPU试图获取锁，那么第二个CPU只需要简单地设置”pending”为1，而不用创建一个MCS node</p></li><li><p>试图加锁的CPU数目超过3个，使用ticket spinlock机制就会造成多个CPU的cache line刷新的问题，而qspinlock可以利用MCS node队列来解决这个问题</p></li><li><p>在多核争用严重场景下，qspinlock 让等待者在本地内存区域自旋，减少了锁的缓存抖动和对总线的竞争消耗</p></li><li><p>RISCV_QUEUED_SPINLOCKS 只应在平台具有 Zabha 或 Ziccrse 时启用，不支持的情况不要选用</p></li><li><p>优先级反转问题，queue会保证了FIFO提高了公平性，但它无法感知任务的优先级，可能因为排在队列前方的低优先级任务未释放锁而发生等待，从而导致 优先级反转</p></li></ul>]]></content:encoded>
      
      
      
      <category domain="https://GoKo-Son626.github.io/tags/riscv/">riscv</category>
      
      
      <comments>https://goko-son626.github.io/post/qspinlock.html#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>hexo博客搭建</title>
      <link>https://goko-son626.github.io/post/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA.html</link>
      <guid>https://goko-son626.github.io/post/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA.html</guid>
      <pubDate>Thu, 01 May 2025 05:25:09 GMT</pubDate>
      
      <description>&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;使用hexo和GitHub Pagtes部署一个自己的博客&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      
      
      
      <content:encoded><![CDATA[<ul><li><em><strong>使用hexo和GitHub Pagtes部署一个自己的博客</strong></em></li></ul><span id="more"></span><h3 id="1-安装并初始化Hexo"><a href="#1-安装并初始化Hexo" class="headerlink" title="1. 安装并初始化Hexo"></a>1. 安装并初始化Hexo</h3><ul><li><ol><li>安装 Hexo CLI</li></ol></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">npm install -g hexo-cli<br></code></pre></td></tr></table></figure><ul><li><ol start="2"><li>初始化博客项目目录</li></ol></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">mkdir my-blog &amp;&amp; cd my-blog<br>hexo init<br>npm install<br></code></pre></td></tr></table></figure><ul><li><ol start="3"><li>本地预览</li></ol></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">hexo server<br></code></pre></td></tr></table></figure><ul><li>启动本地服务：在浏览器访问 <a href="http://localhost:4000/">http://localhost:4000</a> 查看效果</li></ul><h3 id="2-配置-GitHub-Pages-部署"><a href="#2-配置-GitHub-Pages-部署" class="headerlink" title="2.  配置 GitHub Pages 部署"></a>2.  配置 GitHub Pages 部署</h3><ul><li><ol><li>创建GitHub仓库</li></ol><ul><li>创建一个仓库，名字叫 你的GitHub用户名.github.io</li><li>比如你是 goko，就叫 goko.github.io</li></ul></li><li><ol start="2"><li>安装部署插件</li></ol></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">npm install hexo-deployer-git --save<br></code></pre></td></tr></table></figure><ul><li><ol start="3"><li>修改 _config.yml（根目录下）添加部署配置：</li></ol></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">deploy:<br>  type: git<br>  # repo建议使用SSH, SSH免密<br>  repo: https://github.com/你的GitHub用户名/你的GitHub用户名.github.io.git<br>  branch: main  # 或者 master，看你的默认分支<br></code></pre></td></tr></table></figure><ul><li><ol start="4"><li>生成并部署博客</li></ol></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">hexo clean<br>hexo generate<br>hexo deploy<br></code></pre></td></tr></table></figure><h3 id="3-域名-com-绑定"><a href="#3-域名-com-绑定" class="headerlink" title="3. 域名(.com)绑定"></a>3. 域名(<xxxx>.com)绑定</xxxx></h3><ul><li><ol><li>添加域名(在my-blog下)</li></ol></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">echo &quot;&lt;xxxx&gt;.com&quot; &gt; source/CNAME<br># 或者可以：echo &quot;www.&lt;xxxx&gt;.com&quot; &gt; source/CNAME<br># 只能添加一个，而且两个需要添加不同的域名解析（如下）<br></code></pre></td></tr></table></figure><ul><li><ol start="2"><li>重新部署</li></ol></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d<br></code></pre></td></tr></table></figure><ul><li><ol start="3"><li>设置 DNS 解析指向 GitHub Pages</li></ol></li></ul><p><strong>A. 使用裸域名（apex 域名）goku72.com</strong></p><table><thead><tr><th>记录类型</th><th>主机记录</th><th>记录值</th><th>说明</th></tr></thead><tbody><tr><td>A</td><td>@</td><td>185.199.108.153</td><td>GitHub Pages IP</td></tr><tr><td>A</td><td>@</td><td>185.199.109.153</td><td>GitHub Pages IP</td></tr><tr><td>A</td><td>@</td><td>185.199.110.153</td><td>GitHub Pages IP</td></tr><tr><td>A</td><td>@</td><td>185.199.111.153</td><td>GitHub Pages IP</td></tr></tbody></table><p>example aliyun:</p><ol><li>选择业务需求: 将网站域名解析到服务器IPv4地址</li><li>选择网站域名(主机记录): <xxxx>.com（对应设置“@”主机记录）</xxxx></li><li>填写 IP（记录值）：</li></ol><ul><li>在输入框里粘贴以下四行（每一行一个 IP）：</li><li><pre><code>  &gt; 185.199.109.153  &gt; 185.199.108.153  &gt; 185.199.110.153  &gt; 185.199.111.153</code></pre></li></ul><hr><p><strong>B. 使用 <a href="http://www.goku72.com/">www.goku72.com</a> 作为主域名</strong></p><table><thead><tr><th>记录类型</th><th>主机记录</th><th>记录值</th><th>说明</th></tr></thead><tbody><tr><td>CNAME</td><td>www</td><td>&lt;github用户名&gt;.github.io.</td><td>指向你的 GitHub 用户页仓库</td></tr></tbody></table><p>example aliyun:</p><ol><li>选择业务需求: 将网站域名解析到另外的目标域名</li><li>选择网站域名(主机记录): www.<xxxx>.com（对应设置“www”主机记录）</xxxx></li><li>填写 IP（记录值）：&lt;github用户名&gt;.github.io. (最有有一个符号”.”)</li></ol><h3 id="4-设置主题"><a href="#4-设置主题" class="headerlink" title="4. 设置主题"></a>4. 设置主题</h3><ul><li>cd my-blog&#x2F;themes</li><li>git clone -b master <a href="https://github.com/jerryc127/hexo-theme-butterfly.git">https://github.com/jerryc127/hexo-theme-butterfly.git</a> butterfly</li><li>修改_config.yml: <ul><li>theme: butterfly</li></ul></li><li>hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</li></ul><p><strong>更多主题</strong>：<a href="https://hexo.io/themes/">https://hexo.io/themes/</a></p><p><strong>注：</strong></p><ul><li>如果AB两个方式都添加了，只需要在 Hexo 项目的 source&#x2F;CNAME 文件中写 www.<xxxx>.com，GitHub Pages 就会自动把 goku72.com 重定向过去，无需额外设置！</xxxx></li><li>后续换域名只需要：阿里云重新解析 + 修改 source&#x2F;CNAME + 重新部署 Hexo，就能完成域名迁移。</li><li>有些主题可能需要下载插件</li></ul>]]></content:encoded>
      
      
      
      <category domain="https://GoKo-Son626.github.io/tags/hexo/">hexo</category>
      
      
      <comments>https://goko-son626.github.io/post/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA.html#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>xv6-riscv_ch4</title>
      <link>https://goko-son626.github.io/post/xv6-riscv-ch4.html</link>
      <guid>https://goko-son626.github.io/post/xv6-riscv-ch4.html</guid>
      <pubDate>Wed, 12 Feb 2025 13:59:10 GMT</pubDate>
      
      <description>&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;How traps and system calls work on RISC-V. It introduces the trap mechanism, how user programs invoke system calls, how the kernel handles those traps, and how arguments are passed. It also covers kernel-mode traps, page faults, and real-world implications like protection and isolation.&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      
      
      
      <content:encoded><![CDATA[<ul><li><em><strong>How traps and system calls work on RISC-V. It introduces the trap mechanism, how user programs invoke system calls, how the kernel handles those traps, and how arguments are passed. It also covers kernel-mode traps, page faults, and real-world implications like protection and isolation.</strong></em></li></ul><span id="more"></span><h2 id="ch4-Traps-and-system-calls"><a href="#ch4-Traps-and-system-calls" class="headerlink" title="ch4: Traps and system calls"></a><strong>ch4: Traps and system calls</strong></h2><ul><li><p>There are three kinds of event which cause the CPU to set aside ordinary execution of instructions and force a transfer of control to special code that handles the event. and we uses <code>trap</code> as a generic term for these situations.</p><ul><li>One situation is a <code>systemcall</code>, when a user program executes the ecall instruction to ask the kernel to do something for it. </li><li>Another situation is an <code>exception</code>: an instruction (user or kernel) does something illegal, such as divide by zero or use an invalid virtual address. </li><li>The third situation is a <code>device interrupt</code>, when a device signals that it needs attention, for example when the disk hardware finishes a read or write request.</li></ul></li><li><p>Xv6 handles all traps in the kernel; traps are not delivered to user code. Handling traps in the kernel is natural for system calls. It makes sense for interrupts since isolation demands that only the kernel be allowed to use devices, and because the kernel is a convenient mechanism with which to share devices among multiple processes. It also makes sense for exceptions since xv6 responds to all exceptions from user space by killing the offending program.</p></li><li><p>Xv6 trap handling proceeds in four stages: </p><ul><li>hardware actions taken by the RISC-V CPU,</li><li>some assembly instructions that prepare the way for kernel C code</li><li>a C function that decides what to do with the trap</li><li>and the system call or device-driver service routine.</li></ul><p>While commonality among the three trap types suggests that a kernel could handle all traps with a single code path, it turns out to be convenient to have separate code for two distinct cases: traps from user space, and traps from kernel space. Kernel code (assembler or C) that processes a trap is often called a handler; the first handler instructions are usually written in assembler (rather than C) and are sometimes called a vector.</p></li></ul><h3 id="4-1-RISC-V-trap-machinery机制"><a href="#4-1-RISC-V-trap-machinery机制" class="headerlink" title="4.1 RISC-V trap machinery机制"></a>4.1 RISC-V trap machinery机制</h3><ul><li><p>Each RISC-V CPU has a set of control registers that the kernel writes to tell the CPU how to handle traps, and that the kernel can read to find out about a trap that has occurred. The RISC-V documents contain the full story [3]. riscv.h (kernel&#x2F;riscv.h:1) contains definitions that xv6 uses. Here’s an outline of the most important registers:</p><ul><li><code>stvec</code>: The kernel writes the address of its trap handler here; the RISC-V jumps to the address in stvec to handle a trap.</li><li><code>sepc</code>: When a trap occurs, RISC-V saves the program counter here (since the pc is then overwritten with the value in stvec). The sret (return from trap) instruction copies sepc to the pc. The kernel can write sepc to control where sret goes.</li><li><code>scause</code>: RISC-V puts a number here that describes the reason for the trap.</li><li><code>sscratch</code>: The trap handler code uses sscratch to help it avoid overwriting user registers before saving them.</li><li><code>sstatus</code>: The SIE bit in sstatus controls whether device interrupts are enabled. If the kernel clears SIE, the RISC-V will defer device interrupts until the kernel sets SIE. The SPP bit indicates whether a trap came from user mode or supervisor mode, and controls to what mode sret returns.</li></ul><p>The above registers relate to traps handled in supervisor mode, and they cannot be read or written in user mode. Each CPU on a multi-core chip has its own set of these registers, and more than one CPU may be handling a trap at any given time.</p></li><li><p>When it needs to force a trap, the RISC-V hardware does the following for all trap types:</p><ol><li>If the trap is a device interrupt, and the sstatus SIE bit is clear, don’t do any of the following.</li><li>Disable interrupts by clearing the SIE bit in sstatus.</li><li>Copy the pc to sepc.</li><li>Save the current mode (user or supervisor) in the SPP bit in sstatus.</li><li>Set scause to reflect the trap’s cause.</li><li>Set the mode to supervisor.</li><li>Copy stvec to the pc.</li><li>Start executing at the new pc.</li></ol><p>Note that the CPU doesn’t switch to the kernel page table, doesn’t switch to a stack in the kernel, and doesn’t save any registers other than the pc. Kernel software must perform these tasks. One reason that the CPU does minimal work during a traps is to provide flexibility to software; for example, some operating systems omit a page table switch in some situations to increase trap performance.<br>It’s worth thinking about whether any of the steps listed above could be omitted, perhaps in search of faster traps. Though there are situations in which a simpler sequence can work, many of the steps would be dangerous to omit in general. For example, suppose that the CPU didn’t switch program counters. Then a trap from user space could switch to supervisor mode while still running user instructions. Those user instructions could break user&#x2F;kernel isolation, for example by modifying the satp register to point to a page table that allowed accessing all of physical memory. It is thus important that the CPU switch to a kernel-specified instruction address, namely <code>stvec</code>.</p></li></ul><h3 id="4-2-Traps-from-user-space"><a href="#4-2-Traps-from-user-space" class="headerlink" title="4.2 Traps from user space"></a>4.2 Traps from user space</h3><p>Xv6 handles traps differently depending on whether the trap occurs while executing in the kernel<br>or in user code. Here is the story for traps from user code; Section 4.5 describes traps from kernel<br>code.<br>A trap may occur while executing in user space if the user program makes a system call (ecall<br>instruction), or does something illegal, or if a device interrupts. The high-level path of a trap from<br>user space is uservec (kernel&#x2F;trampoline.S:22), then usertrap (kernel&#x2F;trap.c:37); and when re-<br>turning, usertrapret (kernel&#x2F;trap.c:90) and then userret (kernel&#x2F;trampoline.S:101).<br>A major constraint on the design of xv6’s trap handling is the fact that the RISC-V hardware<br>does not switch page tables when it forces a trap. This means that the trap handler address in<br>stvec must have a valid mapping in the user page table, since that’s the page table in force when<br>the trap handling code starts executing. Furthermore, xv6’s trap handling code needs to switch to<br>the kernel page table; in order to be able to continue executing after that switch, the kernel page<br>table must also have a mapping for the handler pointed to by stvec.<br>Xv6 satisfies these requirements using a trampoline page. The trampoline page contains uservec,<br>the xv6 trap handling code that stvec points to. The trampoline page is mapped in every process’s<br>page table at address TRAMPOLINE, which is at the top of the virtual address space so that it will be<br>above memory that programs use for themselves. The trampoline page is also mapped at address<br>TRAMPOLINE in the kernel page table. See Figure 2.3 and Figure 3.3. Because the trampoline<br>page is mapped in the user page table, traps can start executing there in supervisor mode. Because<br>the trampoline page is mapped at the same address in the kernel address space, the trap handler<br>can continue to execute after it switches to the kernel page table.<br>The code for the uservec trap handler is in trampoline.S (kernel&#x2F;trampoline.S:22). When<br>uservec starts, all 32 registers contain values owned by the interrupted user code. These 32<br>values need to be saved somewhere in memory, so that later on the kernel can restore them before<br>returning to user space. Storing to memory requires use of a register to hold the address, but at this<br>point there are no general-purpose registers available! Luckily RISC-V provides a helping hand in<br>the form of the sscratch register. The csrw instruction at the start of uservec saves a0 in<br>sscratch. Now uservec has one register (a0) to play with.<br>uservec’s next task is to save the 32 user registers. The kernel allocates, for each process, a<br>page of memory for a trapframe structure that (among other things) has space to save the 32<br>user registers (kernel&#x2F;proc.h:43). Because satp still refers to the user page table, uservec needs<br>the trapframe to be mapped in the user address space. Xv6 maps each process’s trapframe at virtual<br>address TRAPFRAME in that process’s user page table; TRAPFRAME is just below TRAMPOLINE.<br>The process’s p-&gt;trapframe also points to the trapframe, though at its physical address so the<br>kernel can use it through the kernel page table.<br>Thus uservec loads address TRAPFRAME into a0 and saves all the user registers there,<br>including the user’s a0, read back from sscratch.<br>The trapframe contains the address of the current process’s kernel stack, the current CPU’s<br>hartid, the address of the usertrap function, and the address of the kernel page table. uservec<br>retrieves these values, switches satp to the kernel page table, and jumps to usertrap.<br>The job of usertrap is to determine the cause of the trap, process it, and return (kernel&#x2F;-<br>trap.c:37). It first changes stvec so that a trap while in the kernel will be handled by kernelvec<br>rather than uservec. It saves the sepc register (the saved user program counter), because<br>usertrap might call yield to switch to another process’s kernel thread, and that process might<br>return to user space, in the process of which it will modify sepc. If the trap is a system call,<br>usertrap calls syscall to handle it; if a device interrupt, devintr; otherwise it’s an ex-<br>ception, and the kernel kills the faulting process. The system call path adds four to the saved user<br>program counter because RISC-V, in the case of a system call, leaves the program pointer pointing<br>to the ecall instruction but user code needs to resume executing at the subsequent instruction.<br>On the way out, usertrap checks if the process has been killed or should yield the CPU (if this<br>trap is a timer interrupt).<br>The first step in returning to user space is the call to usertrapret (kernel&#x2F;trap.c:90). This<br>function sets up the RISC-V control registers to prepare for a future trap from user space: setting<br>stvec to uservec and preparing the trapframe fields that uservec relies on. usertrapret<br>sets sepc to the previously saved user program counter. At the end, usertrapret calls userret<br>on the trampoline page that is mapped in both user and kernel page tables; the reason is that as-<br>sembly code in userret will switch page tables.<br>usertrapret’s call to userret passes a pointer to the process’s user page table in a0<br>(kernel&#x2F;trampoline.S:101). userret switches satp to the process’s user page table. Recall that the<br>user page table maps both the trampoline page and TRAPFRAME, but nothing else from the kernel.<br>The trampoline page mapping at the same virtual address in user and kernel page tables allows<br>userret to keep executing after changing satp. From this point on, the only data userret<br>can use is the register contents and the content of the trapframe. userret loads the TRAPFRAME<br>address into a0, restores saved user registers from the trapframe via a0, restores the saved user<br>a0, and executes sret to return to user space.</p><h3 id="4-3-Code-Calling-system-calls"><a href="#4-3-Code-Calling-system-calls" class="headerlink" title="4.3 Code: Calling system calls"></a>4.3 Code: Calling system calls</h3><p>Chapter 2 ended with initcode.S invoking the exec system call (user&#x2F;initcode.S:11). Let’s look<br>at how the user call makes its way to the exec system call’s implementation in the kernel.<br>initcode.S places the arguments for exec in registers a0 and a1, and puts the system call<br>number in a7. System call numbers match the entries in the syscalls array, a table of function<br>pointers (kernel&#x2F;syscall.c:107). The ecall instruction traps into the kernel and causes uservec,<br>usertrap, and then syscall to execute, as we saw above.<br>syscall (kernel&#x2F;syscall.c:132) retrieves the system call number from the saved a7 in the trapframe<br>and uses it to index into syscalls. For the first system call, a7 contains SYS_exec (ker-<br>nel&#x2F;syscall.h:8), resulting in a call to the system call implementation function sys_exec.<br>When sys_exec returns, syscall records its return value in p-&gt;trapframe-&gt;a0. This will<br>cause the original user-space call to exec() to return that value, since the C calling convention<br>on RISC-V places return values in a0. System calls conventionally return negative numbers to<br>indicate errors, and zero or positive numbers for success. If the system call number is invalid,<br>syscall prints an error and returns −1.</p><h3 id="4-4-Code-System-call-arguments"><a href="#4-4-Code-System-call-arguments" class="headerlink" title="4.4 Code: System call arguments"></a>4.4 Code: System call arguments</h3><ul><li>System call implementations in the kernel need to find the arguments passed by user code. Because<br>user code calls system call wrapper functions, the arguments are initially where the RISC-V C<br>calling convention places them: in registers. The kernel trap code saves user registers to the current<br>process’s trap frame, where kernel code can find them. The kernel functions argint, argaddr,<br>and argfd retrieve the n ’th system call argument from the trap frame as an integer, pointer, or a file<br>descriptor. They all call argraw to retrieve the appropriate saved user register (kernel&#x2F;syscall.c:34).<br>Some system calls pass pointers as arguments, and the kernel must use those pointers to read<br>or write user memory. The exec system call, for example, passes the kernel an array of pointers<br>referring to string arguments in user space. These pointers pose two challenges. First, the user pro-<br>gram may be buggy or malicious, and may pass the kernel an invalid pointer or a pointer intended<br>to trick the kernel into accessing kernel memory instead of user memory. Second, the xv6 kernel<br>page table mappings are not the same as the user page table mappings, so the kernel cannot use<br>ordinary instructions to load or store from user-supplied addresses.<br>The kernel implements functions that safely transfer data to and from user-supplied addresses.<br>fetchstr is an example (kernel&#x2F;syscall.c:25). File system calls such as exec use fetchstr to<br>retrieve string file-name arguments from user space. fetchstr calls copyinstr to do the hard<br>work.<br>copyinstr (kernel&#x2F;vm.c:415) copies up to max bytes to dst from virtual address srcva in<br>the user page table pagetable. Since pagetable is not the current page table, copyinstr<br>uses walkaddr (which calls walk) to look up srcva in pagetable, yielding physical address<br>pa0. The kernel’s page table maps all of physical RAM at virtual addresses that are equal to the<br>RAM’s physical address. This allows copyinstr to directly copy string bytes from pa0 to dst.<br>walkaddr (kernel&#x2F;vm.c:109) checks that the user-supplied virtual address is part of the process’s user address space, so programs cannot trick the kernel into reading other memory. A similar<br>function, copyout, copies data from the kernel to a user-supplied address.</li></ul><h3 id="4-5-Traps-from-kernel-space"><a href="#4-5-Traps-from-kernel-space" class="headerlink" title="4.5 Traps from kernel space"></a>4.5 Traps from kernel space</h3><p>Xv6 handles traps from kernel code in a different way than traps from user code. When entering<br>the kernel, usertrap points stvec to the assembly code at kernelvec (kernel&#x2F;kernelvec.S:12).<br>Since kernelvec only executes if xv6 was already in the kernel, kernelvec can rely on<br>satp being set to the kernel page table, and on the stack pointer referring to a valid kernel stack.<br>kernelvec pushes all 32 registers onto the stack, from which it will later restore them so that<br>the interrupted kernel code can resume without disturbance.<br>kernelvec saves the registers on the stack of the interrupted kernel thread, which makes<br>sense because the register values belong to that thread. This is particularly important if the trap<br>causes a switch to a different thread – in that case the trap will actually return from the stack of the<br>new thread, leaving the interrupted thread’s saved registers safely on its stack.<br>kernelvec jumps to kerneltrap (kernel&#x2F;trap.c:135) after saving registers. kerneltrap<br>is prepared for two types of traps: device interrupts and exceptions. It calls devintr (kernel&#x2F;-<br>trap.c:185) to check for and handle the former. If the trap isn’t a device interrupt, it must be an<br>exception, and that is always a fatal error if it occurs in the xv6 kernel; the kernel calls panic and<br>stops executing.<br>If kerneltrap was called due to a timer interrupt, and a process’s kernel thread is running<br>(as opposed to a scheduler thread), kerneltrap calls yield to give other threads a chance to<br>run. At some point one of those threads will yield, and let our thread and its kerneltrap resume<br>again. Chapter 7 explains what happens in yield.<br>When kerneltrap’s work is done, it needs to return to whatever code was interrupted<br>by the trap. Because a yield may have disturbed sepc and the previous mode in sstatus,<br>kerneltrap saves them when it starts. It now restores those control registers and returns to<br>kernelvec (kernel&#x2F;kernelvec.S:38). kernelvec pops the saved registers from the stack and ex-<br>ecutes sret, which copies sepc to pc and resumes the interrupted kernel code.<br>It’s worth thinking through how the trap return happens if kerneltrap called yield due to<br>a timer interrupt.<br>Xv6 sets a CPU’s stvec to kernelvec when that CPU enters the kernel from user space;<br>you can see this in usertrap (kernel&#x2F;trap.c:29). There’s a window of time when the kernel has<br>started executing but stvec is still set to uservec, and it’s crucial that no device interrupt occur<br>during that window. Luckily the RISC-V always disables interrupts when</p><h3 id="4-6-Page-fault-exceptions"><a href="#4-6-Page-fault-exceptions" class="headerlink" title="4.6 Page-fault exceptions"></a>4.6 Page-fault exceptions</h3><h3 id="4-7-Real-world"><a href="#4-7-Real-world" class="headerlink" title="4.7 Real world"></a>4.7 Real world</h3><h3 id="4-8-Exercises"><a href="#4-8-Exercises" class="headerlink" title="4.8 Exercises"></a>4.8 Exercises</h3>]]></content:encoded>
      
      
      
      <category domain="https://GoKo-Son626.github.io/tags/xv6-riscv/">xv6-riscv</category>
      
      
      <comments>https://goko-son626.github.io/post/xv6-riscv-ch4.html#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>xv6-riscv_ch3</title>
      <link>https://goko-son626.github.io/post/xv6-riscv-ch3.html</link>
      <guid>https://goko-son626.github.io/post/xv6-riscv-ch3.html</guid>
      <pubDate>Mon, 10 Feb 2025 01:25:24 GMT</pubDate>
      
      <description>&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;This chapter covers the fundamental concepts of paging hardware, memory allocation, and process address space management, including practical code implementations like creating address spaces, physical memory allocation, and process management functions such as &lt;code&gt;sbrk&lt;/code&gt; and &lt;code&gt;exec&lt;/code&gt;.&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      
      
      
      <content:encoded><![CDATA[<ul><li><em><strong>This chapter covers the fundamental concepts of paging hardware, memory allocation, and process address space management, including practical code implementations like creating address spaces, physical memory allocation, and process management functions such as <code>sbrk</code> and <code>exec</code>.</strong></em></li></ul><span id="more"></span><h2 id="ch3-Page-tables"><a href="#ch3-Page-tables" class="headerlink" title="ch3: Page tables"></a><strong>ch3: Page tables</strong></h2><ul><li>Page tables are the most popular mechanism through which the operating system provides each process with its own private address space and memory.</li><li>Xv6 performs a few tricks: mapping the same memory (a trampoline page) in several address spaces, and guarding kernel and user stacks with an unmapped page. The rest of this chapter explains the page tables that the RISC-V hardware provides and how xv6 uses them.</li></ul><h3 id="3-1-Paging-hardware"><a href="#3-1-Paging-hardware" class="headerlink" title="3.1 Paging hardware"></a>3.1 Paging hardware</h3><ul><li>As a reminder, RISC-V instructions (both user and kernel) manipulate virtual addresses. The machine’s RAM, or physical memory, is indexed with physical addresses. The RISC-V page table hardware connects these two kinds of addresses, by mapping each virtual address to a physical address.</li><li>Xv6 runs on Sv39 RISC-V, which means that only the bottom 39 bits of a 64-bit virtual address are used; the top 25 bits are not used. In this Sv39 configuration, a RISC-V page table is logically an array of 227 (134,217,728) page table entries (PTEs). Each PTE contains a 44-bit physical page number (PPN) and some flags. The paging hardware translates a virtual address by using the top 27 bits of the 39 bits to index into the page table to find a PTE, and making a 56-bit physical address whose top 44 bits come from the PPN in the PTE and whose bottom 12 bits are copied from the original virtual address. Figure 3.1 shows this process with a logical view of the page table as a simple array of PTEs (see Figure 3.2 for a fuller story). A page table gives the operating system control over virtual-to-physical address translations at the granularity of aligned chunks of 4096 (212 ) bytes. Such a chunk is called a page.<br><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/xv6-riscv-ch3/image.png" alt="alt text"></li><li>In Sv39 RISC-V, the top 25 bits of a virtual address are not used for translation. The physical<br>address also has room for growth: there is room in the PTE format for the physical page number<br>to grow by another 10 bits. The designers of RISC-V chose these numbers based on technology<br>predictions. 239 bytes is 512 GB, which should be enough address space for applications running on RISC-V computers. 256 is enough physical memory space for the near future to fit many I&#x2F;O<br>devices and RAM chips. If more is needed, the RISC-V designers have defined Sv48 with 48-bit<br>virtual addresses [3].</li><li>As Figure 3.2 shows, a RISC-V CPU translates a virtual address into a physical in three steps.<br>A page table is stored in physical memory as a three-level tree. The root of the tree is a 4096-byte<br>page-table page that contains 512 PTEs, which contain the physical addresses for page-table pages<br>in the next level of the tree. Each of those pages contains 512 PTEs for the final level in the tree.<br>The paging hardware uses the top 9 bits of the 27 bits to select a PTE in the root page-table page,<br>the middle 9 bits to select a PTE in a page-table page in the next level of the tree, and the bottom<br>9 bits to select the final PTE. (In Sv48 RISC-V a page table has four levels, and bits 39 through 47<br>of a virtual address index into the top-level.)<br>If any of the three PTEs required to translate an address is not present, the paging hardware<br>raises a page-fault exception, leaving it up to the kernel to handle the exception (see Chapter 4).<br>The three-level structure of Figure 3.2 allows a memory-efficient way of recording PTEs, com-<br>pared to the single-level design of Figure 3.1. In the common case in which large ranges of virtual<br>addresses have no mappings, the three-level structure can omit entire page directories. For exam-<br>ple, if an application uses only a few pages starting at address zero, then the entries 1 through 511<br>of the top-level page directory are invalid, and the kernel doesn’t have to allocate pages those for<br>511 intermediate page directories. Furthermore, the kernel also doesn’t have to allocate pages for<br>the bottom-level page directories for those 511 intermediate page directories. So, in this example,<br>the three-level design saves 511 pages for intermediate page directories and 511 × 512 pages for<br>bottom-level page directories.<br>Although a CPU walks the three-level structure in hardware as part of executing a load or store<br>instruction, a potential downside of three levels is that the CPU must load three PTEs from memory<br>to perform the translation of the virtual address in the load&#x2F;store instruction to a physical address.<br>To avoid the cost of loading PTEs from physical memory, a RISC-V CPU caches page table entries<br>in a Translation Look-aside Buffer (TLB).<br><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/xv6-riscv-ch3/image-1.png" alt="alt text"><br>allowed to be used. PTE_V indicates whether the PTE is present: if it is not set, a reference to the<br>page causes an exception (i.e., is not allowed). PTE_R controls whether instructions are allowed<br>to read to the page. PTE_W controls whether instructions are allowed to write to the page. PTE_X<br>controls whether the CPU may interpret the content of the page as instructions and execute them.<br>PTE_U controls whether instructions in user mode are allowed to access the page; if PTE_U is not<br>set, the PTE can be used only in supervisor mode. Figure 3.2 shows how it all works. The flags and<br>all other page hardware-related structures are defined in (kernel&#x2F;riscv.h)</li><li>To tell a CPU to use a page table, the kernel must write the physical address of the root page-<br>table page into the satp register. A CPU will translate all addresses generated by subsequent<br>instructions using the page table pointed to by its own satp. Each CPU has its own satp so that<br>different CPUs can run different processes, each with a private address space described by its own<br>page table.</li><li><strong>notice</strong>:A few notes about terms used in this book. Physical memory refers to storage cells in RAM.<br>A byte of physical memory has an address, called a physical address. Instructions that dereference<br>addresses (such as loads, stores, jumps, and function calls) use only virtual addresses, which the<br>paging hardware translates to physical addresses, and then sends to the RAM hardware to read or<br>write storage. An address space is the set of virtual addresses that are valid in a given page table; each xv6 process has a separate user address space, and the xv6 kernel has its own address space as<br>well. User memory refers to a process’s user address space plus the physical memory that the page<br>table allows the process to access. Virtual memory refers to the ideas and techniques associated<br>with managing page tables and using them to achieve goals such as isolation.<br><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/xv6-riscv-ch3/image-2.png" alt="alt text"></li></ul><h3 id="3-2-Kernel-address-space"><a href="#3-2-Kernel-address-space" class="headerlink" title="3.2 Kernel address space"></a>3.2 Kernel address space</h3><ul><li>Xv6 maintains one page table per process, describing each process’s user address space, plus a sin-<br>gle page table that describes the kernel’s address space. The kernel configures the layout of its ad-<br>dress space to give itself access to physical memory and various hardware resources at predictable virtual addresses. Figure 3.3 shows how this layout maps kernel virtual addresses to physical addresses. The file (kernel&#x2F;memlayout.h) declares the constants for xv6’s kernel memory layout.</li><li>The kernel gets at RAM and memory-mapped device registers using “direct mapping;” that<br>is, mapping the resources at virtual addresses that are equal to the physical address. For example,<br>the kernel itself is located at KERNBASE&#x3D;0x80000000 in both the virtual address space and in<br>physical memory. Direct mapping simplifies kernel code that reads or writes physical memory.</li><li>There are a couple of kernel virtual addresses that aren’t direct-mapped:<ul><li>The trampoline page. It is mapped at the top of the virtual address space; user page tables have this same mapping. Chapter 4 discusses the role of the trampoline page, but we see here an interesting use case of page tables; a physical page (holding the trampoline code) is mapped twice in the virtual address space of the kernel: once at top of the virtual address space and once with a direct mapping.</li><li>The kernel stack pages. Each process has its own kernel stack, which is mapped high so that below it xv6 can leave an unmapped guard page. The guard page’s PTE is invalid (i.e., PTE_V is not set), so that if the kernel overflows a kernel stack, it will likely cause an exception and the kernel will panic. Without a guard page an overflowing stack would overwrite other kernel memory, resulting in incorrect operation. A panic crash is preferable.</li></ul></li></ul><h3 id="3-3-Code-creating-an-address-space"><a href="#3-3-Code-creating-an-address-space" class="headerlink" title="3.3 Code: creating an address space"></a>3.3 Code: creating an address space</h3><ul><li>Most of the xv6 code for manipulating address spaces and page tables resides in vm.c (kernel&#x2F;vm.c:1). The central data structure is pagetable_t, which is really a pointer to a RISC-V root page-table page; a pagetable_t may be either the kernel page table, or one of the per-process page tables. The central functions are walk, which finds the PTE for a virtual address,and mappages, which installs PTEs for new mappings. Functions starting with kvm manipulate the kernel page table; functions starting with uvm manipulate a user page table; other functions are used for both. copyout and copyin copy data to and from user virtual addresses provided as system call arguments; they are in vm.c because they need to explicitly translate those addresses in order to find the corresponding physical memory.</li><li>Early in the boot sequence, main calls kvminit (kernel&#x2F;vm.c:54) to create the kernel’s page ta-<br>ble using kvmmake (kernel&#x2F;vm.c:20). This call occurs before xv6 has enabled paging on the RISC-V,<br>so addresses refer directly to physical memory. kvmmake first allocates a page of physical mem-<br>ory to hold the root page-table page. Then it calls kvmmap to install the translations that the kernel<br>needs. The translations include the kernel’s instructions and data, physical memory up to PHYSTOP,<br>and memory ranges which are actually devices. proc_mapstacks (kernel&#x2F;proc.c:33) allocates a<br>kernel stack for each process. It calls kvmmap to map each stack at the virtual address generated<br>by KSTACK, which leaves room for the invalid stack-guard pages.</li><li><code>kvmmap</code> (kernel&#x2F;vm.c:132) calls mappages (kernel&#x2F;vm.c:144), which installs mappings into a<br>page table for a range of virtual addresses to a corresponding range of physical addresses. It does<br>this separately for each virtual address in the range, at page intervals. For each virtual address to<br>be mapped, mappages calls walk to find the address of the PTE for that address. It then initializes<br>the PTE to hold the relevant physical page number, the desired permissions (PTE_W, PTE_X, and&#x2F;or<br>PTE_R), and PTE_V to mark the PTE as valid (kernel&#x2F;vm.c:165).</li><li><code>walk</code> (kernel&#x2F;vm.c:86) mimics the RISC-V paging hardware as it looks up the PTE for a virtual<br>address (see Figure 3.2). walk descends the page table one level at a time, using each level’s 9<br>bits of virtual address to index into the relevant page directory page. At each level it finds either<br>the PTE of the next level’s page directory page, or the PTE of final page (kernel&#x2F;vm.c:92). If a PTE<br>in a first or second level page directory page isn’t valid, then the required directory page hasn’t<br>yet been allocated; if the alloc argument is set, walk allocates a new page-table page and puts<br>its physical address in the PTE. It returns the address of the PTE in the lowest layer in the tree<br>(kernel&#x2F;vm.c:102).</li><li>main calls kvminithart (kernel&#x2F;vm.c:62) to install the kernel page table. It writes the physical<br>address of the root page-table page into the register satp. After this the CPU will translate ad-<br>dresses using the kernel page table. Since the kernel uses a direct mapping, the now virtual address<br>of the next instruction will map to the right physical memory address.</li><li>Each RISC-V CPU caches page table entries in a Translation Look-aside Buffer (TLB), and<br>when xv6 changes a page table, it must tell the CPU to invalidate corresponding cached TLB<br>entries. If it didn’t, then at some point later the TLB might use an old cached mapping, point-<br>ing to a physical page that in the meantime has been allocated to another process, and as a re-<br>sult, a process might be able to scribble on some other process’s memory. The RISC-V has an instruction sfence.vma that flushes the current CPU’s TLB. Xv6 executes sfence.vma in<br>kvminithart after reloading the satp register, and in the trampoline code that switches to a<br>user page table before returning to user space (kernel&#x2F;trampoline.S:89).<br>It is also necessary to issue sfence.vma before changing satp, in order to wait for comple-<br>tion of all outstanding loads and stores. This wait ensures that preceding updates to the page table<br>have completed, and ensures that preceding loads and stores use the old page table, not the new<br>one.<br>To avoid flushing the complete TLB, RISC-V CPUs may support address space identifiers<br>(ASIDs) [3]. The kernel can then flush just the TLB entries for a particular address space. Xv6<br>does not use this feature.</li></ul><h3 id="3-4-Physical-memory-allocation"><a href="#3-4-Physical-memory-allocation" class="headerlink" title="3.4 Physical memory allocation"></a>3.4 Physical memory allocation</h3><ul><li>The kernel must allocate and free physical memory at run-time for page tables, user memory,<br>kernel stacks, and pipe buffers.</li><li>Xv6 uses the physical memory between the end of the kernel and PHYSTOP for run-time alloca-<br>tion. It allocates and frees whole 4096-byte pages at a time. It keeps track of which pages are free<br>by threading a linked list through the pages themselves. Allocation consists of removing a page<br>from the linked list; freeing consists of adding the freed page to the list.</li></ul><h3 id="3-5-Code-Physical-memory-allocator"><a href="#3-5-Code-Physical-memory-allocator" class="headerlink" title="3.5 Code: Physical memory allocator"></a>3.5 Code: Physical memory allocator</h3><ul><li>The allocator resides in kalloc.c (kernel&#x2F;kalloc.c:1). The allocator’s data structure is a free list<br>of physical memory pages that are available for allocation. Each free page’s list element is a<br>struct run (kernel&#x2F;kalloc.c:17). Where does the allocator get the memory to hold that data struc-<br>ture? It store each free page’s run structure in the free page itself, since there’s nothing else stored<br>there. The free list is protected by a spin lock (kernel&#x2F;kalloc.c:21-24). The list and the lock are<br>wrapped in a struct to make clear that the lock protects the fields in the struct. For now, ignore the<br>lock and the calls to acquire and release; Chapter 6 will examine locking in detail.<br>The function main calls kinit to initialize the allocator (kernel&#x2F;kalloc.c:27). kinit initializes<br>the free list to hold every page between the end of the kernel and PHYSTOP. Xv6 ought to de-<br>termine how much physical memory is available by parsing configuration information provided<br>by the hardware. Instead xv6 assumes that the machine has 128 megabytes of RAM. kinit calls<br>freerange to add memory to the free list via per-page calls to kfree. A PTE can only refer to<br>a physical address that is aligned on a 4096-byte boundary (is a multiple of 4096), so freerange<br>uses PGROUNDUP to ensure that it frees only aligned physical addresses. The allocator starts with<br>no memory; these calls to kfree give it some to manage.<br>The allocator sometimes treats addresses as integers in order to perform arithmetic on them<br>(e.g., traversing all pages in freerange), and sometimes uses addresses as pointers to read and<br>write memory (e.g., manipulating the run structure stored in each page); this dual use of addresses<br>is the main reason that the allocator code is full of C type casts.<br>The function kfree (kernel&#x2F;kalloc.c:47) begins by setting every byte in the memory being freed<br>to the value 1. This will cause code that uses memory after freeing it (uses “dangling references”)<br>to read garbage instead of the old valid contents; hopefully that will cause such code to break faster.<br>Then kfree prepends the page to the free list: it casts pa to a pointer to struct run, records the<br>old start of the free list in r-&gt;next, and sets the free list equal to r. kalloc removes and returns<br>the first element in the free list.</li></ul><h3 id="3-6-Process-address-space"><a href="#3-6-Process-address-space" class="headerlink" title="3.6 Process address space"></a>3.6 Process address space</h3><p><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/xv6-riscv-ch3/image-3.png" alt="alt text"></p><ul><li>Each process has its own page table, and when xv6 switches between processes, it also changes<br>page tables. Figure 3.4 shows a process’s address space in more detail than Figure 2.3. A process’s<br>user memory starts at virtual address zero and can grow up to MAXVA (kernel&#x2F;riscv.h:375), allowing<br>a process to address in principle 256 Gigabytes of memory.<br>A process’s address space consists of pages that contain the text of the program (which xv6<br>maps with the permissions PTE_R, PTE_X, and PTE_U), pages that contain the pre-initialized data<br>of the program, a page for the stack, and pages for the heap. Xv6 maps the data, stack, and heap<br>with the permissions PTE_R, PTE_W, and PTE_U.<br>Using permissions within a user address space is a common technique to harden a user process.<br>If the text were mapped with PTE_W, then a process could accidentally modify its own program;<br>for example, a programming error may cause the program to write to a null pointer, modifying<br>instructions at address 0, and then continue running, perhaps creating more havoc. To detect such<br>errors immediately, xv6 maps the text without PTE_W; if a program accidentally attempts to store<br>to address 0, the hardware will refuse to execute the store and raises a page fault (see Section 4.6).<br>The kernel then kills the process and prints out an informative message so that the developer can<br>track down the problem.<br>Similarly, by mapping data without PTE_X, a user program cannot accidentally jump to an<br>address in the program’s data and start executing at that address.<br>In the real world, hardening a process by setting permissions carefully also aids in defending<br>against security attacks. An adversary may feed carefully-constructed input to a program (e.g., a<br>Web server) that triggers a bug in the program in the hope of turning that bug into an exploit [14].<br>Setting permissions carefully and other techniques, such as randomizing of the layout of the user<br>address space, make such attacks harder.<br>The stack is a single page, and is shown with the initial contents as created by exec. Strings<br>containing the command-line arguments, as well as an array of pointers to them, are at the very<br>top of the stack. Just under that are values that allow a program to start at main as if the function<br>main(argc, argv) had just been called.<br>To detect a user stack overflowing the allocated stack memory, xv6 places an inaccessible guard<br>page right below the stack by clearing the PTE_U flag. If the user stack overflows and the process<br>tries to use an address below the stack, the hardware will generate a page-fault exception because<br>the guard page is inaccessible to a program running in user mode. A real-world operating system<br>might instead automatically allocate more memory for the user stack when it overflows.<br>When a process asks xv6 for more user memory, xv6 grows the process’s heap. Xv6 first uses kalloc to allocate physical pages. It then adds PTEs to the process’s page table that point to the<br>new physical pages. Xv6 sets the PTE_W, PTE_R, PTE_U, and PTE_V flags in these PTEs. Most<br>processes do not use the entire user address space; xv6 leaves PTE_V clear in unused PTEs.<br>We see here a few nice examples of use of page tables. First, different processes’ page tables<br>translate user addresses to different pages of physical memory, so that each process has private user<br>memory. Second, each process sees its memory as having contiguous virtual addresses starting at<br>zero, while the process’s physical memory can be non-contiguous. Third, the kernel maps a page<br>with trampoline code at the top of the user address space (without PTE_U), thus a single page of<br>physical memory shows up in all address spaces, but can be used only by the kernel.</li></ul><h3 id="3-7-Code-sbrk"><a href="#3-7-Code-sbrk" class="headerlink" title="3.7 Code: sbrk"></a>3.7 Code: sbrk</h3><ul><li>sbrk is the system call for a process to shrink or grow its memory. The system call is implemented<br>by the function growproc (kernel&#x2F;proc.c:260). growproc calls uvmalloc or uvmdealloc, de-<br>pending on whether n is positive or negative. uvmalloc (kernel&#x2F;vm.c:233) allocates physical mem-<br>ory with kalloc, zeros the allocated memory, and adds PTEs to the user page table with mappages.<br>uvmdealloc calls uvmunmap (kernel&#x2F;vm.c:178), which uses walk to find PTEs and kfree to<br>free the physical memory they refer to.<br>Xv6 uses a process’s page table not just to tell the hardware how to map user virtual addresses, but also as the only record of which physical memory pages are allocated to that process. That is the reason why freeing user memory (in uvmunmap) requires examination of the user page table.</li></ul><h3 id="3-8-Code-exec"><a href="#3-8-Code-exec" class="headerlink" title="3.8 Code: exec"></a>3.8 Code: exec</h3><ul><li>A binary is typically the output of the compiler and linker, and holds<br>machine instructions and program data. <code>exec</code> (kernel&#x2F;exec.c:23) opens the named binary path using<br>namei (kernel&#x2F;exec.c:36), which is explained in Chapter 8. Then, it reads the ELF header. Xv6<br>binaries are formatted in the widely-used ELF format, defined in (kernel&#x2F;elf.h). An ELF binary<br>consists of an ELF header, struct elfhdr (kernel&#x2F;elf.h:6), followed by a sequence of program<br>section headers, struct proghdr (kernel&#x2F;elf.h:25). Each progvhdr describes a section of the<br>application that must be loaded into memory; xv6 programs have two program section headers:<br>one for instructions and one for data.<br>The first step is a quick check that the file probably contains an ELF binary. An ELF binary<br>starts with the four-byte “magic number” 0x7F, ‘E’, ‘L’, ‘F’, or ELF_MAGIC (kernel&#x2F;elf.h:3). If<br>the ELF header has the right magic number, exec assumes that the binary is well-formed.<br>exec allocates a new page table with no user mappings with proc_pagetable (kernel&#x2F;exec.c:49),<br>allocates memory for each ELF segment with uvmalloc (kernel&#x2F;exec.c:65), and loads each segment<br>into memory with loadseg (kernel&#x2F;exec.c:10). loadseg uses walkaddr to find the physical ad-<br>dress of the allocated memory at which to write each page of the ELF segment, and readi to read<br>from the file.</li></ul><p>The program section header for &#x2F;init, the first user program created with exec, looks like this:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs plaintext"># objdump -p user/_init<br># 告诉操作系统如何将文件的各个段（segment）加载到内存中去执行<br>user/_init:     file format elf64-little<br>Program Header:<br>0x70000003 off  0x0000000000006bb0 vaddr 0x0000000000000000<br>                                        paddr 0x0000000000000000 align 2**0<br>        filesz 0x000000000000004a memsz 0x0000000000000000 flags r--<br>LOAD off        0x0000000000001000 vaddr 0x0000000000000000<br>                                        paddr 0x0000000000000000 align 2**12<br>        filesz 0x0000000000001000 memsz 0x0000000000001000 flags r-x<br>LOAD off        0x0000000000002000 vaddr 0x0000000000001000<br>                                        paddr 0x0000000000001000 align 2**12<br>        filesz 0x0000000000000010 memsz 0x0000000000000030 flags rw-<br>STACK off       0x0000000000000000 vaddr 0x0000000000000000<br>                                        paddr 0x0000000000000000 align 2**4<br>        filesz 0x0000000000000000 memsz 0x0000000000000000 flags rw-<br></code></pre></td></tr></table></figure><p>The output of <code>objdump -p</code> shows the <strong>Program Header Table</strong> of an ELF (Executable and Linkable Format) file. This is a crucial part of the ELF file, telling the operating system how to load each segment into memory for execution.</p><p>🌟 Explanation of ELF Program Header fields — each segment corresponds to the following fields:</p><table><thead><tr><th>Field</th><th>Meaning</th></tr></thead><tbody><tr><td><code>off</code></td><td>Byte offset of the segment in the file, counted from the beginning.</td></tr><tr><td><code>vaddr</code></td><td>Virtual address of the segment in memory.</td></tr><tr><td><code>paddr</code></td><td>Physical address — usually ignored by modern OSes.</td></tr><tr><td><code>align</code></td><td>Alignment requirement; the segment must be aligned to this (often a page size).</td></tr><tr><td><code>filesz</code></td><td>Size of the segment in the file (in bytes). <code>loadseg</code> reads this many bytes.</td></tr><tr><td><code>memsz</code></td><td>Total size the segment occupies in memory after loading (may be larger than in the file, e.g., for bss).</td></tr><tr><td><code>flags</code></td><td>Permission flags: <code>r</code> (read), <code>w</code> (write), <code>x</code> (execute).</td></tr><tr><td><code>type</code></td><td>Segment type (e.g., <code>LOAD</code>, <code>STACK</code>, <code>NOTE</code>, <code>DYNAMIC</code>, etc.).</td></tr><tr><td><code>align</code></td><td>Memory alignment requirement.</td></tr></tbody></table><h4 id="4-Program-Headers-Segments"><a href="#4-Program-Headers-Segments" class="headerlink" title="4 Program Headers (Segments):"></a>4 Program Headers (Segments):</h4><p><strong>1. First Segment: Type <code>0x70000003</code> (non-standard)</strong></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">0x70000003 off 0x0000000000006bb0 vaddr 0x0000000000000000<br>                                        paddr 0x0000000000000000 align 2**0<br>        filesz 0x000000000000004a memsz 0x0000000000000000 flags r--<br></code></pre></td></tr></table></figure><ul><li><code>type=0x70000003</code> is processor-specific and non-standard — generally ignored by developers.</li><li><code>off=0x6bb0</code> — the offset within the file.</li><li><code>filesz=0x4a</code> — 74 bytes of data.</li><li><code>memsz=0x0</code> — although there is data in the file, nothing is loaded into memory (e.g., debug info, notes).</li><li>This is typically metadata, not code or data.</li></ul><p><strong>2. Second Segment: The actual code segment (text segment)</strong></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">LOAD off 0x0000000000001000 vaddr 0x0000000000000000<br>                                paddr 0x0000000000000000 align 2**12<br>        filesz 0x0000000000001000 memsz 0x0000000000001000 flags r-x<br></code></pre></td></tr></table></figure><ul><li>Type: <code>LOAD</code> — to be loaded into memory.</li><li><code>off=0x1000</code> — loading starts from offset 0x1000 in the file.</li><li><code>vaddr=0x0</code> — to be loaded at virtual address <code>0x0</code> (important).</li><li><code>filesz = memsz = 0x1000</code> — both file and memory size are 4KB.</li><li><code>flags=r-x</code> — readable and executable. Indicates this is the code segment.</li></ul><p>🔑 <strong>This segment contains program instructions (text segment), and exec&#x2F;loadseg will load it into memory at 0x0.</strong></p><p><strong>3. Third Segment: Data segment</strong></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">LOAD off 0x0000000000002000 vaddr 0x0000000000001000<br>                                paddr 0x0000000000001000 align 2**12<br>        filesz 0x0000000000000010 memsz 0x0000000000000030 flags rw-<br></code></pre></td></tr></table></figure><ul><li>Type: <code>LOAD</code> — also needs to be loaded.</li><li>File offset: 0x2000</li><li>Virtual address: 0x1000</li><li><code>filesz = 0x10</code>, <code>memsz = 0x30</code> — 16 bytes from file, the rest is BSS (needs to be zero-initialized).</li><li><code>flags = rw-</code> — read&#x2F;write permission, indicates this is a data segment.</li></ul><p>🔑 This segment holds global variables — part comes from the file, the rest is zeroed out by <code>memset</code> or page initialization.</p><p><strong>4. Fourth Segment: Stack segment</strong></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">STACK off 0x0000000000000000 vaddr 0x0000000000000000<br>                                paddr 0x0000000000000000 align 2**4<br>        filesz 0x0000000000000000 memsz 0x0000000000000000 flags rw-<br></code></pre></td></tr></table></figure><ul><li>Type: <code>STACK</code> — indicates a stack segment.</li><li>Usually has no actual content; the stack is manually allocated by the kernel (not loaded from ELF).</li><li>This is just a marker indicating that the ELF expects a stack.</li></ul><p><strong>🔧 Main points in how <code>exec</code> loads ELF in xv6</strong></p><ol><li><p><strong>ELF segment loading</strong></p><ul><li>Each segment (like <code>.text</code>, <code>.data</code>) specifies a <code>vaddr</code> (virtual address).</li><li>The kernel reads <code>filesz</code> bytes from the file offset and loads them into memory at <code>vaddr</code>.</li><li>If <code>memsz &gt; filesz</code>, the remaining space (like <code>.bss</code>) must be zero-initialized.</li></ul></li><li><p><strong>User stack initialization</strong></p><ul><li>One page of memory is allocated for the user stack; the top stores the argument strings.</li><li>A “guard page” is placed below the stack and made inaccessible.</li><li>Arguments are passed to <code>main()</code> via <code>a0</code> (argc) and <code>a1</code> (argv).</li></ul></li><li><p><strong>Security checks</strong></p><ul><li>A malicious ELF file could attempt to set dangerous <code>vaddr</code> values or trigger integer overflows.</li><li>xv6 performs checks, such as preventing <code>vaddr + memsz</code> overflows.</li><li>On RISC-V, xv6 uses <strong>separate page tables</strong> for user and kernel space to prevent interference.</li></ul></li></ol><p><strong>ELF loading steps (in <code>exec</code>)</strong></p><ol><li><p>The kernel reads the ELF header and locates the Program Headers.</p></li><li><p>For each <code>LOAD</code>-type segment:</p><ul><li>It calls <code>uvmalloc</code> to allocate memory from <code>vaddr</code> to <code>vaddr + memsz</code>.</li><li>It uses <code>loadseg</code> to read <code>filesz</code> bytes from the file into that memory.</li><li>If <code>memsz &gt; filesz</code>, the remaining bytes are cleared to zero.</li></ul></li><li><p>Finally, it creates the user stack, sets up the trap frame and arguments, and jumps to user mode for execution.</p></li></ol><h3 id="3-9-Real-world"><a href="#3-9-Real-world" class="headerlink" title="3.9 Real world"></a>3.9 Real world</h3><ul><li>Xv6 is simplified by the kernel’s use of a direct map between virtual and physical addresses, and<br>by its assumption that there is physical RAM at address 0x80000000, where the kernel expects to<br>be loaded. This works with QEMU, but on real hardware it turns out to be a bad idea; real hardware<br>places RAM and devices at unpredictable physical addresses, so that (for example) there might be<br>no RAM at 0x80000000, where xv6 expect to be able to store the kernel. More serious kernel<br>designs exploit the page table to turn arbitrary hardware physical memory layouts into predictable<br>kernel virtual address layouts.</li><li>RISC-V supports protection at the level of physical addresses, but xv6 doesn’t use that feature.</li><li>On machines with lots of memory it might make sense to use RISC-V’s support for “super<br>pages.” Small pages make sense when physical memory is small, to allow allocation and page-out<br>to disk with fine granularity. For example, if a program uses only 8 kilobytes of memory, giving<br>it a whole 4-megabyte super-page of physical memory is wasteful. Larger pages make sense on<br>machines with lots of RAM, and may reduce overhead for page-table manipulation.</li><li>The xv6 kernel’s lack of a malloc-like allocator that can provide memory for small objects<br>prevents the kernel from using sophisticated data structures that would require dynamic allocation.<br>A more elaborate kernel would likely allocate many different sizes of small blocks, rather than (as<br>in xv6) just 4096-byte blocks; a real kernel allocator would need to handle small allocations as<br>well as large ones.</li></ul>]]></content:encoded>
      
      
      
      <category domain="https://GoKo-Son626.github.io/tags/xv6-riscv/">xv6-riscv</category>
      
      
      <comments>https://goko-son626.github.io/post/xv6-riscv-ch3.html#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>xv6-riscv-ch2</title>
      <link>https://goko-son626.github.io/post/xv6-riscv-ch2.html</link>
      <guid>https://goko-son626.github.io/post/xv6-riscv-ch2.html</guid>
      <pubDate>Wed, 05 Feb 2025 04:27:56 GMT</pubDate>
      
      <description>&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;This chapter2 explains how the OS is structured internally to manage hardware resources, run processes, and enforce protection.&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      
      
      
      <content:encoded><![CDATA[<ul><li><em><strong>This chapter2 explains how the OS is structured internally to manage hardware resources, run processes, and enforce protection.</strong></em></li></ul><span id="more"></span><h2 id="ch2-Operating-system-organization"><a href="#ch2-Operating-system-organization" class="headerlink" title="ch2: Operating system organization"></a><strong>ch2: Operating system organization</strong></h2><ul><li>A key requirement for an operating system is to support several activities at once.</li><li>an operating system must fulfill three requirements: multiplexing, isolation, and<br>interaction.</li><li>Xv6 runs on a multi-core1 RISC-V microprocessor, and much of its low-level functionality<br>(for example, its process implementation) is specific to RISC-V. RISC-V is a 64-bit CPU, and xv6<br>is written in “LP64” C, which means long (L) and pointers (P) in the C programming language<br>are 64 bits, but an int is 32 bits.</li><li><a href="https://lf-riscv.atlassian.net/wiki/x/kYD2">RISCV Technical Specifications</a></li></ul><h3 id="2-1-Abstracting-physical-resources"><a href="#2-1-Abstracting-physical-resources" class="headerlink" title="2.1 Abstracting physical resources"></a>2.1 Abstracting physical resources</h3><ul><li>The Unix interface is not the only way to abstract<br>resources, but it has proved to be a good one.</li></ul><h3 id="2-2-User-mode-supervisor-mode-and-system-calls"><a href="#2-2-User-mode-supervisor-mode-and-system-calls" class="headerlink" title="2.2 User mode, supervisor mode, and system calls"></a>2.2 User mode, supervisor mode, and system calls</h3><ul><li>CPUs provide hardware support for strong isolation. For example, RISC-V has three modes in<br>which the CPU can execute instructions: machine mode, supervisor mode, and user mode. Instruc-<br>tions executing in machine mode have full privilege; a CPU starts in machine mode. Machine mode<br>is mostly intended for setting up the computer during boot. Xv6 executes a few lines in machine<br>mode and then changes to supervisor mode.</li><li>In supervisor mode the CPU is allowed to execute privileged instructions: for example, en-<br>abling and disabling interrupts, reading and writing the register that holds the address of a page<br>table, etc.</li><li>An application can execute only user-mode instructions (e.g., adding<br>numbers, etc.) and is said to be running in user space, while the software in supervisor mode can<br>also execute privileged instructions and is said to be running in kernel space. The software running<br>in kernel space (or in supervisor mode) is called the kernel.</li><li>CPUs provide a<br>special instruction that switches the CPU from user mode to supervisor mode and enters the kernel<br>at an entry point specified by the kernel. (RISC-V provides the ecall instruction for this purpose.)<br>Once the CPU has switched to supervisor mode, the kernel can then validate the arguments of the<br>system call (e.g., check if the address passed to the system call is part of the application’s memory),<br>decide whether the application is allowed to perform the requested operation (e.g., check if the<br>application is allowed to write the specified file), and then deny it or execute it. It is important that<br>the kernel control the entry point for transitions to supervisor mode; if the application could decide<br>the kernel entry point, a malicious application could, for example, enter the kernel at a point where<br>the validation of arguments is skipped.</li></ul><h3 id="2-3-Kernel-organization"><a href="#2-3-Kernel-organization" class="headerlink" title="2.3 Kernel organization"></a>2.3 Kernel organization</h3><ul><li>A key design question is what part of the operating system should run in supervisor mode. One<br>possibility is that the entire operating system resides in the kernel, so that the implementations of<br>all system calls run in supervisor mode. This organization is called a <strong>monolithic kernel</strong>.</li><li>A downside of the monolithic organization is that the interactions among different parts of<br>the operating system are often complex (as we will see in the rest of this text), and therefore it is easy for an operating system developer to make a mistake. In a monolithic kernel, a mistake is<br>fatal, because an error in supervisor mode will often cause the kernel to fail. If the kernel fails,<br>the computer stops working, and thus all applications fail too. The computer must reboot to start<br>again.</li><li>To reduce the risk of mistakes in the kernel, OS designers can minimize the amount of operating<br>system code that runs in supervisor mode, and execute the bulk of the operating system in user<br>mode. This kernel organization is called a <strong>microkernel</strong>.</li><li>Figure 2.1 illustrates this microkernel design. In the figure, the file system runs as a user-level<br>process. OS services running as processes are called servers. To allow applications to interact with<br>the file server, the kernel provides an <strong>inter-process communication mechanism</strong> to send messages<br>from one user-mode process to another.<br><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/xv6-riscv-ch2/image.png" alt="alt text"></li><li>Xv6 is implemented as a monolithic kernel, like most Unix operating systems. Thus, the xv6<br>kernel interface corresponds to the operating system interface, and the kernel implements the com-<br>plete operating system. Since xv6 doesn’t provide many services, its kernel is smaller than some<br>microkernels, but conceptually xv6 is monolithic.</li></ul><h3 id="2-4-Code-xv6-organization"><a href="#2-4-Code-xv6-organization" class="headerlink" title="2.4 Code: xv6 organization"></a>2.4 Code: xv6 organization</h3><ul><li><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/xv6-riscv-ch2/image-1.png" alt="alt text"></li><li>The xv6 kernel source is in the kernel&#x2F; sub-directory. The source is divided into files, following<br>a rough notion of modularity; Figure 2.2 lists the files.The inter-module interfaces are defined in defs.h (kernel&#x2F;defs.h).</li></ul><h3 id="2-5-Process-overview"><a href="#2-5-Process-overview" class="headerlink" title="2.5 Process overview"></a>2.5 Process overview</h3><ul><li>The unit of isolation in xv6 (as in other Unix operating systems) is a process. The process ab-<br>straction prevents one process from wrecking or spying on another process’s memory, CPU, file<br>descriptors, etc. It also prevents a process from wrecking the kernel itself, so that a process can’t<br>subvert the kernel’s isolation mechanisms.</li><li>To help enforce isolation, the process abstraction provides the illusion to a program that it has<br>its own private machine. A process provides a program with what appears to be a private memory<br>system, or address space, which other processes cannot read or write. A process also provides the<br>program with what appears to be its own CPU to execute the program’s instructions.</li><li>Xv6 uses page tables (which are implemented by hardware) to give each process its own ad-<br>dress space. The RISC-V page table translates (or “maps”) a virtual address (the address that an<br>RISC-V instruction manipulates) to a physical address (an address that the CPU sends to main<br>memory).</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">|  9 bits | 9 bits | 9 bits |     12 bits     |<br>|  VPN[2] | VPN[1] | VPN[0] | Page Offset     |<br>|--------  页表索引 --------| 页内偏移 |<br><br>example:<br>虚拟地址：0x0000004001234567<br>              ↓<br>VPN[2] = 0x01  → level-2 页表（根）中偏移 8，得到 PTE1 → 指向 0x2000_0000<br>VPN[1] = 0x01  → level-1 页表中偏移 8，得到 PTE2 → 指向 0x3000_0000<br>VPN[0] = 0x46  → level-0 页表中偏移 0x230，得到 PTE3 → 页帧 0x4000<br>offset  = 0x4567<br><br>→ 最终物理地址 = 0x4000_0000 + 0x4567 = **0x4000_4567**<br></code></pre></td></tr></table></figure><ul><li>Xv6 maintains a separate page table for each process that defines that process’s address space.<br>As illustrated in Figure 2.3, an address space includes the process’s user memory starting at virtual<br>address zero.<br><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/xv6-riscv-ch2/image-2.png" alt="alt text"><ul><li>Instructions come first, followed by global variables, then the stack, and finally a “heap” area (for malloc) that the process can expand as needed.</li><li>There are a number of factors that limit the maximum size of a  process’s address space: pointers on the RISC-V are 64 bits wide; the hardware uses only the low 39 bits when looking up virtual addresses in page tables; and xv6 uses only 38 of those 39 bits. Thus, the maximum address is 238 − 1 &#x3D; 0x3fffffffff, which is MAXVA (kernel&#x2F;riscv.h:378).</li><li>At the top of the address space xv6 places a trampoline page (4096 bytes) and a trapframe page. Xv6 uses these two pages to transition into the kernel and back; the trampoline page contains the code to transition in and out of the kernel, and the trapframe is where the kernel saves the process’s user registers, as Chapter 4 explains.</li></ul></li><li>The xv6 kernel maintains many pieces of state for each process, which it gathers into a struct proc (kernel&#x2F;proc.h:85). A process’s most important pieces of kernel state are its page table, its kernel<br>stack, and its run state. We’ll use the notation p-&gt;xxx to refer to elements of the proc structure; for example, p-&gt;pagetable is a pointer to the process’s page table.</li><li>Each process has a thread of control (or thread for short) that holds the state needed to ex-<br>ecute the process.might be executing on a CPU, or suspended (not<br>executing, but capable of resuming executing in the future).</li><li>Each process has two stacks:<ul><li><strong>user stack</strong>: When the process is executing user instructions,only its user stack is in use, and its kernel stack is empty.</li><li><strong>kernel stack</strong>: When the process enters the kernel (for a system call or interrupt), the kernel code executes on the process’s kernel stack;   while a process is in the kernel, its user stack still contains saved data, but isn’t actively used.</li><li>A process’s thread alternates between actively using its user stack and its kernel stack.   The kernel stack is separate (and protected from user code) so that the kernel can execute even if a process has wrecked its user stack.</li></ul></li><li>A process can make a system call by executing the RISC-V <code>ecall</code> instruction. This instruction raises the hardware privilege level and changes the program counter to a kernel-defined entry point. The code at the entry point switches to the process’s kernel stack and executes the kernel instructions that implement the system call. When the system call completes, the kernel switches back to the user stack and returns to user space by calling the <code>sret</code> instruction, which lowers the hardware privilege level and resumes executing user instructions just after the system call instruction. A process’s thread can “block” in the kernel to wait for I&#x2F;O, and resume where it left off when the I&#x2F;O has finished.</li><li><code>p-&gt;state</code> indicates whether the process is allocated, ready to run, currently running on a CPU, waiting for I&#x2F;O, or exiting.</li><li><code>p-&gt;pagetable</code> holds the process’s page table, in the format that the RISC-V hardware ex- pects. Xv6 causes the paging hardware to use a process’s p-&gt;pagetable when executing that process in user space. A process’s page table also serve</li><li><em><strong>In summary</strong>, a process bundles two design ideas: an address space to give a process the illusion of its own memory, and a thread to give the process the illusion of its own CPU. In xv6, a process consists of one address space and one thread. In real operating systems a process may have more than one thread to take advantage of multiple CPUs.</em></li></ul><h3 id="2-6-Code-starting-xv6-the-first-process-and-system-call"><a href="#2-6-Code-starting-xv6-the-first-process-and-system-call" class="headerlink" title="2.6 Code: starting xv6, the first process and system call"></a>2.6 Code: starting xv6, the first process and system call</h3><p>To make xv6 more concrete, we’ll outline how the kernel starts and runs the first process.The subsequent chapters will describe the mechanisms that show up in this overview in more detail.</p><p>When the RISC-V computer powers on, it initializes itself and runs a boot loader which is stored in read-only memory.<br>The boot loader loads the xv6 kernel into memory.Then, in machine mode, the CPU executes xv6 starting at <code>_entry</code> (<code>kernel/entry.S:7</code>).The RISC-V starts with paging hardware disabled: virtual addresses map directly to physical addresses.</p><p>The loader loads the xv6 kernel into memory at physical address <code>0x80000000</code>.<br>The reason it places the kernel at <code>0x80000000</code> rather than <code>0x0</code> is because the address range <code>0x0:0x80000000</code> contains I&#x2F;O devices.</p><p>The instructions at <code>_entry</code> set up a stack so that xv6 can run C code.<br>Xv6 declares space for an initial stack, <code>stack0</code>, in the file <code>start.c</code> (<code>kernel/start.c:11</code>).The code at <code>_entry</code> loads the stack pointer register <code>sp</code> with the address <code>stack0 + 4096</code>, the top of the stack, because the stack on RISC-V grows down.Now that the kernel has a stack, <code>_entry</code> calls into C code at <code>start</code> (<code>kernel/start.c:15</code>).</p><p>The function <code>start</code> performs some configuration that is only allowed in machine mode, and then switches to supervisor mode.<br>To enter supervisor mode, RISC-V provides the instruction <code>mret</code>.This instruction is most often used to return from a previous call from supervisor mode to machine mode.<code>start</code> isn’t returning from such a call, but sets things up as if it were:</p><ul><li>it sets the previous privilege mode to supervisor in the register <code>mstatus</code>,</li><li>it sets the return address to <code>main</code> by writing <code>main</code>’s address into the register <code>mepc</code>,</li><li>disables virtual address translation in supervisor mode by writing 0 into the page-table register <code>satp</code>,</li><li>and delegates all interrupts and exceptions to supervisor mode.</li></ul><p>Before jumping into supervisor mode, <code>start</code> performs one more task:<br>it programs the clock chip to generate timer interrupts.With this housekeeping out of the way, <code>start</code> “returns” to supervisor mode by calling <code>mret</code>.<br>This causes the program counter to change to <code>main</code> (<code>kernel/main.c:11</code>), the address previously stored in <code>mepc</code>.</p><p>After <code>main</code> (<code>kernel/main.c:11</code>) initializes several devices and subsystems, it creates the first process by calling <code>userinit</code> (<code>kernel/proc.c:233</code>).The first process executes a small program written in RISC-V assembly, which makes the first system call in xv6.<code>initcode.S</code> (<code>user/initcode.S:3</code>) loads the number for the <code>exec</code> system call, <code>SYS_EXEC</code> (<code>kernel/syscall.h:8</code>), into register <code>a7</code>,and then calls <code>ecall</code> to re-enter the kernel.</p><p>The kernel uses the number in register <code>a7</code> in <code>syscall</code> (<code>kernel/syscall.c:132</code>) to call the desired system call.<br>The system call table (<code>kernel/syscall.c:107</code>) maps <code>SYS_EXEC</code> to the function <code>sys_exec</code>, which the kernel invokes.As we saw in Chapter 1, <code>exec</code> replaces the memory and registers of the current process with a new program (in this case, <code>/init</code>).</p><p>Once the kernel has completed <code>exec</code>, it returns to user space in the <code>/init</code> process.<code>init</code> (<code>user/init.c:15</code>) creates a new console device file if needed and then opens it as file descriptors 0, 1, and 2. Then it starts a shell on the console. The system is up.</p><h3 id="2-7-Security-Model"><a href="#2-7-Security-Model" class="headerlink" title="2.7 Security Model"></a>2.7 Security Model</h3><ul><li><p>The operating system must assume that a process’s <strong>user-level code</strong> will do its best to wreck the kernel or other processes.User code may try to dereference pointers outside its allowed address space; it may attempt to execute any RISC-V instructions, even those not intended for user code; it may try to read and write any RISC-V control register; it may try to directly access device hardware; and it may pass clever values to system calls in an attempt to trick the kernel into crashing or doing something stupid. The kernel’s goal is to restrict each user process so that all it can do is:</p><ul><li>read&#x2F;write&#x2F;execute its own user memory,</li><li>use the 32 general-purpose RISC-V registers,</li><li>and affect the kernel and other processes <strong>only</strong> in the ways that system calls are intended to allow.</li></ul></li><li><p>The expectations for the <strong>kernel’s own code</strong> are quite different.Kernel code is assumed to be written by well-meaning and careful programmers.Kernel code is expected to be bug-free, and certainly to contain nothing malicious.This assumption affects how we analyze kernel code.For example, there are many internal kernel functions (e.g., the spin locks) that would cause serious problems if kernel code used them incorrectly.When examining any specific piece of kernel code, we’ll want to convince ourselves that it behaves correctly.We assume, however, that kernel code in general is correctly written, and follows all the rules about use of the kernel’s own functions and data structures. At the hardware level, the RISC-V CPU, RAM, disk, etc. are assumed to operate as advertised in the documentation, with no hardware bugs.</p></li></ul><h3 id="2-8-Real-world"><a href="#2-8-Real-world" class="headerlink" title="2.8 Real world"></a>2.8 Real world</h3><p>Most operating systems have adopted the process concept, and most processes look similar to xv6’s. Modern operating systems, however, support several threads within a process, to allow a single process to exploit multiple CPUs. Supporting multiple threads in a process involves quite a bit of machinery that xv6 doesn’t have, often including interface changes (e.g., Linux’s clone, a variant of fork), to control which aspects of a process threads share.</p>]]></content:encoded>
      
      
      
      <category domain="https://GoKo-Son626.github.io/tags/xv6-riscv/">xv6-riscv</category>
      
      
      <comments>https://goko-son626.github.io/post/xv6-riscv-ch2.html#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>xv6-riscv-ch1</title>
      <link>https://goko-son626.github.io/post/xv6-riscv-ch1.html</link>
      <guid>https://goko-son626.github.io/post/xv6-riscv-ch1.html</guid>
      <pubDate>Wed, 05 Feb 2025 02:00:04 GMT</pubDate>
      
      <description>&lt;ul&gt;
&lt;li&gt;&lt;em&gt;&lt;strong&gt;This chapter-1 introduces the basic Unix process, file, and I&amp;#x2F;O abstractions that applications use to interact with the OS.&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      
      
      
      <content:encoded><![CDATA[<ul><li><em><strong>This chapter-1 introduces the basic Unix process, file, and I&#x2F;O abstractions that applications use to interact with the OS.</strong></em></li></ul><span id="more"></span><h2 id="ch1-Operating-system-interfaces"><a href="#ch1-Operating-system-interfaces" class="headerlink" title="ch1: Operating system interfaces"></a><strong>ch1: Operating system interfaces</strong></h2><ul><li><p>As Figure 1.1 shows, xv6 takes the traditional form of a kernel, a special program that provides<br>services to running programs. Each running program, called a process, has memory containing<br>instructions, data, and a stack. The instructions implement the program’s computation. The data<br>are the variables on which the computation acts. The stack organizes the program’s procedure calls.<br>A given computer typically has many processes but only a single kernel.<br><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/xv6-riscv-ch1/image.png" alt="alt text"></p></li><li><p>When a user program invokes a sys-<br>tem call, the hardware raises the privilege level and starts executing a pre-arranged function in the<br>kernel.<br>The collection of system calls that a kernel provides is the interface that user programs see. The<br>xv6 kernel provides a subset of the services and system calls that Unix kernels traditionally offer.<br>Figure 1.2 lists all of xv6’s system calls.<br><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/xv6-riscv-ch1/image-1.png" alt="alt text"></p></li><li><p>The shell is an ordinary program that reads commands from the user and executes them. The<br>fact that the shell is a user program, and not part of the kernel, illustrates the power of the system<br>call interface: there is nothing special about the shell. It also means that the shell is easy to replace;<br>as a result, modern Unix systems have a variety of shells to choose from, each with its own user<br>interface and scripting features. The xv6 shell is a simple implementation of the essence of the<br>Unix Bourne shell. Its implementation can be found at (user&#x2F;sh.c:1).<br><img src="https://raw.githubusercontent.com/GoKo-Son626/my-blog_images/main/xv6-riscv-ch1/image-2.png" alt="alt text"><br>The xv6 shell uses the exec calls of blew to run programs on behalf of users. The main structure of<br>the shell is simple; see main (user&#x2F;sh.c:146). The main loop reads a line of input from the user with<br>getcmd. Then it calls fork, which creates a copy of the shell process. The parent calls wait,<br>while the child runs the command. For example, if the user had typed “echo hello” to the shell,<br>runcmd would have been called with “echo hello” as the argument. runcmd (user&#x2F;sh.c:55) runs<br>the actual command. For “echo hello”, it would call exec (user&#x2F;sh.c:79). If exec succeeds then<br>the child will execute instructions from echo instead of runcmd. At some point echo will call<br>exit, which will cause the parent to return from wait in main (user&#x2F;sh.c:146).</p></li></ul><h3 id="1-1-Processes-and-memory"><a href="#1-1-Processes-and-memory" class="headerlink" title="1.1 Processes and memory"></a>1.1 Processes and memory</h3><ul><li>An xv6 process consists of user-space memory (instructions, data, and stack) and per-process state<br>private to the kernel. Xv6 time-shares processes: it transparently switches the available CPUs<br>among the set of processes waiting to execute. When a process is not executing, xv6 saves the<br>process’s CPU registers, restoring them when it next runs the process. The kernel associates a<br>process identifier, or PID, with each process.</li><li>the following program fragment written in the C programming lan-<br>guage</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> pid = fork();<br><span class="hljs-keyword">if</span>(pid &gt; <span class="hljs-number">0</span>)&#123;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;parent: child=%d\n&quot;</span>, pid);<br>pid = wait((<span class="hljs-type">int</span> *) <span class="hljs-number">0</span>);<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;child %d is done\n&quot;</span>, pid);<br>&#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(pid == <span class="hljs-number">0</span>)&#123;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;child: exiting\n&quot;</span>);<br><span class="hljs-built_in">exit</span>(<span class="hljs-number">0</span>);<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;fork error\n&quot;</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>In the example, the output lines<br>parent: child&#x3D;1234<br>child: exiting<br>might come out in either order (or even intermixed), depending on whether the parent or child gets<br>to its printf call first. After the child exits, the parent’s wait returns, causing the parent to print<br>parent: child 1234 is done<br>Although the child has the same memory contents as the parent initially, the parent and child are<br>executing with separate memory and separate registers: changing a variable in one does not affect<br>the other. For example, when the return value of wait is stored into pid in the parent process, it<br>doesn’t change the variable pid in the child. The value of pid in the child will still be zero.</p><ul><li>The exec system call replaces the calling process’s memory with a new memory image loaded<br>from a file stored in the file system. The file must have a particular format, which specifies which<br>part of the file holds instructions, which part is data, at which instruction to start, etc. Xv6 uses the<br>ELF format, which Chapter 3 discusses in more detail. Usually the file is the result of compiling<br>a program’s source code. When exec succeeds, it does not return to the calling program; instead,<br>the instructions loaded from the file start executing at the entry point declared in the ELF header.<br>exec takes two arguments: the name of the file containing the executable and an array of string<br>arguments. For example</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">char</span> *argv[<span class="hljs-number">3</span>];<br>argv[<span class="hljs-number">0</span>] = <span class="hljs-string">&quot;echo&quot;</span>;<br>argv[<span class="hljs-number">1</span>] = <span class="hljs-string">&quot;hello&quot;</span>;<br>argv[<span class="hljs-number">2</span>] = <span class="hljs-number">0</span>;<br>exec(<span class="hljs-string">&quot;/bin/echo&quot;</span>, argv);<br><span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;exec error\n&quot;</span>);<br></code></pre></td></tr></table></figure><p>This fragment replaces the calling program with an instance of the program &#x2F;bin&#x2F;echo running<br>with the argument list echo hello. Most programs ignore the first element of the argument array,<br>which is conventionally the name of the program.</p><ul><li>why fork and exec are not combined in a single call<br>we will see later that<br>the shell exploits the separation in its implementation of I&#x2F;O redirection.<br>Xv6 allocates most user-space memory implicitly: fork allocates the memory required for the<br>child’s copy of the parent’s memory, and exec allocates enough memory to hold the executable<br>file. A process that needs more memory at run-time (perhaps for malloc) can call sbrk(n) to<br>grow its data memory by n zero bytes; sbrk returns the location of the new memory.</li></ul><h3 id="1-2-I-O-and-File-descriptors"><a href="#1-2-I-O-and-File-descriptors" class="headerlink" title="1.2 I&#x2F;O and File descriptors"></a>1.2 I&#x2F;O and File descriptors</h3><ul><li>A file descriptor is a small integer representing a kernel-managed object that a process may read<br>from or write to. A process may obtain a file descriptor by opening a file, directory, or device,<br>or by creating a pipe, or by duplicating an existing descriptor. For simplicity we’ll often refer<br>to the object a file descriptor refers to as a “file”; the file descriptor interface abstracts away the<br>differences between files, pipes, and devices, making them all look like streams of bytes. We’ll<br>refer to input and output as I&#x2F;O.</li><li>Internally, the xv6 kernel uses the file descriptor as an index into a per-process table, so that<br>every process has a private space of file descriptors starting at zero. By convention, a process reads<br>from file descriptor 0 (standard input), writes output to file descriptor 1 (standard output), and<br>writes error messages to file descriptor 2 (standard error). As we will see, the shell exploits the<br>convention to implement I&#x2F;O redirection and pipelines. The shell ensures that it always has three<br>file descriptors open (user&#x2F;sh.c:152), which are by default file descriptors for the console.</li><li>The following program fragment (which forms the essence of the program cat) copies data<br>from its standard input to its standard output. If an error occurs, it writes a message to the standard<br>error.</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">char</span> buf[<span class="hljs-number">512</span>];<br><span class="hljs-type">int</span> n;<br><span class="hljs-keyword">for</span>(;;)&#123;<br>n = read(<span class="hljs-number">0</span>, buf, <span class="hljs-keyword">sizeof</span> buf);<br><span class="hljs-keyword">if</span>(n == <span class="hljs-number">0</span>)<br><span class="hljs-keyword">break</span>;<br><span class="hljs-keyword">if</span>(n &lt; <span class="hljs-number">0</span>)&#123;<br><span class="hljs-built_in">fprintf</span>(<span class="hljs-number">2</span>, <span class="hljs-string">&quot;read error\n&quot;</span>);<br><span class="hljs-built_in">exit</span>(<span class="hljs-number">1</span>);<br>&#125;<br><span class="hljs-keyword">if</span>(write(<span class="hljs-number">1</span>, buf, n) != n)&#123;<br><span class="hljs-built_in">fprintf</span>(<span class="hljs-number">2</span>, <span class="hljs-string">&quot;write error\n&quot;</span>);<br><span class="hljs-built_in">exit</span>(<span class="hljs-number">1</span>);<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>The important thing to note in the code fragment is that cat doesn’t know whether it is reading<br>from a file, console, or a pipe. Similarly cat doesn’t know whether it is printing to a console, a<br>file, or whatever. The use of file descriptors and the convention that file descriptor 0 is input and<br>file descriptor 1 is output allows a simple implementation of cat.</p><ul><li>The close system call releases a file descriptor, making it free for reuse by a future open,<br>pipe, or dup system call (see below). A newly allocated file descriptor is always the lowest-<br>numbered unused descriptor of the current process.</li><li>File descriptors and fork interact to make I&#x2F;O redirection easy to implement.</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">char</span> *argv[<span class="hljs-number">2</span>];<br>argv[<span class="hljs-number">0</span>] = <span class="hljs-string">&quot;cat&quot;</span>;<br>argv[<span class="hljs-number">1</span>] = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">if</span>(fork() == <span class="hljs-number">0</span>) &#123;<br>close(<span class="hljs-number">0</span>);<br>open(<span class="hljs-string">&quot;input.txt&quot;</span>, O_RDONLY);<br>exec(<span class="hljs-string">&quot;cat&quot;</span>, argv);<br>&#125;<br></code></pre></td></tr></table></figure><p>After the child closes file descriptor 0, open is guaranteed to use that file descriptor for the newly<br>opened input.txt: 0 will be the smallest available file descriptor. cat then executes with file<br>descriptor 0 (standard input) referring to input.txt. The parent process’s file descriptors are not<br>changed by this sequence</p><ul><li>Two file descriptors share an offset if they were derived from the same original file descriptor<br>by a sequence of fork and dup calls. Otherwise file descriptors do not share offsets, even if they<br>resulted from open calls for the same file.</li><li>dup allows shells to implement commands like this: <code>ls existing-file non-existing-file &gt; tmp1 2&gt;&amp;1</code>. The 2&gt;&amp;1 tells the shell to give the command a file descriptor 2 that is a duplicate of descriptor 1. Both the name of the existing file and the error message for the non-existing file will show up in the file tmp1. The xv6 shell doesn’t support I&#x2F;O redirection for the error file descriptor, but now you know how to implement it.</li></ul><h3 id="1-3-Pipes"><a href="#1-3-Pipes" class="headerlink" title="1.3 Pipes"></a>1.3 Pipes</h3><ul><li>A pipe is a small kernel buffer exposed to processes as a pair of file descriptors, one for reading<br>and one for writing. Writing data to one end of the pipe makes that data available for reading from<br>the other end of the pipe. Pipes provide a way for processes to communicate.</li><li>The following example code runs the program wc with standard input connected to the read<br>end of a pipe.</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> p[<span class="hljs-number">2</span>];<br><span class="hljs-type">char</span> *argv[<span class="hljs-number">2</span>];<br>argv[<span class="hljs-number">0</span>] = <span class="hljs-string">&quot;wc&quot;</span>;<br>argv[<span class="hljs-number">1</span>] = <span class="hljs-number">0</span>;<br>pipe(p);<br><span class="hljs-keyword">if</span>(fork() == <span class="hljs-number">0</span>) &#123;<br>close(<span class="hljs-number">0</span>);<br>dup(p[<span class="hljs-number">0</span>]);<br>close(p[<span class="hljs-number">0</span>]);<br>close(p[<span class="hljs-number">1</span>]);<br>exec(<span class="hljs-string">&quot;/bin/wc&quot;</span>, argv);<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>close(p[<span class="hljs-number">0</span>]);<br>write(p[<span class="hljs-number">1</span>], <span class="hljs-string">&quot;hello world\n&quot;</span>, <span class="hljs-number">12</span>);<br>close(p[<span class="hljs-number">1</span>]);<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">          pipe<br>  [p[1]] -------&gt; [p[0]]<br>   (write)         (read)<br><br>parent:<br>   write(p[1], ...)<br><br>child:<br>   dup(p[0]) -&gt; fd 0<br>   exec(&quot;wc&quot;) -&gt; wc reads from stdin (=read of pipe)<br></code></pre></td></tr></table></figure><p>The fact that read blocks until it is impossible for new data to arrive<br>is one reason that it’s important for the child to close the write end of the pipe before executing<br>wc above: if one of wc ’s file descriptors referred to the write end of the pipe and <strong>not close</strong>, wc would never see<br>end-of-file.</p><ul><li>The xv6 shell implements pipelines such as grep fork sh.c | wc -l in a manner similar<br>to the above code (user&#x2F;sh.c:101). The child process creates a pipe to connect the left end of the<br>pipeline with the right end. Then it calls fork and runcmd for the left end of the pipeline and<br>fork and runcmd for the right end, and waits for both to finish. The right end of the pipeline<br>may be a command that itself includes a pipe (e.g., a | b | c), which itself forks two new child<br>processes (one for b and one for c). Thus, the shell may create a tree of processes. The leaves<br>16of this tree are commands and the interior nodes are processes that wait until the left and right<br>children complete.</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">   sh<br>  /  \<br>a     sh<br>     /  \<br>   b     c<br></code></pre></td></tr></table></figure><ul><li><code>echo hello world &gt;/tmp/xyz; wc &lt;/tmp/xyz</code><br>Pipes have at least three advantages over temporary files in this situation. <ul><li>First, pipes automatically clean themselves up; with the file redirection, a shell would have to be careful to remove &#x2F;tmp&#x2F;xyz when done. </li><li>Second, pipes can pass arbitrarily long streams of data, while file redirection requires enough free space on disk to store all the data. </li><li>Third, pipes allow for parallel execution of pipeline stages, while the file approach requires the first program to finish before the second starts.</li></ul></li></ul><h3 id="1-4-File-system"><a href="#1-4-File-system" class="headerlink" title="1.4 File system"></a>1.4 File system</h3><ul><li>The xv6 file system provides data files, which contain uninterpreted byte arrays, and directories,<br>which contain named references to data files and other directories.</li><li>There are system calls to create new files and directories: mkdir creates a new directory, open<br>with the O_CREATE flag creates a new data file, and mknod creates a new device file. This example<br>illustrates all three:</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c">mkdir(<span class="hljs-string">&quot;/dir&quot;</span>);<br>fd = open(<span class="hljs-string">&quot;/dir/file&quot;</span>, O_CREATE|O_WRONLY);<br>close(fd);<br>mknod(<span class="hljs-string">&quot;/console&quot;</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>);<br></code></pre></td></tr></table></figure><p>mknod creates a special file that refers to a device. Associated with a device file are the major and<br>minor device numbers (the two arguments to mknod), which uniquely identify a kernel device.<br>When a process later opens a device file, the kernel diverts read and write system calls to the<br>kernel device implementation instead of passing them to the file system.</p><ul><li>A file’s name is distinct from the file itself; the same underlying file, called an inode, can have<br>multiple names, called links. Each link consists of an entry in a directory; the entry contains a file<br>name and a reference to an inode. An inode holds metadata about a file, including its type (file or<br>directory or device), its length, the location of the file’s content on disk, and the number of links to<br>a file.</li><li>The fstat system call retrieves information from the inode that a file descriptor refers to. It<br>fills in a struct stat, defined in stat.h (kernel&#x2F;stat.h) as:</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">#define T_DIR           1// Directory<br>#define T_FILE          2// File<br>#define T_DEVICE        3// Device<br><br>struct stat &#123;<br>        int dev;        // File system’s disk device<br>        uint ino;       // Inode number<br>        short type;     // Type of file<br>        short nlink;    // Number of links to file<br>        uint64 size;    // Size of file in bytes<br>&#125;;<br></code></pre></td></tr></table></figure><ul><li>The link system call creates another file system name referring to the same inode as an exist-<br>ing file. This fragment creates a new file named both a and b.</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">open(<span class="hljs-string">&quot;a&quot;</span>, O_CREATE|O_WRONLY);<br>link(<span class="hljs-string">&quot;a&quot;</span>, <span class="hljs-string">&quot;b&quot;</span>);<br></code></pre></td></tr></table></figure><p>Reading from or writing to a is the same as reading from or writing to b. Each inode is identified<br>by a unique inode number. After the code sequence above, it is possible to determine that a and b<br>refer to the same underlying contents by inspecting the result of fstat: both will return the same<br>inode number (ino), and the nlink count will be set to 2.<br>The unlink system call removes a name from the file</p><ul><li>The unlink system call removes a name from the file system. The file’s inode and the disk<br>space holding its content are only freed when the file’s link count is zero and no file descriptors<br>refer to it. Thus adding</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c">unlink(<span class="hljs-string">&quot;a&quot;</span>);<br></code></pre></td></tr></table></figure><p>to the last code sequence leaves the inode and file content accessible as b. Furthermore,</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">fd = open(<span class="hljs-string">&quot;/tmp/xyz&quot;</span>, O_CREATE|O_RDWR);<br>unlink(<span class="hljs-string">&quot;/tmp/xyz&quot;</span>);<br></code></pre></td></tr></table></figure><p>is an idiomatic way to create a temporary inode with no name that will be cleaned up when the<br>process closes fd or exits.</p><ul><li>Unix provides file utilities callable from the shell as user-level programs, for example mkdir,<br>ln, and rm. This design allows anyone to extend the command-line interface by adding new user-<br>level programs. In hindsight this plan seems obvious, but other systems designed at the time of<br>Unix often built such commands into the shell (and built the shell into the kernel).<br>One exception is cd, which is built into the shell (user&#x2F;sh.c:161). cd must change the current<br>working directory of the shell itself. If cd were run as a regular command, then the shell would<br>18fork a child process, the child process would run cd, and cd would change the child ’s working<br>directory. The parent’s (i.e., the shell’s) working directory would not change.</li></ul><h3 id="1-5-Real-world"><a href="#1-5-Real-world" class="headerlink" title="1.5 Real world"></a>1.5 Real world</h3><ul><li>the shell was the <strong>first so-called “scripting language.”</strong> The Unix system call interface persists today in<br>systems like BSD, Linux, and macOS.</li><li>The Unix system call interface has been standardized through the Portable Operating System<br>Interface (POSIX) standard. Xv6 is not POSIX compliant: it is missing many system calls (in-<br>cluding basic ones such as lseek), and many of the system calls it does provide differ from the<br>standard. Our main goals for xv6 are simplicity and clarity while providing a simple UNIX-like<br>system-call interface. Several people have extended xv6 with a few more system calls and a sim-<br>ple C library in order to run basic Unix programs. Modern kernels, however, provide many more<br>system calls, and many more kinds of kernel services, than xv6. For example, they support net-<br>working, windowing systems, user-level threads, drivers for many devices, and so on. Modern<br>kernels evolve continuously and rapidly, and offer many features beyond POSIX.</li><li>Xv6 does not provide a notion of users or of protecting one user from another; in Unix terms,<br>all xv6 processes run as root.</li></ul><h3 id="comments："><a href="#comments：" class="headerlink" title="comments："></a>comments：</h3><ul><li>Linux tries to adhere to POSIX (glibc provides most of the POSIX interfaces), but has its own extensions (e.g., epoll).</li><li>Programmers who write POSIX interfaces can compile and run them on macOS, BSD, and Linux (as long as they don’t use platform-specific extensions).</li><li>Think of the xv6 system call interface as a “subset implementation of POSIX.”</li><li></li></ul><p><a href="https://pubs.opengroup.org/onlinepubs/9699919799/"><strong>POSIX文档</strong></a></p>]]></content:encoded>
      
      
      
      <category domain="https://GoKo-Son626.github.io/tags/xv6-riscv/">xv6-riscv</category>
      
      
      <comments>https://goko-son626.github.io/post/xv6-riscv-ch1.html#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>xv6-riscv_struct</title>
      <link>https://goko-son626.github.io/post/xv6-riscv-struct.html</link>
      <guid>https://goko-son626.github.io/post/xv6-riscv-struct.html</guid>
      <pubDate>Tue, 04 Feb 2025 16:17:48 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;em&gt;&lt;strong&gt;File structure of &lt;code&gt;xv6-riscv&lt;/code&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><em><strong>File structure of <code>xv6-riscv</code></strong></em></p><span id="more"></span><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs zsh">.<br>├── kernel<br>│   ├── bio.c<br>│   ├── buf.h<br>│   ├── console.c<br>│   ├── defs.h<br>│   ├── elf.h<br>│   ├── entry.S<br>│   ├── exec.c<br>│   ├── fcntl.h<br>│   ├── file.c<br>│   ├── file.h<br>│   ├── fs.c<br>│   ├── fs.h<br>│   ├── kalloc.c<br>│   ├── kernel.ld<br>│   ├── kernelvec.S<br>│   ├── log.c<br>│   ├── main.c<br>│   ├── memlayout.h<br>│   ├── param.h<br>│   ├── pipe.c<br>│   ├── plic.c<br>│   ├── printf.c<br>│   ├── proc.c<br>│   ├── proc.h<br>│   ├── riscv.h<br>│   ├── sleeplock.c<br>│   ├── sleeplock.h<br>│   ├── spinlock.c<br>│   ├── spinlock.h<br>│   ├── start.c<br>│   ├── stat.h<br>│   ├── string.c<br>│   ├── swtch.S<br>│   ├── syscall.c<br>│   ├── syscall.h<br>│   ├── sysfile.c<br>│   ├── sysproc.c<br>│   ├── trampoline.S<br>│   ├── trap.c<br>│   ├── types.h<br>│   ├── uart.c<br>│   ├── virtio_disk.c<br>│   ├── virtio.h<br>│   └── vm.c<br>├── LICENSE<br>├── Makefile<br>├── mkfs<br>│   └── mkfs.c<br>├── README<br>└── user<br>    ├── cat.c<br>    ├── echo.c<br>    ├── forktest.c<br>    ├── grep.c<br>    ├── grind.c<br>    ├── init.c<br>    ├── initcode.S<br>    ├── kill.c<br>    ├── ln.c<br>    ├── ls.c<br>    ├── mkdir.c<br>    ├── printf.c<br>    ├── rm.c<br>    ├── sh.c<br>    ├── stressfs.c<br>    ├── ulib.c<br>    ├── umalloc.c<br>    ├── user.h<br>    ├── user.ld<br>    ├── usertests.c<br>    ├── usys.pl<br>    ├── wc.c<br>    └── zombie.c<br></code></pre></td></tr></table></figure><h2 id="逐文件详细解读它们的作用、重要性："><a href="#逐文件详细解读它们的作用、重要性：" class="headerlink" title="逐文件详细解读它们的作用、重要性："></a>逐文件详细解读它们的作用、重要性：</h2><hr><h3 id="🧠-整体结构"><a href="#🧠-整体结构" class="headerlink" title="🧠 整体结构"></a>🧠 整体结构</h3><table><thead><tr><th>目录&#x2F;文件</th><th>作用</th><th>建议重点关注</th></tr></thead><tbody><tr><td><code>kernel/</code></td><td>xv6 核心实现，内核源码</td><td>✅ 必看</td></tr><tr><td><code>user/</code></td><td>用户态程序、测试程序、库</td><td>✅ 推荐</td></tr><tr><td><code>mkfs/</code></td><td>构建文件系统镜像工具</td><td>❗可选</td></tr><tr><td>顶层构建文件</td><td><code>Makefile</code>, <code>README</code>, <code>LICENSE</code> 等</td><td>🧩 熟悉结构用</td></tr></tbody></table><hr><h2 id="📁-kernel-—-xv6-的心脏（重点模块）"><a href="#📁-kernel-—-xv6-的心脏（重点模块）" class="headerlink" title="📁 kernel&#x2F; — xv6 的心脏（重点模块）"></a>📁 kernel&#x2F; — xv6 的心脏（重点模块）</h2><p>xv6 主要模块可分为：</p><ul><li><strong>内核启动与内存管理</strong>：<code>entry.S</code>、<code>start.c</code>、<code>vm.c</code>、<code>kalloc.c</code></li><li><strong>中断、异常、系统调用</strong>：<code>trap.c</code>、<code>syscall.c</code>、<code>kernelvec.S</code>、<code>trampoline.S</code></li><li><strong>进程调度与管理</strong>：<code>proc.c</code>、<code>swtch.S</code></li><li><strong>文件系统与文件接口</strong>：<code>fs.c</code>、<code>file.c</code>、<code>bio.c</code>、<code>log.c</code></li><li><strong>设备驱动</strong>：<code>uart.c</code>、<code>console.c</code>、<code>virtio_disk.c</code>、<code>plic.c</code></li><li><strong>内核工具代码</strong>：<code>spinlock.c</code>、<code>sleeplock.c</code>、<code>printf.c</code>、<code>string.c</code></li></ul><hr><h3 id="🧾-文件级详细解释（按子系统分类）"><a href="#🧾-文件级详细解释（按子系统分类）" class="headerlink" title="🧾 文件级详细解释（按子系统分类）"></a>🧾 文件级详细解释（按子系统分类）</h3><hr><h5 id="🟩-一、内核启动与内存管理"><a href="#🟩-一、内核启动与内存管理" class="headerlink" title="🟩 一、内核启动与内存管理"></a>🟩 一、内核启动与内存管理</h5><table><thead><tr><th>文件</th><th>作用</th><th>说明</th></tr></thead><tbody><tr><td><code>entry.S</code></td><td>核心启动汇编入口</td><td>设置页表、跳转到 <code>start()</code></td></tr><tr><td><code>start.c</code></td><td>C 语言入口</td><td><code>main()</code> 前做环境初始化（页表、trapframe）</td></tr><tr><td><code>main.c</code></td><td>内核主函数</td><td>启动内核模块，如 <code>userinit()</code></td></tr><tr><td><code>kernel.ld</code></td><td>内核链接脚本</td><td>指定内核段地址、符号导出顺序</td></tr><tr><td><code>vm.c</code></td><td>虚拟内存系统</td><td>页表分配、拷贝、映射（基于 Sv39）</td></tr><tr><td><code>kalloc.c</code></td><td>物理页分配器</td><td>管理空闲页链表，用于 <code>allocuvm</code></td></tr><tr><td><code>memlayout.h</code></td><td>内存布局宏</td><td>定义 KERNBASE、PHYSTOP 等常量</td></tr></tbody></table><p>📌 建议从 <code>entry.S → start.c → main.c → userinit()</code> 跑一遍流程。</p><hr><h5 id="🟦-二、进程管理与调度"><a href="#🟦-二、进程管理与调度" class="headerlink" title="🟦 二、进程管理与调度"></a>🟦 二、进程管理与调度</h5><table><thead><tr><th>文件</th><th>作用</th><th>说明</th></tr></thead><tbody><tr><td><code>proc.c</code></td><td>管理进程表、fork&#x2F;wait</td><td><code>scheduler()</code> 是调度器核心</td></tr><tr><td><code>proc.h</code></td><td>进程结构体定义</td><td>结构体 <code>struct proc</code> 包含页表、状态、trapframe</td></tr><tr><td><code>swtch.S</code></td><td>上下文切换汇编</td><td>保存&#x2F;恢复寄存器，调度必用</td></tr><tr><td><code>trap.c</code></td><td>trap&#x2F;中断入口</td><td>用户 → 内核的总入口；异常调度、syscall 都走它</td></tr><tr><td><code>sysproc.c</code></td><td>与进程相关的系统调用</td><td><code>sys_exit</code>、<code>sys_fork</code>、<code>sys_wait</code></td></tr></tbody></table><p>📌 强烈建议：给 <code>fork()</code>、<code>scheduler()</code>、<code>yield()</code> 加打印观察运行。</p><hr><h5 id="🟨-三、系统调用机制"><a href="#🟨-三、系统调用机制" class="headerlink" title="🟨 三、系统调用机制"></a>🟨 三、系统调用机制</h5><table><thead><tr><th>文件</th><th>作用</th><th>说明</th></tr></thead><tbody><tr><td><code>syscall.c</code></td><td>syscall 分发器</td><td>根据 syscall num 分发到 <code>sys_*</code></td></tr><tr><td><code>syscall.h</code></td><td>syscall 编号</td><td>用 <code>#define SYS_write 1</code> 等映射</td></tr><tr><td><code>sysfile.c</code></td><td>文件相关 syscall</td><td><code>open/close/read/write</code> 的内核实现</td></tr><tr><td><code>usys.pl</code> → <code>usys.S</code></td><td>用户态 syscall 包装</td><td>生成用户代码 <code>mov a7, id; ecall</code></td></tr></tbody></table><p>📌 syscall 流程 &#x3D; 用户态 <code>ecall</code> → trap → syscall.c → sys_*()</p><hr><h5 id="🟧-四、文件系统与-I-O-接口"><a href="#🟧-四、文件系统与-I-O-接口" class="headerlink" title="🟧 四、文件系统与 I&#x2F;O 接口"></a>🟧 四、文件系统与 I&#x2F;O 接口</h5><table><thead><tr><th>文件</th><th>作用</th><th>说明</th></tr></thead><tbody><tr><td><code>fs.c</code></td><td>inode 层</td><td><code>ialloc</code>, <code>readi</code>, <code>writei</code>，文件核心结构</td></tr><tr><td><code>fs.h</code></td><td>inode 定义</td><td><code>struct inode</code>，块地址信息等</td></tr><tr><td><code>file.c</code></td><td>文件描述符层</td><td><code>struct file</code>，管理 open&#x2F;close 等</td></tr><tr><td><code>file.h</code></td><td>文件描述符定义</td><td>支持 pipe&#x2F;dev&#x2F;inode 等类型</td></tr><tr><td><code>bio.c</code></td><td>缓存块读写</td><td>实现 block 级读写缓存</td></tr><tr><td><code>log.c</code></td><td>日志机制</td><td>crash-safe 写操作事务（write-ahead logging）</td></tr><tr><td><code>pipe.c</code></td><td>管道实现</td><td>内存中双向 FIFO</td></tr><tr><td><code>fcntl.h</code>, <code>stat.h</code></td><td>POSIX 相关头文件</td><td>用于 <code>open</code> flag、<code>stat</code> 结构体</td></tr></tbody></table><p>📌 建议调试 <code>fs.c</code> 的 <code>namei()</code>、<code>dirlookup()</code>，看路径如何被解析。</p><hr><h5 id="🟥-五、设备驱动与中断控制"><a href="#🟥-五、设备驱动与中断控制" class="headerlink" title="🟥 五、设备驱动与中断控制"></a>🟥 五、设备驱动与中断控制</h5><table><thead><tr><th>文件</th><th>作用</th><th>说明</th></tr></thead><tbody><tr><td><code>uart.c</code></td><td>串口驱动</td><td>初始化串口，写入字符给终端</td></tr><tr><td><code>console.c</code></td><td>控制台 I&#x2F;O</td><td>与 UART 配合实现 shell 输入输出</td></tr><tr><td><code>plic.c</code></td><td>中断控制器</td><td>Platform-Level Interrupt Controller</td></tr><tr><td><code>virtio_disk.c</code></td><td>虚拟磁盘驱动</td><td>QEMU 虚拟磁盘硬件访问层</td></tr><tr><td><code>virtio.h</code></td><td>virtio 设备定义</td><td>配套数据结构</td></tr></tbody></table><p>📌 <code>virtio_disk.c</code> 调试方法：观察 <code>virtio_rw()</code> 实现的读写逻辑。</p><hr><h5 id="🟫-六、工具类-内核库函数"><a href="#🟫-六、工具类-内核库函数" class="headerlink" title="🟫 六、工具类 &#x2F; 内核库函数"></a>🟫 六、工具类 &#x2F; 内核库函数</h5><table><thead><tr><th>文件</th><th>作用</th><th>说明</th></tr></thead><tbody><tr><td><code>defs.h</code></td><td>内核函数声明</td><td><code>extern</code> 所有模块函数，供全局使用</td></tr><tr><td><code>riscv.h</code></td><td>RISC-V CSR 宏、寄存器定义</td><td>包含 <code>rdtime</code>, <code>csrr</code>, <code>sstatus</code> 等</td></tr><tr><td><code>spinlock.c/.h</code></td><td>自旋锁实现</td><td>核心互斥机制，需关中断</td></tr><tr><td><code>sleeplock.c/.h</code></td><td>睡眠锁实现</td><td>用于文件系统，sleep&#x2F;wakeup 管理</td></tr><tr><td><code>string.c</code></td><td>libc 实现</td><td><code>memcpy</code>, <code>strlen</code> 等内核自带函数</td></tr><tr><td><code>printf.c</code></td><td>内核级 printf</td><td>用于调试打印，无缓冲版</td></tr><tr><td><code>param.h</code></td><td>系统参数宏</td><td>定义 <code>NPROC</code>, <code>MAXPATH</code> 等全局参数</td></tr><tr><td><code>types.h</code></td><td>常用类型定义</td><td><code>uchar</code>, <code>uint</code>, <code>sint</code> 等简写</td></tr></tbody></table><p>📌 常用 grep 命令：<code>grep -rn &quot;spin_lock&quot; kernel/</code> 追踪并发点</p><hr><h3 id="📁-user-—-用户态程序与测试"><a href="#📁-user-—-用户态程序与测试" class="headerlink" title="📁 user&#x2F; — 用户态程序与测试"></a>📁 user&#x2F; — 用户态程序与测试</h3><table><thead><tr><th>文件</th><th>作用</th><th>说明</th></tr></thead><tbody><tr><td><code>*.c</code></td><td>命令程序</td><td>shell 命令如 <code>ls</code>, <code>cat</code>, <code>echo</code>, <code>sh</code> 等</td></tr><tr><td><code>init.c</code></td><td>首个用户进程</td><td><code>userinit()</code> 启动的程序，运行 <code>/init</code></td></tr><tr><td><code>initcode.S</code></td><td>最原始的用户态代码</td><td>由 <code>userinit()</code> 载入的程序（汇编）</td></tr><tr><td><code>ulib.c</code></td><td>libc 函数</td><td>用户态的 <code>malloc</code>, <code>printf</code> 等</td></tr><tr><td><code>umalloc.c</code></td><td>malloc 实现</td><td>用户态堆分配</td></tr><tr><td><code>usertests.c</code></td><td>用户态测试集</td><td>测试 syscall、进程、文件功能</td></tr><tr><td><code>user.ld</code></td><td>用户态链接脚本</td><td>控制用户程序的段分布</td></tr><tr><td><code>user.h</code></td><td>函数声明</td><td>供用户程序引用 <code>printf</code>, <code>fork</code> 等接口</td></tr></tbody></table><p>📌 强烈推荐你从 <code>init.c</code> 开始 debug，第一个用户进程的运行关键路径！</p><hr><h3 id="📁-mkfs-—-构建文件系统镜像工具"><a href="#📁-mkfs-—-构建文件系统镜像工具" class="headerlink" title="📁 mkfs&#x2F; — 构建文件系统镜像工具"></a>📁 mkfs&#x2F; — 构建文件系统镜像工具</h3><table><thead><tr><th>文件</th><th>说明</th></tr></thead><tbody><tr><td><code>mkfs.c</code></td><td>构建 xv6 文件系统镜像（user&#x2F;init 等文件压入）</td></tr></tbody></table><p>📌 不看也无妨，用于 <code>make</code> 阶段构建 <code>fs.img</code></p><hr><h3 id="📄-顶层文件"><a href="#📄-顶层文件" class="headerlink" title="📄 顶层文件"></a>📄 顶层文件</h3><table><thead><tr><th>文件</th><th>说明</th></tr></thead><tbody><tr><td><code>Makefile</code></td><td>编译入口，构建 <code>kernel</code>, <code>fs.img</code>, <code>qemu</code> 等</td></tr><tr><td><code>README</code></td><td>简要说明文档，讲解如何使用</td></tr><tr><td><code>LICENSE</code></td><td>授权条款（MIT）</td></tr></tbody></table><hr><h3 id="✅-总结"><a href="#✅-总结" class="headerlink" title="✅ 总结"></a>✅ 总结</h3><ul><li>用 <strong>模块化思维</strong> 分阶段学，比如 “先把 trap 理清楚”，再看 syscall。</li><li>推荐搭配如下工具：<ul><li>tmux</li><li>zsh</li><li>grep…</li></ul></li></ul>]]></content:encoded>
      
      
      
      <category domain="https://GoKo-Son626.github.io/tags/xv6-riscv/">xv6-riscv</category>
      
      
      <comments>https://goko-son626.github.io/post/xv6-riscv-struct.html#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
